[
  {
    "id": "q_1928",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der Begriff „Big Data“ bezeichnet dabei sowohl die zugrunde liegenden Daten als auch die Technologien und Methoden zu deren Erfassung, Verarbeitung, Übertragung und Speicherung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der Begriff „Big Data“ bezeichnet dabei sowohl die zugrunde liegenden Daten als auch die Technologien und Methoden zu deren Erfassung, Verarbeitung, Übertragung und Speicherung",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 3,
    "tags": [
      "Der",
      "Begriff",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1929",
    "question": "Welche Aussage über Das ist korrekt?",
    "type": "single",
    "options": [
      "Das Hauptziel von Big-Data -Analytics besteht darin, Organisationen dabei zu unterstützen, fundiertere Geschäftsentscheidungen zu treffen, indem Data Scientists, Modellierer prädiktiver Modelle und andere Analysefachkräfte in die Lage versetzt werden, große Mengen an Transaktionsdaten sowie weitere Datenarten zu analysieren, die von herkömmlichen Business -Intelligence -(BI)-Programmen häufig nicht erschlossen werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Das Hauptziel von Big-Data -Analytics besteht darin, Organisationen dabei zu unterstützen, fundiertere Geschäftsentscheidungen zu treffen, indem Data Scientists, Modellierer prädiktiver Modelle und andere Analysefachkräfte in die Lage versetzt werden, große Mengen an Transaktionsdaten sowie weitere Datenarten zu analysieren, die von herkömmlichen Business -Intelligence -(BI)-Programmen häufig nicht erschlossen werden",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 3,
    "tags": [
      "Das",
      "Hauptziel",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1930",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science SQL-Datenbanken (Relationale Datenbanken) Optimiert für Transaktionen Optimiert für Online Transaction Processing (OLTP) schnell kleine, komplexe Abfragen viele Updates oder Einfügungen Schema -on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science SQL-Datenbanken (Relationale Datenbanken) Optimiert für Transaktionen Optimiert für Online Transaction Processing (OLTP) schnell kleine, komplexe Abfragen viele Updates oder Einfügungen Schema -on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1931",
    "question": "Welche Aussage über Server ist korrekt?",
    "type": "single",
    "options": [
      ", man kann einfach mehr Server hinzufügen, um die Leistung zu steigern",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": ", man kann einfach mehr Server hinzufügen, um die Leistung zu steigern",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Server",
      "Leistung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1932",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science WS 25/26Szenario 1: Bestellverwaltung in einem Online -Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science WS 25/26Szenario 1: Bestellverwaltung in einem Online -Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1933",
    "question": "Welche Aussage über Aktualisieren ist korrekt?",
    "type": "single",
    "options": [
      "•Aktualisieren des Lagerbestands, wenn eine Bestellung aufgegeben wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "•Aktualisieren des Lagerbestands, wenn eine Bestellung aufgegeben wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Aktualisieren",
      "Lagerbestands",
      "Bestellung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1934",
    "question": "Welche Aussage über Performance ist korrekt?",
    "type": "single",
    "options": [
      "Performance -Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Performance -Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Performance",
      "Aspekte",
      "Schnelligkeit"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1935",
    "question": "Welche Aussage über Die ist korrekt?",
    "type": "single",
    "options": [
      "Die Datenmenge ist riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Die Datenmenge ist riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Die",
      "Datenmenge",
      "Posts"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1936",
    "question": "Welche Aussage über Performance ist korrekt?",
    "type": "single",
    "options": [
      "Performance -Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Performance -Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Performance",
      "Aspekte",
      "Verarbeitung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1937",
    "question": "Welche Aussage über Skalierbarkeit ist korrekt?",
    "type": "single",
    "options": [
      "•Skalierbarkeit: Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "•Skalierbarkeit: Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Skalierbarkeit",
      "Bei",
      "Datenvolumen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1938",
    "question": "Welche Aussage über Flexibilität ist korrekt?",
    "type": "single",
    "options": [
      "•Flexibilität bei unstrukturierten Daten: Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "•Flexibilität bei unstrukturierten Daten: Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Flexibilität",
      "Daten",
      "Diese"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1939",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Moderne Systeme ( BigQuery , Snowflake, Redshift , Spark SQL) sind SQL -basiert SQL ist eine Abfragesprache – nicht gleichbedeutend mit einer einzelnen Datenbanktechnologie",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Moderne Systeme ( BigQuery , Snowflake, Redshift , Spark SQL) sind SQL -basiert SQL ist eine Abfragesprache – nicht gleichbedeutend mit einer einzelnen Datenbanktechnologie",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 9,
    "tags": [
      "Klemens",
      "Waldhör",
      "Moderne"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1940",
    "question": "Welche Aussage über Warum ist korrekt?",
    "type": "single",
    "options": [
      "Warum ist Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Warum ist Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Warum",
      "Spark",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1941",
    "question": "Welche Aussage über Warum ist korrekt?",
    "type": "single",
    "options": [
      "Warum ist Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Warum ist Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Warum",
      "Spark",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1942",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science Hadoop – Überblick Apache Hadoop isteinOpen- Source -Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science Hadoop – Überblick Apache Hadoop isteinOpen- Source -Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 19,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1943",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science HDFS –Hadoop Distributed File System 20Big Data & Data Science -Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science HDFS –Hadoop Distributed File System 20Big Data & Data Science -Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 20,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1944",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science MapReduce – Überblick & Idee Architektur MapReduce isteinProgrammiermodell zur verteilten Batch -Verarbeitung sehr großer Datenmengen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science MapReduce – Überblick & Idee Architektur MapReduce isteinProgrammiermodell zur verteilten Batch -Verarbeitung sehr großer Datenmengen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 21,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1945",
    "question": "Welche Aussage über Input ist korrekt?",
    "type": "single",
    "options": [
      "Input -Daten werden inSplits aufgeteilt 2",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Input -Daten werden inSplits aufgeteilt 2",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Input",
      "Daten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1946",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science MapReduce – Einordnung & Grenzen Vorteile Einfaches ,robustes Modell Hohe Skalierbarkeit undFehlertoleranz Grenzen Hohe Latenz (Batch -orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science MapReduce – Einordnung & Grenzen Vorteile Einfaches ,robustes Modell Hohe Skalierbarkeit undFehlertoleranz Grenzen Hohe Latenz (Batch -orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 23,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1947",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science YARN – Zentrale Komponenten ResourceManager (RM): Zentrale Instanz für clusterweite Ressourcenverwaltung Besteht ausScheduler und ApplicationManager NodeManager (NM): Agent auf jedem Knoten Überwacht Container und Ressourcennutzung ApplicationMaster (AM): Anwendungs -spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science YARN – Zentrale Komponenten ResourceManager (RM): Zentrale Instanz für clusterweite Ressourcenverwaltung Besteht ausScheduler und ApplicationManager NodeManager (NM): Agent auf jedem Knoten Überwacht Container und Ressourcennutzung ApplicationMaster (AM): Anwendungs -spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 26,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1948",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science Apache Spark – Überblick Apache Spark isteinschnelles ,verteiltes In-Memory -Framework zurVerarbeitung großer Datenmengen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science Apache Spark – Überblick Apache Spark isteinschnelles ,verteiltes In-Memory -Framework zurVerarbeitung großer Datenmengen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 27,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1949",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data & Data Science Hadoop heute – Einordnung Basis vieler Big-Data-Architekturen HDFS alsData Lake oder Storage-Basis MapReduce meist durch Spark ersetzt Konzepte bleiben zentral für Big Data WS  Big Data & Data Science -Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data & Data Science Hadoop heute – Einordnung Basis vieler Big-Data-Architekturen HDFS alsData Lake oder Storage-Basis MapReduce meist durch Spark ersetzt Konzepte bleiben zentral für Big Data WS  Big Data & Data Science -Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 31,
    "tags": [
      "Big",
      "Data",
      "Data"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1950",
    "question": "Welche Aussage über The ist korrekt?",
    "type": "single",
    "options": [
      "org/ “The Apache® Hadoop® project develops open-source software for reliable, scalable, distributed computing",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "org/ “The Apache® Hadoop® project develops open-source software for reliable, scalable, distributed computing",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 33,
    "tags": [
      "The",
      "Apache",
      "Hadoop"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1951",
    "question": "Welche Aussage über The ist korrekt?",
    "type": "single",
    "options": [
      "The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 33,
    "tags": [
      "The",
      "Apache",
      "Hadoop"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1952",
    "question": "Welche Aussage über Hadoop ist korrekt?",
    "type": "single",
    "options": [
      "Hadoop-Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop-Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Hadoop",
      "Anwendungen",
      "Rechner"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1953",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Betriebssysteme Hauptsächlich Linux „GNU/Linux wird als Entwicklungs - und Produktionsplattform unterstützt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Betriebssysteme Hauptsächlich Linux „GNU/Linux wird als Entwicklungs - und Produktionsplattform unterstützt",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Klemens",
      "Waldhör",
      "Hauptsächlich"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1954",
    "question": "Welche Aussage über Quelle ist korrekt?",
    "type": "single",
    "options": [
      "“ (Quelle: Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "“ (Quelle: Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Quelle",
      "Hadoop",
      "Dokumentation"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1955",
    "question": "Welche Aussage über Hadoop ist korrekt?",
    "type": "single",
    "options": [
      " Hadoop ist für Cluster - Computing konzipiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": " Hadoop ist für Cluster - Computing konzipiert",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Hadoop",
      "Cluster",
      "Computing"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1956",
    "question": "Welche Aussage über Release ist korrekt?",
    "type": "single",
    "options": [
      "2 – dies ist das neueste stabile Release der Hadoop-3",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "2 – dies ist das neueste stabile Release der Hadoop-3",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Release",
      "Hadoop"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1957",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Facebook (2020, historisch) HDFS -Cluster mit einer Speicherkapazität von 21 PB 2000 Maschinen (1200 Maschinen mit jeweils 8 Kernen und 800 Maschinen mit jeweils 16 Kernen) 12 TB Speicher pro Maschine und 32 GB RAM pro Maschine 15 MapReduce- Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Facebook (2020, historisch) HDFS -Cluster mit einer Speicherkapazität von 21 PB 2000 Maschinen (1200 Maschinen mit jeweils 8 Kernen und 800 Maschinen mit jeweils 16 Kernen) 12 TB Speicher pro Maschine und 32 GB RAM pro Maschine 15 MapReduce- Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 37,
    "tags": [
      "Klemens",
      "Waldhör",
      "Cluster"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1958",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Traditionelle Architektur mit getrennten Speicher - und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Traditionelle Architektur mit getrennten Speicher - und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 39,
    "tags": [
      "Klemens",
      "Waldhör",
      "Traditionelle"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1959",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Anstatt einen einzelnen großen Speicher zu verwenden, werden die Daten auf eine große Anzahl von Knoten verteilt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Anstatt einen einzelnen großen Speicher zu verwenden, werden die Daten auf eine große Anzahl von Knoten verteilt",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 40,
    "tags": [
      "Klemens",
      "Waldhör",
      "Anstatt"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1960",
    "question": "Welche Aussage über Die ist korrekt?",
    "type": "single",
    "options": [
      "Die gleichen Daten werden auf mehrere Knoten repliziert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Die gleichen Daten werden auf mehrere Knoten repliziert",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 40,
    "tags": [
      "Die",
      "Daten",
      "Knoten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1961",
    "question": "Welche Aussage über Knoten ist korrekt?",
    "type": "single",
    "options": [
      "Knoten können jederzeit hinzugefügt oder entfernt werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Knoten können jederzeit hinzugefügt oder entfernt werden",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 40,
    "tags": [
      "Knoten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1962",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der Datentransfer wird minimiert, da die Daten dort verarbeitet werden, wo sie gespeichert sind",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der Datentransfer wird minimiert, da die Daten dort verarbeitet werden, wo sie gespeichert sind",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 40,
    "tags": [
      "Der",
      "Datentransfer",
      "Daten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1963",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data Analytics Hadoop Distributed File System (HDFS): 41Big Data & Data Science - Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop Distributed File System (HDFS): 41Big Data & Data Science - Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Big",
      "Data",
      "Analytics"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1964",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Scaling Reliability Ausfälle sind keine Ausnahme, sondern die Regel",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Scaling Reliability Ausfälle sind keine Ausnahme, sondern die Regel",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Klemens",
      "Waldhör",
      "Reliability"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1965",
    "question": "Welche Aussage über Erfordert ist korrekt?",
    "type": "single",
    "options": [
      "16 TB RAM) Erfordert einen fehlertoleranten Speicher mit angemessenen Verfügbarkeitsgarantien Hardwarefehler müssen transparent behandelt werden, ohne Eingriff durch Anwendungen oder Benutzer In großen Clustern ist nicht die Frage, ob etwas ausfällt, sondern wann",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "16 TB RAM) Erfordert einen fehlertoleranten Speicher mit angemessenen Verfügbarkeitsgarantien Hardwarefehler müssen transparent behandelt werden, ohne Eingriff durch Anwendungen oder Benutzer In großen Clustern ist nicht die Frage, ob etwas ausfällt, sondern wann",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Erfordert",
      "Speicher",
      "Verfügbarkeitsgarantien"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1966",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS  Relationale Datenbanken Kriterium Hadoop (klassisch) Cloud Data Lake / Spark SQL Schema- on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS  Relationale Datenbanken Kriterium Hadoop (klassisch) Cloud Data Lake / Spark SQL Schema- on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 44,
    "tags": [
      "Klemens",
      "Waldhör",
      "Relationale"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1967",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Predictive Maintenance: The Schema IoT Application: Predictive Maintenance Machine Health Forecast Pattern recognition Condition monitoringRaw Sensor Data Analyze React Reduce Devices and ConductorsMachine Data Integration 1001010101001100 1001001010101101 0110001110101011 01010100101100101010010101101101 Any DBMemoryCreate mmm Service Order Schedule Order m Execute Order m ERP DB Connectivity Hadoop ConnectorSmart Data Access Links only Historic Analytics & Reaction",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Predictive Maintenance: The Schema IoT Application: Predictive Maintenance Machine Health Forecast Pattern recognition Condition monitoringRaw Sensor Data Analyze React Reduce Devices and ConductorsMachine Data Integration 1001010101001100 1001001010101101 0110001110101011 01010100101100101010010101101101 Any DBMemoryCreate mmm Service Order Schedule Order m Execute Order m ERP DB Connectivity Hadoop ConnectorSmart Data Access Links only Historic Analytics & Reaction",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 48,
    "tags": [
      "Klemens",
      "Waldhör",
      "Maintenance"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1968",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Hadoop Distributed File System (HDFS) Dateisystem eines Hadoop- Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Hadoop Distributed File System (HDFS) Dateisystem eines Hadoop- Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Klemens",
      "Waldhör",
      "Distributed"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1969",
    "question": "Welche Aussage über Hadoop ist korrekt?",
    "type": "single",
    "options": [
      "über Hadoop Archives (HAR), HBase oder Containerformate gebündelt werden HDFS unterstützt Rack -Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "über Hadoop Archives (HAR), HBase oder Containerformate gebündelt werden HDFS unterstützt Rack -Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Hadoop",
      "Archives",
      "Containerformate"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1970",
    "question": "Welche Aussage über Vermeidung ist korrekt?",
    "type": "single",
    "options": [
      "Vermeidung mehrerer Replikate im selben Rack) HDFS ist für Durchsatz und Skalierbarkeit optimiert – nicht für niedrige Latenz oder viele kleine Dateien",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Vermeidung mehrerer Replikate im selben Rack) HDFS ist für Durchsatz und Skalierbarkeit optimiert – nicht für niedrige Latenz oder viele kleine Dateien",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Vermeidung",
      "Replikate",
      "Rack"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1971",
    "question": "Welche Aussage über The ist korrekt?",
    "type": "single",
    "options": [
      "” “The existence of a single NameNode in a cluster greatly simplifies the architecture of the system",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "” “The existence of a single NameNode in a cluster greatly simplifies the architecture of the system",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 53,
    "tags": [
      "The"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1972",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Job Execution : Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Job Execution : Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Klemens",
      "Waldhör",
      "Execution"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1973",
    "question": "Welche Aussage über Map ist korrekt?",
    "type": "single",
    "options": [
      ") Map- Phase: Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": ") Map- Phase: Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Map",
      "Phase",
      "Die"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1974",
    "question": "Welche Aussage über Die ist korrekt?",
    "type": "single",
    "options": [
      "Die Ergebnisse werden anschließend geshuffelt und sortiert, um sie für die Reduce- Phase vorzubereiten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Die Ergebnisse werden anschließend geshuffelt und sortiert, um sie für die Reduce- Phase vorzubereiten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Die",
      "Ergebnisse",
      "Reduce"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1975",
    "question": "Welche Aussage über Fault ist korrekt?",
    "type": "single",
    "options": [
      "Fault Tolerance: HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Fault Tolerance: HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Fault",
      "Tolerance",
      "Datenblöcke"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1976",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der NameNode verwaltet die Metadaten des Dateisystems im Arbeitsspeicher und speichert sie dauerhaft auf der Festplatte: Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der NameNode verwaltet die Metadaten des Dateisystems im Arbeitsspeicher und speichert sie dauerhaft auf der Festplatte: Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Der",
      "Metadaten",
      "Dateisystems"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1977",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der vollständige Zustand des Dateisystem -Namespace wird in der Datei FsImage serialisiert gespeichert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der vollständige Zustand des Dateisystem -Namespace wird in der Datei FsImage serialisiert gespeichert",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Der",
      "Zustand",
      "Dateisystem"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1978",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Skalierbarkeit Neue Knoten können dem Cluster hinzugefügt werden, ohne Datenformate, Ladevorgänge, Job-Implementierungen oder darauf aufbauende Anwendungen anpassen zu müssen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Skalierbarkeit Neue Knoten können dem Cluster hinzugefügt werden, ohne Datenformate, Ladevorgänge, Job-Implementierungen oder darauf aufbauende Anwendungen anpassen zu müssen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 55,
    "tags": [
      "Klemens",
      "Waldhör",
      "Neue"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1979",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Cluster -Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Cluster -Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Klemens",
      "Waldhör",
      "Management"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1980",
    "question": "Welche Aussage über Für ist korrekt?",
    "type": "single",
    "options": [
      "Für die Erfassung von Leistungskennzahlen nutzt Ambari das Ambari Metrics System",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Für die Erfassung von Leistungskennzahlen nutzt Ambari das Ambari Metrics System",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Für",
      "Erfassung",
      "Leistungskennzahlen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1981",
    "question": "Welche Aussage über Für ist korrekt?",
    "type": "single",
    "options": [
      "Für Systemmeldungen und Warnungen verwendet Ambari das Ambari Alert Framework, z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Für Systemmeldungen und Warnungen verwendet Ambari das Ambari Alert Framework, z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Für",
      "Systemmeldungen",
      "Warnungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1982",
    "question": "Welche Aussage über Ausfall ist korrekt?",
    "type": "single",
    "options": [
      ": Ausfall eines Knotens geringer verbleibender Speicherplatz andere kritische Systemzustände Apache Ambari wird weiterhin eingesetzt, wird jedoch in modernen Cloud- Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": ": Ausfall eines Knotens geringer verbleibender Speicherplatz andere kritische Systemzustände Apache Ambari wird weiterhin eingesetzt, wird jedoch in modernen Cloud- Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Ausfall",
      "Knotens",
      "Speicherplatz"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1983",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Resource Management (YARN): YARN ( Yet Another Resource Negotiator ) ist eine zentrale Komponente des Hadoop -Ökosystems, die mit Hadoop 2",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Resource Management (YARN): YARN ( Yet Another Resource Negotiator ) ist eine zentrale Komponente des Hadoop -Ökosystems, die mit Hadoop 2",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Klemens",
      "Waldhör",
      "Management"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1984",
    "question": "Welche Aussage über Plattform ist korrekt?",
    "type": "single",
    "options": [
      "YARN ist eine Plattform zur Ressourcenverwaltung, die für die Verwaltung der Rechenressourcen in Clustern und deren Nutzung zur Planung und Ausführung von Anwendungen verantwortlich ist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "YARN ist eine Plattform zur Ressourcenverwaltung, die für die Verwaltung der Rechenressourcen in Clustern und deren Nutzung zur Planung und Ausführung von Anwendungen verantwortlich ist",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Plattform",
      "Ressourcenverwaltung",
      "Verwaltung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1985",
    "question": "Welche Aussage über Diese ist korrekt?",
    "type": "single",
    "options": [
      "Diese Trennung verbessert die Skalierbarkeit und Auslastung des Clusters, da mehrere Datenverarbeitungs - Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Diese Trennung verbessert die Skalierbarkeit und Auslastung des Clusters, da mehrere Datenverarbeitungs - Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Diese",
      "Trennung",
      "Skalierbarkeit"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1986",
    "question": "Welche Aussage über Verbesserte ist korrekt?",
    "type": "single",
    "options": [
      "Verbesserte Clusterauslastung: YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Verbesserte Clusterauslastung: YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Verbesserte",
      "Clusterauslastung",
      "Zuweisung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1987",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26ResourceManager (RM): Der ResourceManager ist die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26ResourceManager (RM): Der ResourceManager ist die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Klemens",
      "Waldhör",
      "Der"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1988",
    "question": "Welche Aussage über Er ist korrekt?",
    "type": "single",
    "options": [
      "Er besteht aus zwei Hauptkomponenten: dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Er besteht aus zwei Hauptkomponenten: dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Er",
      "Hauptkomponenten",
      "Schedulerdem"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1989",
    "question": "Welche Aussage über Annahme ist korrekt?",
    "type": "single",
    "options": [
      "ApplicationManagerist zuständig für: die Annahme von Job- Einreichungen, die Aushandlung des ersten Containers zur Ausführung des anwendungsspezifischen ApplicationMaster , das Neustarten des ApplicationMaster -Containers im Fehlerfall",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "ApplicationManagerist zuständig für: die Annahme von Job- Einreichungen, die Aushandlung des ersten Containers zur Ausführung des anwendungsspezifischen ApplicationMaster , das Neustarten des ApplicationMaster -Containers im Fehlerfall",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Annahme",
      "Job",
      "Einreichungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1990",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26NodeManager Der NodeManager ist ein Agent auf jedem Cluster -Knoten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26NodeManager Der NodeManager ist ein Agent auf jedem Cluster -Knoten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Klemens",
      "Waldhör",
      "Der"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1991",
    "question": "Welche Aussage über Er ist korrekt?",
    "type": "single",
    "options": [
      "Er ist verantwortlich für: die Verwaltung der Container auf dem jeweiligen Knoten, die Überwachung der Ressourcennutzung( CPU, Speicher, Festplatte, Netzwerk), die Rückmeldung von Status - und Ressourcendaten an den ResourceManager",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Er ist verantwortlich für: die Verwaltung der Container auf dem jeweiligen Knoten, die Überwachung der Ressourcennutzung( CPU, Speicher, Festplatte, Netzwerk), die Rückmeldung von Status - und Ressourcendaten an den ResourceManager",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Er",
      "Verwaltung",
      "Container"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1992",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26ApplicationMaster (AM) Der ApplicationMaster ist eine instanzierte, frameworkspezifische Komponente (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26ApplicationMaster (AM) Der ApplicationMaster ist eine instanzierte, frameworkspezifische Komponente (z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Klemens",
      "Waldhör",
      "Der"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1993",
    "question": "Welche Aussage über Er ist korrekt?",
    "type": "single",
    "options": [
      "Er ist verantwortlich für: die Aushandlung geeigneter Ressourcen-Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Er ist verantwortlich für: die Aushandlung geeigneter Ressourcen-Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Er",
      "Aushandlung",
      "Ressourcen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1994",
    "question": "Welche Aussage über Für ist korrekt?",
    "type": "single",
    "options": [
      "Für jede Anwendung existiert genau ein eigener ApplicationMaster",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Für jede Anwendung existiert genau ein eigener ApplicationMaster",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Für",
      "Anwendung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1995",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Container Wird eine Anwendung bei YARN eingereicht, weist der ResourceManager einen oder mehrere Container zu",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Container Wird eine Anwendung bei YARN eingereicht, weist der ResourceManager einen oder mehrere Container zu",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Klemens",
      "Waldhör",
      "Wird"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1996",
    "question": "Welche Aussage über Arbeitsspeicher ist korrekt?",
    "type": "single",
    "options": [
      ": Arbeitsspeicher (RAM) CPU-Kerne (optional) weitere Ressourcen wie lokale Festplatte oder Netzwerk Container sind isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": ": Arbeitsspeicher (RAM) CPU-Kerne (optional) weitere Ressourcen wie lokale Festplatte oder Netzwerk Container sind isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Arbeitsspeicher",
      "Kerne",
      "Ressourcen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1997",
    "question": "Welche Aussage über Ein ist korrekt?",
    "type": "single",
    "options": [
      "Ein YARN -Container ist kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Ein YARN -Container ist kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Ein",
      "Container",
      "Betriebssystem"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1998",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Funktionsweise von YARN Bei der Einreichung einer Anwendung weist der ResourceManager zunächst einen Container zu, um den ApplicationMaster der Anwendung zu starten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Funktionsweise von YARN Bei der Einreichung einer Anwendung weist der ResourceManager zunächst einen Container zu, um den ApplicationMaster der Anwendung zu starten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Klemens",
      "Waldhör",
      "Bei"
    ],
    "difficulty": 3
  },
  {
    "id": "q_1999",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der ResourceManager ist für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der ResourceManager ist für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Der",
      "Ressourcenplanung",
      "Ausführung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2000",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Der JobTracker ist eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Der JobTracker ist eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Klemens",
      "Waldhör",
      "Komponente"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2001",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der TaskTracker ist in Hadoop 1",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der TaskTracker ist in Hadoop 1",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Der",
      "Hadoop"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2002",
    "question": "Welche Aussage über Stellt ist korrekt?",
    "type": "single",
    "options": [
      "Stellt einen Single Point of Failure dar, sofern kein Hadoop -HA-Modus eingesetzt wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Stellt einen Single Point of Failure dar, sofern kein Hadoop -HA-Modus eingesetzt wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Stellt",
      "Single",
      "Point"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2003",
    "question": "Welche Aussage über Ermöglicht ist korrekt?",
    "type": "single",
    "options": [
      "Ermöglicht Clients den direkten Zugriff auf konkrete Datenblöcke (Lesen/Schreiben)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Ermöglicht Clients den direkten Zugriff auf konkrete Datenblöcke (Lesen/Schreiben)",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Ermöglicht",
      "Clients",
      "Zugriff"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2004",
    "question": "Welche Aussage über Die ist korrekt?",
    "type": "single",
    "options": [
      "Die Client -API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Die Client -API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 66,
    "tags": [
      "Die",
      "Client",
      "Dateizeigers"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2005",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der NameNode antwortet dem Client und teilt ihm mit, welcher DataNode der Primary und welche die Secondary -Replikate sind",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der NameNode antwortet dem Client und teilt ihm mit, welcher DataNode der Primary und welche die Secondary -Replikate sind",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 67,
    "tags": [
      "Der",
      "Client",
      "Primary"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2006",
    "question": "Welche Aussage über Der ist korrekt?",
    "type": "single",
    "options": [
      "Der Client streamt die Daten an den Primary DataNode , der die Daten pipeline -artig an die weiteren Secondary DataNodes weiterleitet; die Daten werden zunächst gepuffert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Der Client streamt die Daten an den Primary DataNode , der die Daten pipeline -artig an die weiteren Secondary DataNodes weiterleitet; die Daten werden zunächst gepuffert",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 67,
    "tags": [
      "Der",
      "Client",
      "Daten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2007",
    "question": "Welche Aussage über Blockverteilung ist korrekt?",
    "type": "single",
    "options": [
      "Blockverteilung und Replikationsinformationen, und schreibt diese Änderungen persistent in das EditLog/ FsImage",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Blockverteilung und Replikationsinformationen, und schreibt diese Änderungen persistent in das EditLog/ FsImage",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 67,
    "tags": [
      "Blockverteilung",
      "Replikationsinformationen",
      "Änderungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2008",
    "question": "Welche Aussage über Zusätzlich ist korrekt?",
    "type": "single",
    "options": [
      "Zusätzlich kann ein Parallelkorpus vorliegen – eine Sammlung von Originaltexten und deren Übersetzungen, die zur Analyse sowie zum Training maschineller Übersetzungssysteme verwendet wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Zusätzlich kann ein Parallelkorpus vorliegen – eine Sammlung von Originaltexten und deren Übersetzungen, die zur Analyse sowie zum Training maschineller Übersetzungssysteme verwendet wird",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 69,
    "tags": [
      "Zusätzlich",
      "Parallelkorpus",
      "Sammlung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2009",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Datenspeicherung Das Hadoop Distributed File System (HDFS) speichert umfangreiche Parallelkorpora und Translation -Memory -(TM) -Datenbanken",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Datenspeicherung Das Hadoop Distributed File System (HDFS) speichert umfangreiche Parallelkorpora und Translation -Memory -(TM) -Datenbanken",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Klemens",
      "Waldhör",
      "Das"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2010",
    "question": "Welche Aussage über Diese ist korrekt?",
    "type": "single",
    "options": [
      "Diese Datensätze sind häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Diese Datensätze sind häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Diese",
      "Datensätze",
      "Datenbanksystemen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2011",
    "question": "Welche Aussage über Beispielsweise ist korrekt?",
    "type": "single",
    "options": [
      "Beispielsweise kann Hadoop beim Start eines neuen Projekts eingesetzt werden, um die Translation Memory schnell nach passenden früheren Übersetzungen zum neuen Inhalt zu durchsuchen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Beispielsweise kann Hadoop beim Start eines neuen Projekts eingesetzt werden, um die Translation Memory schnell nach passenden früheren Übersetzungen zum neuen Inhalt zu durchsuchen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Beispielsweise",
      "Hadoop",
      "Start"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2012",
    "question": "Welche Aussage über Datenanalyse ist korrekt?",
    "type": "single",
    "options": [
      "Datenanalyse Hadoop kann zur Sprachanalyse der gespeicherten Daten verwendet werden, um häufige Phrasen und Terminologie zu identifizieren",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Datenanalyse Hadoop kann zur Sprachanalyse der gespeicherten Daten verwendet werden, um häufige Phrasen und Terminologie zu identifizieren",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Datenanalyse",
      "Hadoop",
      "Sprachanalyse"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2013",
    "question": "Welche Aussage über Dies ist korrekt?",
    "type": "single",
    "options": [
      "Dies verbessert die Konsistenz der Übersetzungen über verschiedene Übersetzer und Projekte hinweg",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Dies verbessert die Konsistenz der Übersetzungen über verschiedene Übersetzer und Projekte hinweg",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Dies",
      "Konsistenz",
      "Übersetzungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2014",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Skalierbarkeit Mit dem Wachstum der unternehmensweiten Übersetzungsdatenbank ermöglicht Hadoop eine einfache Skalierung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Skalierbarkeit Mit dem Wachstum der unternehmensweiten Übersetzungsdatenbank ermöglicht Hadoop eine einfache Skalierung",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 71,
    "tags": [
      "Klemens",
      "Waldhör",
      "Mit"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2015",
    "question": "Welche Aussage über Zusätzliche ist korrekt?",
    "type": "single",
    "options": [
      "Zusätzliche Knoten können dem Cluster hinzugefügt werden, um steigende Datenmengen zu verarbeiten, ohne dass eine grundlegende Umstrukturierung der Infrastruktur erforderlich ist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Zusätzliche Knoten können dem Cluster hinzugefügt werden, um steigende Datenmengen zu verarbeiten, ohne dass eine grundlegende Umstrukturierung der Infrastruktur erforderlich ist",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 71,
    "tags": [
      "Zusätzliche",
      "Knoten",
      "Cluster"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2016",
    "question": "Welche Aussage über Kosteneffizienz ist korrekt?",
    "type": "single",
    "options": [
      "Kosteneffizienz Im Vergleich zu klassischen relationalen Datenbanksystemen (RDBMS), die bei wachsenden Datenvolumina schnell sehr kostspielig werden können, bietet Hadoop durch seine verteilte Architektur eine kosteneffizientere Lösung für Speicherung und Verarbeitung großer Datenmengen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Kosteneffizienz Im Vergleich zu klassischen relationalen Datenbanksystemen (RDBMS), die bei wachsenden Datenvolumina schnell sehr kostspielig werden können, bietet Hadoop durch seine verteilte Architektur eine kosteneffizientere Lösung für Speicherung und Verarbeitung großer Datenmengen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 71,
    "tags": [
      "Kosteneffizienz",
      "Im",
      "Vergleich"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2017",
    "question": "Welche Aussage über Dies ist korrekt?",
    "type": "single",
    "options": [
      "Dies verbessert die Fähigkeit, präzise und konsistente Übersetzungen bereitzustellen, unterstützt die Entwicklung proprietärer Übersetzungstechnologien und verschafft dem Unternehmen letztlich einen Wettbewerbsvorteil im Übersetzungsmarkt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Dies verbessert die Fähigkeit, präzise und konsistente Übersetzungen bereitzustellen, unterstützt die Entwicklung proprietärer Übersetzungstechnologien und verschafft dem Unternehmen letztlich einen Wettbewerbsvorteil im Übersetzungsmarkt",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 71,
    "tags": [
      "Dies",
      "Fähigkeit",
      "Übersetzungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2018",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Datenspeicherung Speicherung von Parallelkorpora und Translation Memories (TM) Data Lake auf HDFS oder Object Storage (S3 / ADLS) Geeignet für strukturierte und unstrukturierte Textdaten Hohe Skalierbarkeit gegenüber klassischen RDBMS Datenverarbeitung Verarbeitung großer Textmengen mit Apache Spark In-Memory -Verarbeitung für schnelle Analysen Suche in Translation Memories Erkennung von Mustern und ÄhnlichkeitenDatenanalyse SQL-ähnliche Abfragen mit Spark SQL Analyse häufiger Phrasen und Terminologie Identifikation von Inkonsistenzen Verbesserung der Übersetzungsqualität Maschinelles Lernen Training von NLP - und Übersetzungsmodellen Nutzung von Spark MLlib oder angebundenen ML-Frameworks Verarbeitung großer Parallelkorpora Kontinuierliche Modellverbesserung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Datenspeicherung Speicherung von Parallelkorpora und Translation Memories (TM) Data Lake auf HDFS oder Object Storage (S3 / ADLS) Geeignet für strukturierte und unstrukturierte Textdaten Hohe Skalierbarkeit gegenüber klassischen RDBMS Datenverarbeitung Verarbeitung großer Textmengen mit Apache Spark In-Memory -Verarbeitung für schnelle Analysen Suche in Translation Memories Erkennung von Mustern und ÄhnlichkeitenDatenanalyse SQL-ähnliche Abfragen mit Spark SQL Analyse häufiger Phrasen und Terminologie Identifikation von Inkonsistenzen Verbesserung der Übersetzungsqualität Maschinelles Lernen Training von NLP - und Übersetzungsmodellen Nutzung von Spark MLlib oder angebundenen ML-Frameworks Verarbeitung großer Parallelkorpora Kontinuierliche Modellverbesserung",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 73,
    "tags": [
      "Klemens",
      "Waldhör",
      "Speicherung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2019",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Skalierbarkeit Horizontale Skalierung von Speicher und Rechenleistung Trennung von Compute und Storage Flexible Nutzung von Cloud- Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Skalierbarkeit Horizontale Skalierung von Speicher und Rechenleistung Trennung von Compute und Storage Flexible Nutzung von Cloud- Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 74,
    "tags": [
      "Klemens",
      "Waldhör",
      "Horizontale"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2020",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Software-Framework zur verteilten Verarbeitung großer Datenmengen Paralleler, verteilter Algorithmus, der auf einem Cluster ausgeführt wird Ursprünglich von Google als Werkzeug zur Big-Data-Analyse entwickelt Die Datenverarbeitung erfolgt direkt auf den Clusterknoten, auf denen die Daten auch gespeichert sind (Datenlokalität) MapReduce-Tasks werden auf mehrere Clusterknoten verteilt, um die Vorteile der parallelen Verarbeitung optimal zu nutzen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Software-Framework zur verteilten Verarbeitung großer Datenmengen Paralleler, verteilter Algorithmus, der auf einem Cluster ausgeführt wird Ursprünglich von Google als Werkzeug zur Big-Data-Analyse entwickelt Die Datenverarbeitung erfolgt direkt auf den Clusterknoten, auf denen die Daten auch gespeichert sind (Datenlokalität) MapReduce-Tasks werden auf mehrere Clusterknoten verteilt, um die Vorteile der parallelen Verarbeitung optimal zu nutzen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 78,
    "tags": [
      "Klemens",
      "Waldhör",
      "Software"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2021",
    "question": "Welche Aussage über Sobald ist korrekt?",
    "type": "single",
    "options": [
      "Sobald alle Map- Tasks abgeschlossen sind, weist der JobTracker die ausgewählten TaskTracker an, mit der Reduce- Phase zu beginnen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Sobald alle Map- Tasks abgeschlossen sind, weist der JobTracker die ausgewählten TaskTracker an, mit der Reduce- Phase zu beginnen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 79,
    "tags": [
      "Sobald",
      "Map",
      "Tasks"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2022",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Key-Value -Pairs – Map Phase Ein Key -Value-Paar besteht aus zwei miteinander verknüpften Datenelementen: einem Key, der als eindeutiger Identifikator dient, und einem Value, der die dem Key zugeordneten Daten enthält",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Key-Value -Pairs – Map Phase Ein Key -Value-Paar besteht aus zwei miteinander verknüpften Datenelementen: einem Key, der als eindeutiger Identifikator dient, und einem Value, der die dem Key zugeordneten Daten enthält",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 82,
    "tags": [
      "Klemens",
      "Waldhör",
      "Value"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2023",
    "question": "Welche Aussage über In ist korrekt?",
    "type": "single",
    "options": [
      "(\"green\", 1) In einer realen MapReduce- Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "(\"green\", 1) In einer realen MapReduce- Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 83,
    "tags": [
      "In",
      "Ausführunga",
      "Datenmengen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2024",
    "question": "Welche Aussage über Das ist korrekt?",
    "type": "single",
    "options": [
      "Das Programm P besteht aus zwei Teilprogrammen: Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Das Programm P besteht aus zwei Teilprogrammen: Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Das",
      "Programm",
      "Teilprogrammen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2025",
    "question": "Welche Aussage über Identifiziere ist korrekt?",
    "type": "single",
    "options": [
      "Identifiziere alle Clusterknoten C, auf denen Teile des Datensatzes X gespeichert sind (Datenlokalität)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Identifiziere alle Clusterknoten C, auf denen Teile des Datensatzes X gespeichert sind (Datenlokalität)",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Identifiziere",
      "Clusterknoten",
      "Teile"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2026",
    "question": "Welche Aussage über Daraus ist korrekt?",
    "type": "single",
    "options": [
      "Daraus wird eine Liste einzelner Wörter erzeugt, jeweils zusammen mit der Anzahl ihrer Vorkommen ( Termfrequenz )",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Daraus wird eine Liste einzelner Wörter erzeugt, jeweils zusammen mit der Anzahl ihrer Vorkommen ( Termfrequenz )",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Daraus",
      "Liste",
      "Wörter"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2027",
    "question": "Welche Aussage über Zur ist korrekt?",
    "type": "single",
    "options": [
      "Zur Simulation mehrerer Knoten werden Threads verwendet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Zur Simulation mehrerer Knoten werden Threads verwendet",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Zur",
      "Simulation",
      "Knoten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2028",
    "question": "Welche Aussage über It ist korrekt?",
    "type": "single",
    "options": [
      "It processes a list of texts , using the map_function on each text",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "It processes a list of texts , using the map_function on each text",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 89,
    "tags": [
      "It"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2029",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Kopieren und Ausführen des Sourcecodes für den Map-Task M auf allen Knoten C Map-Task M Input: Eine Zeile aus dem Datensatz Verarbeitung: Extraktion eines KEY:VALUE -Paares aus den Inputdaten Output: Ein KEY:VALUE Paar Jeder Knoten verarbeitet nur die Daten von X, die auf ihm gespeichert sind Input Data Mapper K1:V K2 :V K3 :V K1 :V1Map- Phase",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Kopieren und Ausführen des Sourcecodes für den Map-Task M auf allen Knoten C Map-Task M Input: Eine Zeile aus dem Datensatz Verarbeitung: Extraktion eines KEY:VALUE -Paares aus den Inputdaten Output: Ein KEY:VALUE Paar Jeder Knoten verarbeitet nur die Daten von X, die auf ihm gespeichert sind Input Data Mapper K1:V K2 :V K3 :V K1 :V1Map- Phase",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 97,
    "tags": [
      "Klemens",
      "Waldhör",
      "Kopieren"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2030",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Kopieren und Ausführen des Sourcecodes für den Reduce-Task R auf einem Teil der Knoten Reduce-Task R Input: Ein KEY und eine Liste der dazugehörigen VALUES (KEY:VALUES) Verarbeitung: Aggregierung der VALUES zu einem Ergebnis (VALUE) Output: Ein KEY:VALUE Paar Sorted Data Reduce K1:2 K2:1 K3:1Reduce - Phase",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Kopieren und Ausführen des Sourcecodes für den Reduce-Task R auf einem Teil der Knoten Reduce-Task R Input: Ein KEY und eine Liste der dazugehörigen VALUES (KEY:VALUES) Verarbeitung: Aggregierung der VALUES zu einem Ergebnis (VALUE) Output: Ein KEY:VALUE Paar Sorted Data Reduce K1:2 K2:1 K3:1Reduce - Phase",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 101,
    "tags": [
      "Klemens",
      "Waldhör",
      "Kopieren"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2031",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS Für jedes KEY:VALUES Paar wird die Anzahl der VALUES bestimmt und in Form eines neuen Paares KEY:ANZAHL(VALUES) gespeichert Sorted Data Reduce K1:2 K2:1 K3:1196:[242, 337] 244:51166:346 186:[302, 274, 265]244:1 196:2186:3 166:1Reduce - Phase",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS Für jedes KEY:VALUES Paar wird die Anzahl der VALUES bestimmt und in Form eines neuen Paares KEY:ANZAHL(VALUES) gespeichert Sorted Data Reduce K1:2 K2:1 K3:1196:[242, 337] 244:51166:346 186:[302, 274, 265]244:1 196:2186:3 166:1Reduce - Phase",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 102,
    "tags": [
      "Klemens",
      "Waldhör",
      "Für"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2032",
    "question": "Welche Aussage über Spark ist korrekt?",
    "type": "single",
    "options": [
      "Spark wurde mit dem Ziel entwickelt, MapReduce als Verarbeitungsmodell zu ersetzen (insbesondere wegen Performance und Flexibilität), kann jedoch komplementär zu Hadoop eingesetzt werden, z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Spark wurde mit dem Ziel entwickelt, MapReduce als Verarbeitungsmodell zu ersetzen (insbesondere wegen Performance und Flexibilität), kann jedoch komplementär zu Hadoop eingesetzt werden, z",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 111,
    "tags": [
      "Spark",
      "Ziel",
      "Verarbeitungsmodell"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2033",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS “A fast and general engine for large -scale data processing“ Spark wird häufig in Kombination mit Hadoop eingesetzt, wobei HDFS als Speicherschicht und YARN als Ressourcenmanager verwendet werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS “A fast and general engine for large -scale data processing“ Spark wird häufig in Kombination mit Hadoop eingesetzt, wobei HDFS als Speicherschicht und YARN als Ressourcenmanager verwendet werden",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 113,
    "tags": [
      "Klemens",
      "Waldhör",
      "Spark"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2034",
    "question": "Welche Aussage über Fast ist korrekt?",
    "type": "single",
    "options": [
      "Fast 100x faster than MapReduce Batch processing Real-time processing Stores data on disk Stores data in memory Java Codebase Scala Codebase Low on Cost Higher costs More line of codes (MR) High-level APIS Java, Python, … Batch processing Real-time processing Data replication in HDFS Resilient Distributed Datasets",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Fast 100x faster than MapReduce Batch processing Real-time processing Stores data on disk Stores data in memory Java Codebase Scala Codebase Low on Cost Higher costs More line of codes (MR) High-level APIS Java, Python, … Batch processing Real-time processing Data replication in HDFS Resilient Distributed Datasets",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 113,
    "tags": [
      "Fast",
      "Batch",
      "Real"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2035",
    "question": "Welche Aussage über Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens Waldhör WS 25/26Basiert auf einem zentralen Konzept : dem Resilient Distributed Dataset (RDD)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens Waldhör WS 25/26Basiert auf einem zentralen Konzept : dem Resilient Distributed Dataset (RDD)",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 116,
    "tags": [
      "Klemens",
      "Waldhör",
      "Konzept"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2036",
    "question": "Welche Aussage über Big ist korrekt?",
    "type": "single",
    "options": [
      "Big Data Analytics Erkläre den Begriff “Resilient Distributed Datasets“ in Spark",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Erkläre den Begriff “Resilient Distributed Datasets“ in Spark",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 118,
    "tags": [
      "Big",
      "Data",
      "Analytics"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2037",
    "question": "Welche Aussage über Finde ist korrekt?",
    "type": "single",
    "options": [
      "Finde einen Anwendungsfall, in dem Apache Spark in Ihrem Unternehmen eingesetzt werden kann",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "Finde einen Anwendungsfall, in dem Apache Spark in Ihrem Unternehmen eingesetzt werden kann",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 118,
    "tags": [
      "Finde",
      "Anwendungsfall",
      "Apache"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2038",
    "question": "Welche Aussage über Netze ist korrekt?",
    "type": "single",
    "options": [
      "durch neuronale Netze) Speicherung im hochdimensionalen Vektorraum Suche über Distanzmaße (Kosinus, euklidisch) Nutzung spezieller Indexstrukturen (ANN, HNSW) Vektordatenbanken in RAG & Big Data Zentrale Komponente in Retrieval -Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage möglich"
    ],
    "correct_answer": 0,
    "explanation": "durch neuronale Netze) Speicherung im hochdimensionalen Vektorraum Suche über Distanzmaße (Kosinus, euklidisch) Nutzung spezieller Indexstrukturen (ANN, HNSW) Vektordatenbanken in RAG & Big Data Zentrale Komponente in Retrieval -Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 121,
    "tags": [
      "Netze",
      "Speicherung",
      "Vektorraum"
    ],
    "difficulty": 3
  },
  {
    "id": "q_2039",
    "question": "Was ist Veracity?",
    "type": "single",
    "options": [
      "Value Big Data Analytics Bezieht sich auf den komplexen Prozess der Analyse großer und vielfältiger Datenmengen („Big Data“), um Erkenntnisse wie verborgene Muster, unbekannte Zusammenhänge, Markttrends, Kundenpräferenzen und andere geschäftlich relevante Informationen aufzudecken.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Veracity: Value Big Data Analytics Bezieht sich auf den komplexen Prozess der Analyse großer und vielfältiger Datenmengen („Big Data“), um Erkenntnisse wie verborgene Muster, unbekannte Zusammenhänge, Markttrends, Kundenpräferenzen und andere geschäftlich relevante Informationen aufzudecken.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 3,
    "tags": [
      "Veracity"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2040",
    "question": "Richtig oder Falsch: Veracity Value Big Data Analytics Bezieht sich auf den komplexen Prozess der Analyse großer und vielfältiger Datenmengen („Big Data“), um Erkenntnisse wie verborgene Muster, unbekannte Zusammenhänge, Markttrends, Kundenpräferenzen und andere geschäftlich relevante Informationen aufzudecken.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Veracity: Value Big Data Analytics Bezieht sich auf den komplexen Prozess der Analyse großer und vielfältiger Datenmengen („Big Data“), um Erkenntnisse wie verborgene Muster, unbekannte Zusammenhänge, Markttrends, Kundenpräferenzen und andere geschäftlich relevante Informationen aufzudecken.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 3,
    "tags": [
      "Veracity"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2041",
    "question": "Was ist Data Science Frage?",
    "type": "single",
    "options": [
      "Warum reicht SQL nicht aus?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Data Science Frage: Warum reicht SQL nicht aus?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 4,
    "tags": [
      "Data Science Frage"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2042",
    "question": "Richtig oder Falsch: Data Science Frage Warum reicht SQL nicht aus?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Data Science Frage: Warum reicht SQL nicht aus?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 4,
    "tags": [
      "Data Science Frage"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2043",
    "question": "Was ist Schema?",
    "type": "single",
    "options": [
      "on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Schema: on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Schema"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2044",
    "question": "Richtig oder Falsch: Schema on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Schema: on-Write definiertes Schema für Einfügen in Datenbank Datenstruktur sehr stabil und vorhersehbar ACID- Eigenschaften Atomicity , Consistency, Isolation, und Durability , Geschwindigkeit Schnell bei kleineren Datensätzen oder komplexen Abfragen, auf strukturierte DatenSQL?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Schema"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2045",
    "question": "Was ist Schema?",
    "type": "single",
    "options": [
      "on-Read verschiedenen Formaten Schema erst bei der Abfragehohe Flexibilität bei der Datenspeicherung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Schema: on-Read verschiedenen Formaten Schema erst bei der Abfragehohe Flexibilität bei der Datenspeicherung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Schema"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2046",
    "question": "Richtig oder Falsch: Schema on-Read verschiedenen Formaten Schema erst bei der Abfragehohe Flexibilität bei der Datenspeicherung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Schema: on-Read verschiedenen Formaten Schema erst bei der Abfragehohe Flexibilität bei der Datenspeicherung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 5,
    "tags": [
      "Schema"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2047",
    "question": "Was ist Geschwindigkeitsunterschiede?",
    "type": "single",
    "options": [
      "Kleine, komplexe Transaktionen Ein Online-Shop aktualisiert LagerbeständeSQL-Datenbank wahrscheinlich schneller und zuverlässiger.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Geschwindigkeitsunterschiede: Kleine, komplexe Transaktionen Ein Online-Shop aktualisiert LagerbeständeSQL-Datenbank wahrscheinlich schneller und zuverlässiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 6,
    "tags": [
      "Geschwindigkeitsunterschiede"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2048",
    "question": "Richtig oder Falsch: Geschwindigkeitsunterschiede Kleine, komplexe Transaktionen Ein Online-Shop aktualisiert LagerbeständeSQL-Datenbank wahrscheinlich schneller und zuverlässiger.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Geschwindigkeitsunterschiede: Kleine, komplexe Transaktionen Ein Online-Shop aktualisiert LagerbeständeSQL-Datenbank wahrscheinlich schneller und zuverlässiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 6,
    "tags": [
      "Geschwindigkeitsunterschiede"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2049",
    "question": "Was ist Social?",
    "type": "single",
    "options": [
      "Media-Daten über mehrere Jahre Big Data-Technologie wie Hadoop oder Spark wahrscheinlich effizienter.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Social: Media-Daten über mehrere Jahre Big Data-Technologie wie Hadoop oder Spark wahrscheinlich effizienter.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 6,
    "tags": [
      "Social"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2050",
    "question": "Richtig oder Falsch: Social Media-Daten über mehrere Jahre Big Data-Technologie wie Hadoop oder Spark wahrscheinlich effizienter.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Social: Media-Daten über mehrere Jahre Big Data-Technologie wie Hadoop oder Spark wahrscheinlich effizienter.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 6,
    "tags": [
      "Social"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2051",
    "question": "Was ist Online?",
    "type": "single",
    "options": [
      "Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Online: Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Online"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2052",
    "question": "Richtig oder Falsch: Online Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Online: Shop (SQL -Datenbank) Situation: Ein Online -Shop verwendet eine SQL -Datenbank, um Bestellungen zu verwalten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Online"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2053",
    "question": "Was ist Kunden?",
    "type": "single",
    "options": [
      "ID, Produkt -ID, Menge, Preis und Datum.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Kunden: ID, Produkt -ID, Menge, Preis und Datum.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Kunden"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2054",
    "question": "Richtig oder Falsch: Kunden ID, Produkt -ID, Menge, Preis und Datum.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Kunden: ID, Produkt -ID, Menge, Preis und Datum.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Kunden"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2055",
    "question": "Was ist Typische Aufgaben?",
    "type": "single",
    "options": [
      "•Einfügen neuer Bestellungen in die Datenbank.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Typische Aufgaben: •Einfügen neuer Bestellungen in die Datenbank.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Typische Aufgaben"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2056",
    "question": "Richtig oder Falsch: Typische Aufgaben •Einfügen neuer Bestellungen in die Datenbank.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Typische Aufgaben: •Einfügen neuer Bestellungen in die Datenbank.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Typische Aufgaben"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2057",
    "question": "Was ist Performance?",
    "type": "single",
    "options": [
      "Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Performance: Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Performance"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2058",
    "question": "Richtig oder Falsch: Performance Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Performance: Aspekte: •Schnelligkeit bei Transaktionen: Das Einfügen und Aktualisieren von Daten erfolgt schnell, da die Datenbank für solche Operationen optimiert ist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Performance"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2059",
    "question": "Was ist Komplexe Abfragen?",
    "type": "single",
    "options": [
      "Die Datenbank kann komplexe Abfragen effizient verarbeiten, z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Komplexe Abfragen: Die Datenbank kann komplexe Abfragen effizient verarbeiten, z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Komplexe Abfragen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2060",
    "question": "Richtig oder Falsch: Komplexe Abfragen Die Datenbank kann komplexe Abfragen effizient verarbeiten, z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Komplexe Abfragen: Die Datenbank kann komplexe Abfragen effizient verarbeiten, z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 7,
    "tags": [
      "Komplexe Abfragen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2061",
    "question": "Was ist Social?",
    "type": "single",
    "options": [
      "Media -Daten (Big Data -Technologie) Situation: Ein Unternehmen analysiert Social -Media -Daten, um Trends und Muster zu erkennen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Social: Media -Daten (Big Data -Technologie) Situation: Ein Unternehmen analysiert Social -Media -Daten, um Trends und Muster zu erkennen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Social"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2062",
    "question": "Richtig oder Falsch: Social Media -Daten (Big Data -Technologie) Situation: Ein Unternehmen analysiert Social -Media -Daten, um Trends und Muster zu erkennen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Social: Media -Daten (Big Data -Technologie) Situation: Ein Unternehmen analysiert Social -Media -Daten, um Trends und Muster zu erkennen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Social"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2063",
    "question": "Was ist Typische Aufgaben?",
    "type": "single",
    "options": [
      "•Verarbeitung und Speicherung von riesigen Datenmengen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Typische Aufgaben: •Verarbeitung und Speicherung von riesigen Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Typische Aufgaben"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2064",
    "question": "Richtig oder Falsch: Typische Aufgaben •Verarbeitung und Speicherung von riesigen Datenmengen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Typische Aufgaben: •Verarbeitung und Speicherung von riesigen Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Typische Aufgaben"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2065",
    "question": "Was ist Performance?",
    "type": "single",
    "options": [
      "Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Performance: Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Performance"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2066",
    "question": "Richtig oder Falsch: Performance Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Performance: Aspekte: •Verarbeitung großer Datenmengen: Big Data -Systeme wie Hadoop oder Spark sind dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Performance"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2067",
    "question": "Was ist Skalierbarkeit?",
    "type": "single",
    "options": [
      "Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Skalierbarkeit: Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Skalierbarkeit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2068",
    "question": "Richtig oder Falsch: Skalierbarkeit Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Skalierbarkeit: Bei zunehmendem Datenvolumen können diese Systeme leicht skaliert werden, indem man mehr Ressourcen hinzufügt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Skalierbarkeit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2069",
    "question": "Was ist Daten?",
    "type": "single",
    "options": [
      "Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Daten: Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Daten"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2070",
    "question": "Richtig oder Falsch: Daten Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Daten: Diese Technologien können mit einer Vielzahl von Datenformaten umgehen, was für die Analyse von Social -Media -Daten wichtig ist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Daten"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2071",
    "question": "Was ist Datenmenge?",
    "type": "single",
    "options": [
      "riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Datenmenge: riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Datenmenge"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2072",
    "question": "Richtig oder Falsch: Datenmenge riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Datenmenge: riesig und beinhaltet Posts, Likes, Kommentare und Shares über mehrere Jahre.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Datenmenge"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2073",
    "question": "Was ist Spark?",
    "type": "single",
    "options": [
      "dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Spark: dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Spark"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2074",
    "question": "Richtig oder Falsch: Spark dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Spark: dafür ausgelegt, große Datenmengen effizient zu verarbeiten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 8,
    "tags": [
      "Spark"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2075",
    "question": "Was ist Big Data?",
    "type": "single",
    "options": [
      "Mythen 9Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data: Mythen 9Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 9,
    "tags": [
      "Big Data"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2076",
    "question": "Richtig oder Falsch: Big Data Mythen 9Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data: Mythen 9Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 9,
    "tags": [
      "Big Data"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2077",
    "question": "Was ist Data Science Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 11 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Data Science Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 11 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 11,
    "tags": [
      "Data Science Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2078",
    "question": "Richtig oder Falsch: Data Science Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 11 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Data Science Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 11 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 11,
    "tags": [
      "Data Science Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2079",
    "question": "Was ist Data Science Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 12Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Data Science Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 12Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 12,
    "tags": [
      "Data Science Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2080",
    "question": "Richtig oder Falsch: Data Science Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 12Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Data Science Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 12Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 12,
    "tags": [
      "Data Science Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2081",
    "question": "Was ist Redshift?",
    "type": "single",
    "options": [
      "Analyse & Reporting Trennung von Engineering und Analytics Skalierbare End-to -End-Datenpipeline Offizielle Produkt - & Doku -Seiten Google BigQuery https://cloud.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Redshift: Analyse & Reporting Trennung von Engineering und Analytics Skalierbare End-to -End-Datenpipeline Offizielle Produkt - & Doku -Seiten Google BigQuery https://cloud.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 12,
    "tags": [
      "Redshift"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2082",
    "question": "Richtig oder Falsch: Redshift Analyse & Reporting Trennung von Engineering und Analytics Skalierbare End-to -End-Datenpipeline Offizielle Produkt - & Doku -Seiten Google BigQuery https://cloud.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Redshift: Analyse & Reporting Trennung von Engineering und Analytics Skalierbare End-to -End-Datenpipeline Offizielle Produkt - & Doku -Seiten Google BigQuery https://cloud.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 12,
    "tags": [
      "Redshift"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2083",
    "question": "Was ist Klick?",
    "type": "single",
    "options": [
      "und Eventdaten (Logs) Buchungs - bzw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Klick: und Eventdaten (Logs) Buchungs - bzw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 13,
    "tags": [
      "Klick"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2084",
    "question": "Richtig oder Falsch: Klick und Eventdaten (Logs) Buchungs - bzw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Klick: und Eventdaten (Logs) Buchungs - bzw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 13,
    "tags": [
      "Klick"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2085",
    "question": "Was ist Ad-hoc?",
    "type": "single",
    "options": [
      "Analysen durch Analysten perspektivisch Machine-Learning-Modelle einsetzenPraxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 13 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ad-hoc: Analysen durch Analysten perspektivisch Machine-Learning-Modelle einsetzenPraxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 13 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 13,
    "tags": [
      "Ad-hoc"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2086",
    "question": "Richtig oder Falsch: Ad-hoc Analysen durch Analysten perspektivisch Machine-Learning-Modelle einsetzenPraxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 13 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ad-hoc: Analysen durch Analysten perspektivisch Machine-Learning-Modelle einsetzenPraxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 13 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 13,
    "tags": [
      "Ad-hoc"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2087",
    "question": "Was ist Systemen?",
    "type": "single",
    "options": [
      "Google BigQuery Snowflake Amazon Redshift Apache Spark SQL Nutzen Sie dafür offizielle Herstellerseiten und Dokumentationen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Systemen: Google BigQuery Snowflake Amazon Redshift Apache Spark SQL Nutzen Sie dafür offizielle Herstellerseiten und Dokumentationen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 14,
    "tags": [
      "Systemen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2088",
    "question": "Richtig oder Falsch: Systemen Google BigQuery Snowflake Amazon Redshift Apache Spark SQL Nutzen Sie dafür offizielle Herstellerseiten und Dokumentationen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Systemen: Google BigQuery Snowflake Amazon Redshift Apache Spark SQL Nutzen Sie dafür offizielle Herstellerseiten und Dokumentationen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 14,
    "tags": [
      "Systemen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2089",
    "question": "Was ist Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 14 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 14 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 14,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2090",
    "question": "Richtig oder Falsch: Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 14 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 14 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 14,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2091",
    "question": "Was ist Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 15 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 15 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 15,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2092",
    "question": "Richtig oder Falsch: Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 15 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 15 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 15,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2093",
    "question": "Was ist Begründung?",
    "type": "single",
    "options": [
      "Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Begründung: Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Begründung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2094",
    "question": "Richtig oder Falsch: Begründung Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Begründung: Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Begründung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2095",
    "question": "Was ist Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 16 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 16 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2096",
    "question": "Richtig oder Falsch: Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 16 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 16 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2097",
    "question": "Was ist Warum?",
    "type": "single",
    "options": [
      "Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Warum: Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Warum"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2098",
    "question": "Richtig oder Falsch: Warum Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Warum: Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 16,
    "tags": [
      "Warum"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2099",
    "question": "Was ist Begründung?",
    "type": "single",
    "options": [
      "Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Begründung: Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Begründung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2100",
    "question": "Richtig oder Falsch: Begründung Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Begründung: Welches System eignet sich am besten für: a) spontane Ad-hoc -Analysen großer Datenmengen?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Begründung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2101",
    "question": "Was ist Praxisbeispiel?",
    "type": "single",
    "options": [
      "Analyse von Nutzungs- und Buchungsdaten 17 Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 17 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2102",
    "question": "Richtig oder Falsch: Praxisbeispiel Analyse von Nutzungs- und Buchungsdaten 17 Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Praxisbeispiel: Analyse von Nutzungs- und Buchungsdaten 17 Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Praxisbeispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2103",
    "question": "Was ist Warum?",
    "type": "single",
    "options": [
      "Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Warum: Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Warum"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2104",
    "question": "Richtig oder Falsch: Warum Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Warum: Spark SQL kein klassisches Data Warehouse, obwohl SQL verwendet wird?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 17,
    "tags": [
      "Warum"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2105",
    "question": "Was ist Open- Source?",
    "type": "single",
    "options": [
      "Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Open- Source: Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 19,
    "tags": [
      "Open- Source"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2106",
    "question": "Richtig oder Falsch: Open- Source Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Open- Source: Framework zur verteilten Speicherung und Verarbeitung sehr großer Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 19,
    "tags": [
      "Open- Source"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2107",
    "question": "Was ist Zentrale Ziele?",
    "type": "single",
    "options": [
      "Skalierbarkeit Fehlertoleranz Verarbeitung großer Datenmengen auf Clustern WS  Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Zentrale Ziele: Skalierbarkeit Fehlertoleranz Verarbeitung großer Datenmengen auf Clustern WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 19,
    "tags": [
      "Zentrale Ziele"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2108",
    "question": "Richtig oder Falsch: Zentrale Ziele Skalierbarkeit Fehlertoleranz Verarbeitung großer Datenmengen auf Clustern WS  Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Zentrale Ziele: Skalierbarkeit Fehlertoleranz Verarbeitung großer Datenmengen auf Clustern WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 19,
    "tags": [
      "Zentrale Ziele"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2109",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "Jobs Nicht geeignet für: viele kleine Dateien zufällige, häufige Einzelzugriffe klassische transaktionale Workloads (OLTP ) HDFS verarbeitet viel auf einmal – aber nicht schnell einzeln.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: Jobs Nicht geeignet für: viele kleine Dateien zufällige, häufige Einzelzugriffe klassische transaktionale Workloads (OLTP ) HDFS verarbeitet viel auf einmal – aber nicht schnell einzeln.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 20,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2110",
    "question": "Richtig oder Falsch: Batch Jobs Nicht geeignet für: viele kleine Dateien zufällige, häufige Einzelzugriffe klassische transaktionale Workloads (OLTP ) HDFS verarbeitet viel auf einmal – aber nicht schnell einzeln.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: Jobs Nicht geeignet für: viele kleine Dateien zufällige, häufige Einzelzugriffe klassische transaktionale Workloads (OLTP ) HDFS verarbeitet viel auf einmal – aber nicht schnell einzeln.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 20,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2111",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "Verarbeitung sehr großer Datenmengen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: Verarbeitung sehr großer Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 21,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2112",
    "question": "Richtig oder Falsch: Batch Verarbeitung sehr großer Datenmengen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: Verarbeitung sehr großer Datenmengen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 21,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2113",
    "question": "Was ist Input?",
    "type": "single",
    "options": [
      "Daten werden inSplits aufgeteilt 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Input: Daten werden inSplits aufgeteilt 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Input"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2114",
    "question": "Richtig oder Falsch: Input Daten werden inSplits aufgeteilt 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Input: Daten werden inSplits aufgeteilt 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Input"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2115",
    "question": "Was ist Sort?",
    "type": "single",
    "options": [
      "Gruppierung aller Werte pro Key 4.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Sort: Gruppierung aller Werte pro Key 4.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Sort"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2116",
    "question": "Richtig oder Falsch: Sort Gruppierung aller Werte pro Key 4.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Sort: Gruppierung aller Werte pro Key 4.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Sort"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2117",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Phase: Aggregation der Werte pro Key 5.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Phase: Aggregation der Werte pro Key 5.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2118",
    "question": "Richtig oder Falsch: Reduce Phase: Aggregation der Werte pro Key 5.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Phase: Aggregation der Werte pro Key 5.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 22,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2119",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 23,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2120",
    "question": "Richtig oder Falsch: Batch orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: orientiert ) Umständlich füriterative Algorithmen Heute Meist ersetzt durch Apache Spark Konzeptionell weiterhin wichtig WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 23,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2121",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Ansatzes zuüberwinden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Ansatzes zuüberwinden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 25,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2122",
    "question": "Richtig oder Falsch: Reduce Ansatzes zuüberwinden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Ansatzes zuüberwinden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 25,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2123",
    "question": "Was ist Multi?",
    "type": "single",
    "options": [
      "Tenant) WS  Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Multi: Tenant) WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 25,
    "tags": [
      "Multi"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2124",
    "question": "Richtig oder Falsch: Multi Tenant) WS  Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Multi: Tenant) WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 25,
    "tags": [
      "Multi"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2125",
    "question": "Was ist Anwendungs?",
    "type": "single",
    "options": [
      "spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Anwendungs: spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 26,
    "tags": [
      "Anwendungs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2126",
    "question": "Richtig oder Falsch: Anwendungs spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Anwendungs: spezifische Steuerung Aushandlung von Ressourcen und Überwachung der Tasks WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 26,
    "tags": [
      "Anwendungs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2127",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "Einführung 32 Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: Einführung 32 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 32,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2128",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop Einführung 32 Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: Einführung 32 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 32,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2129",
    "question": "Was ist Open?",
    "type": "single",
    "options": [
      "Source -Apache-Framework zur Speicherung und Verarbeitung großer Datenmengen auf Computerclustern.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Open: Source -Apache-Framework zur Speicherung und Verarbeitung großer Datenmengen auf Computerclustern.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Open"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2130",
    "question": "Richtig oder Falsch: Open Source -Apache-Framework zur Speicherung und Verarbeitung großer Datenmengen auf Computerclustern.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Open: Source -Apache-Framework zur Speicherung und Verarbeitung großer Datenmengen auf Computerclustern.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Open"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2131",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2132",
    "question": "Richtig oder Falsch: Hadoop Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: Anwendungen können von einem einzelnen Rechner bis hin zu mehreren tausend Servern skaliert werden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2133",
    "question": "Was ist Apache?",
    "type": "single",
    "options": [
      "Nutch-Projekts entwickelt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Apache: Nutch-Projekts entwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Apache"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2134",
    "question": "Richtig oder Falsch: Apache Nutch-Projekts entwickelt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Apache: Nutch-Projekts entwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 34,
    "tags": [
      "Apache"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2135",
    "question": "Was ist Entwicklungs?",
    "type": "single",
    "options": [
      "und Produktionsplattform unterstützt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Entwicklungs: und Produktionsplattform unterstützt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Entwicklungs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2136",
    "question": "Richtig oder Falsch: Entwicklungs und Produktionsplattform unterstützt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Entwicklungs: und Produktionsplattform unterstützt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Entwicklungs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2137",
    "question": "Was ist Linux?",
    "type": "single",
    "options": [
      "Clustern mit 2000 Knoten demonstriert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Linux: Clustern mit 2000 Knoten demonstriert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Linux"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2138",
    "question": "Richtig oder Falsch: Linux Clustern mit 2000 Knoten demonstriert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Linux: Clustern mit 2000 Knoten demonstriert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Linux"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2139",
    "question": "Was ist Quelle?",
    "type": "single",
    "options": [
      "Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Quelle: Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Quelle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2140",
    "question": "Richtig oder Falsch: Quelle Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Quelle: Hadoop-Dokumentation) macOS Windows  Linux ist die bevorzugte Umgebung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Quelle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2141",
    "question": "Was ist Cluster?",
    "type": "single",
    "options": [
      "Computing konzipiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Cluster: Computing konzipiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Cluster"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2142",
    "question": "Richtig oder Falsch: Cluster Computing konzipiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Cluster: Computing konzipiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Cluster"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2143",
    "question": "Was ist Ressourcen?",
    "type": "single",
    "options": [
      "und Cluster -Management - Werkzeug sowie Verbesserungen an HDFS Hadoop 3.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ressourcen: und Cluster -Management - Werkzeug sowie Verbesserungen an HDFS Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Ressourcen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2144",
    "question": "Richtig oder Falsch: Ressourcen und Cluster -Management - Werkzeug sowie Verbesserungen an HDFS Hadoop 3.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ressourcen: und Cluster -Management - Werkzeug sowie Verbesserungen an HDFS Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Ressourcen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2145",
    "question": "Was ist Linux?",
    "type": "single",
    "options": [
      "die bevorzugte Umgebung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Linux: die bevorzugte Umgebung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Linux"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2146",
    "question": "Richtig oder Falsch: Linux die bevorzugte Umgebung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Linux: die bevorzugte Umgebung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Linux"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2147",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "für Cluster - Computing konzipiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: für Cluster - Computing konzipiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2148",
    "question": "Richtig oder Falsch: Hadoop für Cluster - Computing konzipiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: für Cluster - Computing konzipiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 35,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2149",
    "question": "Was ist Performance?",
    "type": "single",
    "options": [
      "Optimierungen• Stabilisierung• Cloud - & Container -Verbesserungen Weit verbreitet Hadoop 3.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Performance: Optimierungen• Stabilisierung• Cloud - & Container -Verbesserungen Weit verbreitet Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 36,
    "tags": [
      "Performance"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2150",
    "question": "Richtig oder Falsch: Performance Optimierungen• Stabilisierung• Cloud - & Container -Verbesserungen Weit verbreitet Hadoop 3.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Performance: Optimierungen• Stabilisierung• Cloud - & Container -Verbesserungen Weit verbreitet Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 36,
    "tags": [
      "Performance"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2151",
    "question": "Was ist Weitere Performance?",
    "type": "single",
    "options": [
      "Verbesserungen• Robustere High Availability • Bessere Ressourcennutzung• GPU - Support Aktueller Standard Aktuell 2025 Apache Hadoop 3.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Weitere Performance: Verbesserungen• Robustere High Availability • Bessere Ressourcennutzung• GPU - Support Aktueller Standard Aktuell 2025 Apache Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 36,
    "tags": [
      "Weitere Performance"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2152",
    "question": "Richtig oder Falsch: Weitere Performance Verbesserungen• Robustere High Availability • Bessere Ressourcennutzung• GPU - Support Aktueller Standard Aktuell 2025 Apache Hadoop 3.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Weitere Performance: Verbesserungen• Robustere High Availability • Bessere Ressourcennutzung• GPU - Support Aktueller Standard Aktuell 2025 Apache Hadoop 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 36,
    "tags": [
      "Weitere Performance"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2153",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 37,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2154",
    "question": "Richtig oder Falsch: Reduce Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Tasks pro Maschine Die Zahlen zeigen die Größenordnung klassischer Hadoop- Cluster – moderne Systeme sind deutlich leistungsfähiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 37,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2155",
    "question": "Was ist Systeme?",
    "type": "single",
    "options": [
      "deutlich leistungsfähiger.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Systeme: deutlich leistungsfähiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 37,
    "tags": [
      "Systeme"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2156",
    "question": "Richtig oder Falsch: Systeme deutlich leistungsfähiger.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Systeme: deutlich leistungsfähiger.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 37,
    "tags": [
      "Systeme"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2157",
    "question": "Was ist Speicher?",
    "type": "single",
    "options": [
      "und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Speicher: und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 39,
    "tags": [
      "Speicher"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2158",
    "question": "Richtig oder Falsch: Speicher und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Speicher: und RechensystemenHadoop – distributed data storage Compute Compute Compute OS OS OS Data Movement Storage By Apache Software Foundation [Apache License 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 39,
    "tags": [
      "Speicher"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2159",
    "question": "Was ist Node?",
    "type": "single",
    "options": [
      "Der Master -Server, der den Namespace des Dateisystems verwaltet und den Zugriff der Clients auf Dateien steuert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Node: Der Master -Server, der den Namespace des Dateisystems verwaltet und den Zugriff der Clients auf Dateien steuert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Node"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2160",
    "question": "Richtig oder Falsch: Node Der Master -Server, der den Namespace des Dateisystems verwaltet und den Zugriff der Clients auf Dateien steuert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Node: Der Master -Server, der den Namespace des Dateisystems verwaltet und den Zugriff der Clients auf Dateien steuert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Node"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2161",
    "question": "Was ist Namespace?",
    "type": "single",
    "options": [
      "Informationen ( FsImage) und Transaktionsprotokollen (Edit Logs).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Namespace: Informationen ( FsImage) und Transaktionsprotokollen (Edit Logs).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Namespace"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2162",
    "question": "Richtig oder Falsch: Namespace Informationen ( FsImage) und Transaktionsprotokollen (Edit Logs).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Namespace: Informationen ( FsImage) und Transaktionsprotokollen (Edit Logs).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Namespace"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2163",
    "question": "Was ist Kein Backup?",
    "type": "single",
    "options": [
      "oder Ersatz -NameNode.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Kein Backup: oder Ersatz -NameNode.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Kein Backup"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2164",
    "question": "Richtig oder Falsch: Kein Backup oder Ersatz -NameNode.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Kein Backup: oder Ersatz -NameNode.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 41,
    "tags": [
      "Kein Backup"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2165",
    "question": "Was ist Reduce Engine?",
    "type": "single",
    "options": [
      "JobTracker : Der Master -Knoten, der die Verteilung und Überwachung der MapReduce- Tasks auf die Worker -Knoten koordiniert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce Engine: JobTracker : Der Master -Knoten, der die Verteilung und Überwachung der MapReduce- Tasks auf die Worker -Knoten koordiniert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 42,
    "tags": [
      "Reduce Engine"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2166",
    "question": "Richtig oder Falsch: Reduce Engine JobTracker : Der Master -Knoten, der die Verteilung und Überwachung der MapReduce- Tasks auf die Worker -Knoten koordiniert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce Engine: JobTracker : Der Master -Knoten, der die Verteilung und Überwachung der MapReduce- Tasks auf die Worker -Knoten koordiniert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 42,
    "tags": [
      "Reduce Engine"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2167",
    "question": "Was ist Tracker?",
    "type": "single",
    "options": [
      "Worker -Knoten, die die vom JobTracker zugewiesenen Tasks ausführen und diesem fortlaufend Statusinformationen melden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Tracker: Worker -Knoten, die die vom JobTracker zugewiesenen Tasks ausführen und diesem fortlaufend Statusinformationen melden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 42,
    "tags": [
      "Tracker"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2168",
    "question": "Richtig oder Falsch: Tracker Worker -Knoten, die die vom JobTracker zugewiesenen Tasks ausführen und diesem fortlaufend Statusinformationen melden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Tracker: Worker -Knoten, die die vom JobTracker zugewiesenen Tasks ausführen und diesem fortlaufend Statusinformationen melden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 42,
    "tags": [
      "Tracker"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2169",
    "question": "Was ist Ausfälle?",
    "type": "single",
    "options": [
      "keine Ausnahme, sondern die Regel!",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ausfälle: keine Ausnahme, sondern die Regel!",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Ausfälle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2170",
    "question": "Richtig oder Falsch: Ausfälle keine Ausnahme, sondern die Regel!",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ausfälle: keine Ausnahme, sondern die Regel!",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Ausfälle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2171",
    "question": "Was ist Clustern?",
    "type": "single",
    "options": [
      "nicht die Frage, ob etwas ausfällt, sondern wann.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Clustern: nicht die Frage, ob etwas ausfällt, sondern wann.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Clustern"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2172",
    "question": "Richtig oder Falsch: Clustern nicht die Frage, ob etwas ausfällt, sondern wann.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Clustern: nicht die Frage, ob etwas ausfällt, sondern wann.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 43,
    "tags": [
      "Clustern"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2173",
    "question": "Was ist Schema?",
    "type": "single",
    "options": [
      "on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Schema: on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 44,
    "tags": [
      "Schema"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2174",
    "question": "Richtig oder Falsch: Schema on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Schema: on-Write, strikt, statischSchema Schema- on-Read, flexibelSchema- on-Read / Schema- Evolution Sehr schnelles Lesen & Schreiben (transaktional)Performance- Fokus Optimiert für Batch- SchreibenOptimiert für Analytics (In- Memory, Caching) Strukturiert Datenstruktur Semi - / unstrukturiertStrukturiert, semi - & unstrukturiert GB – TB Datenvolumen PB PB – EB Sehr hoch (ACID) Datenintegrität EingeschränktHoch (ACID via Delta Lake / Iceberg / Hudi) Verarbeitung meist außerhalb (ETL, DW)DatenverarbeitungVerarbeitung nahe am Speicher (Data Locality )Compute & Storage entkoppelt, elastisch Begrenzt, vertikal / begrenzt horizontalSkalierbarkeit Hoch, nahezu linearSehr hoch, elastisch (Cloud-native) SQL (klassisch) Abfragesprache MapReduce, HiveSQL (Spark SQL, Trino , Presto) OLTP, klassische BI, Reporting AnwendungsfälleBatch -Processing, Offline- AnalyticsModerne Analytics, ML, BI, Streaming On-Premises Deployment On-Premises Cloud / Hybrid Relationale DB ( Postgres , Oracle, MySQL)Typische Systeme HDFS + MapReduce S3 / ADLS + Spark / Trino https://cdn.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 44,
    "tags": [
      "Schema"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2175",
    "question": "Was ist Big Data Analytics Beispiel?",
    "type": "single",
    "options": [
      "Predictive Maintenance 45Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Beispiel: Predictive Maintenance 45Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 45,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2176",
    "question": "Richtig oder Falsch: Big Data Analytics Beispiel Predictive Maintenance 45Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Beispiel: Predictive Maintenance 45Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 45,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2177",
    "question": "Was ist Big Data Analytics Beispiel?",
    "type": "single",
    "options": [
      "Predictive Maintenance 46Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Beispiel: Predictive Maintenance 46Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 46,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2178",
    "question": "Richtig oder Falsch: Big Data Analytics Beispiel Predictive Maintenance 46Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Beispiel: Predictive Maintenance 46Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 46,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2179",
    "question": "Was ist Big Data Analytics Beispiel?",
    "type": "single",
    "options": [
      "Predictive Maintenance 47Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Beispiel: Predictive Maintenance 47Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 47,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2180",
    "question": "Richtig oder Falsch: Big Data Analytics Beispiel Predictive Maintenance 47Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Beispiel: Predictive Maintenance 47Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 47,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2181",
    "question": "Was ist Big Data Analytics Beispiel?",
    "type": "single",
    "options": [
      "Predictive Maintenance 48Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Beispiel: Predictive Maintenance 48Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 48,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2182",
    "question": "Richtig oder Falsch: Big Data Analytics Beispiel Predictive Maintenance 48Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Beispiel: Predictive Maintenance 48Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 48,
    "tags": [
      "Big Data Analytics Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2183",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 51 Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 51 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 50,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2184",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 51 Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 51 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 50,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2185",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 52Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 52Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2186",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 52Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 52Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2187",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2188",
    "question": "Richtig oder Falsch: Hadoop Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: Clusters Optimiert für die verteilte, fehlertolerante Speicherung großer Datenmengen Dateien werden in große Blöcke aufgeteilt (typischerweise 128 MB oder 256 MB) Jeder Block wird standardmäßig auf mindestens drei Knoten repliziert (zur Erhöhung von Verfügbarkeit und Fehlertoleranz)  Fällt ein Knoten aus, werden dessen Blöcke automatisch auf andere Knoten neu repliziert Hauptanwendungsfall sind große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2189",
    "question": "Was ist Rack?",
    "type": "single",
    "options": [
      "Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Rack: Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Rack"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2190",
    "question": "Richtig oder Falsch: Rack Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Rack: Awareness Das System kennt die Topologie des Clusters(Position der Knoten und deren Netzwerkzuordnung) Datenblöcke werden so über die Knoten verteilt, dass Ausfallsicherheit und Zugriffperformance optimiert werden (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Rack"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2191",
    "question": "Was ist Hauptanwendungsfall?",
    "type": "single",
    "options": [
      "große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hauptanwendungsfall: große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Hauptanwendungsfall"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2192",
    "question": "Richtig oder Falsch: Hauptanwendungsfall große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hauptanwendungsfall: große Dateien; viele kleine Dateien werden ineffizient unterstützt und sollten z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 51,
    "tags": [
      "Hauptanwendungsfall"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2193",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 53Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 53Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 52,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2194",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 53Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 53Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 52,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2195",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 54 Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 54 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 53,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2196",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 54 Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 54 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 53,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2197",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 55 Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 55 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2198",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 55 Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 55 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2199",
    "question": "Was ist Job Execution?",
    "type": "single",
    "options": [
      "Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Job Execution: Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Job Execution"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2200",
    "question": "Richtig oder Falsch: Job Execution Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Job Execution: Ein Client übermittelt einen MapReduce- Job an den JobTracker , der verfügbare TaskTracker -Knoten ermittelt und die Tasks zuweist.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Job Execution"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2201",
    "question": "Was ist Map- Phase?",
    "type": "single",
    "options": [
      "Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Map- Phase: Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Map- Phase"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2202",
    "question": "Richtig oder Falsch: Map- Phase Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Map- Phase: Die Eingabedaten werden verarbeitet und in Schlüssel -Wert -Paare (Key -Value Pairs) transformiert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Map- Phase"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2203",
    "question": "Was ist Reduce- Phase?",
    "type": "single",
    "options": [
      "Der Reducer verarbeitet die sortierten Ergebnisse der Map- Phase und erzeugt das endgültige Ergebnis.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce- Phase: Der Reducer verarbeitet die sortierten Ergebnisse der Map- Phase und erzeugt das endgültige Ergebnis.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Reduce- Phase"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2204",
    "question": "Richtig oder Falsch: Reduce- Phase Der Reducer verarbeitet die sortierten Ergebnisse der Map- Phase und erzeugt das endgültige Ergebnis.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce- Phase: Der Reducer verarbeitet die sortierten Ergebnisse der Map- Phase und erzeugt das endgültige Ergebnis.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Reduce- Phase"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2205",
    "question": "Was ist Fault Tolerance?",
    "type": "single",
    "options": [
      "HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Fault Tolerance: HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Fault Tolerance"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2206",
    "question": "Richtig oder Falsch: Fault Tolerance HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Fault Tolerance: HDFS ist fehlertolerant ausgelegt, indem Datenblöcke automatisch auf mehrere Knoten repliziert werden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Fault Tolerance"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2207",
    "question": "Was ist Festplatte?",
    "type": "single",
    "options": [
      "Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Festplatte: Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Festplatte"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2208",
    "question": "Richtig oder Falsch: Festplatte Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Festplatte: Änderungen werden in einem Transaktionsprotokoll (EditLog) festgehalten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Festplatte"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2209",
    "question": "Was ist Dateisystem?",
    "type": "single",
    "options": [
      "Namespace wird in der Datei FsImage serialisiert gespeichert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Dateisystem: Namespace wird in der Datei FsImage serialisiert gespeichert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Dateisystem"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2210",
    "question": "Richtig oder Falsch: Dateisystem Namespace wird in der Datei FsImage serialisiert gespeichert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Dateisystem: Namespace wird in der Datei FsImage serialisiert gespeichert.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 54,
    "tags": [
      "Dateisystem"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2211",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 56Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 56Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 55,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2212",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 56Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 56Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 55,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2213",
    "question": "Was ist Big Data Analytics Hadoop?",
    "type": "single",
    "options": [
      "HDFS 57Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop: HDFS 57Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2214",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop HDFS 57Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop: HDFS 57Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Big Data Analytics Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2215",
    "question": "Was ist Cluster?",
    "type": "single",
    "options": [
      "Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Cluster: Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Cluster"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2216",
    "question": "Richtig oder Falsch: Cluster Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Cluster: Management Hadoop- Cluster werden häufig mit Management- und Monitoring- Werkzeugen wie Apache Ambari verwaltet.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Cluster"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2217",
    "question": "Was ist Cloud?",
    "type": "single",
    "options": [
      "Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Cloud: Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Cloud"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2218",
    "question": "Richtig oder Falsch: Cloud Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Cloud: Umgebungen häufig durch cloud- native Monitoring- und Managementlösungen ersetzt (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 56,
    "tags": [
      "Cloud"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2219",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "Ökosystems, die mit Hadoop 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: Ökosystems, die mit Hadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2220",
    "question": "Richtig oder Falsch: Hadoop Ökosystems, die mit Hadoop 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: Ökosystems, die mit Hadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2221",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Programmiermodells zu überwinden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Programmiermodells zu überwinden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2222",
    "question": "Richtig oder Falsch: Reduce Programmiermodells zu überwinden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Programmiermodells zu überwinden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2223",
    "question": "Was ist Datenverarbeitungs?",
    "type": "single",
    "options": [
      "Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Datenverarbeitungs: Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Datenverarbeitungs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2224",
    "question": "Richtig oder Falsch: Datenverarbeitungs Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Datenverarbeitungs: Engines wie MapReduce, Apache Tez und Apache Spark parallel auf demselben Hadoop -Cluster betrieben werden können.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Datenverarbeitungs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2225",
    "question": "Was ist Verbesserte Clusterauslastung?",
    "type": "single",
    "options": [
      "YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verbesserte Clusterauslastung: YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Verbesserte Clusterauslastung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2226",
    "question": "Richtig oder Falsch: Verbesserte Clusterauslastung YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verbesserte Clusterauslastung: YARN ermöglicht eine dynamische Zuweisung von Ressourcen entsprechend den Anforderungen der Anwendungen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Verbesserte Clusterauslastung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2227",
    "question": "Was ist Slot?",
    "type": "single",
    "options": [
      "basierten Modell des ursprünglichen MapReduce -Frameworks.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Slot: basierten Modell des ursprünglichen MapReduce -Frameworks.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Slot"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2228",
    "question": "Richtig oder Falsch: Slot basierten Modell des ursprünglichen MapReduce -Frameworks.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Slot: basierten Modell des ursprünglichen MapReduce -Frameworks.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Slot"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2229",
    "question": "Was ist Workloads?",
    "type": "single",
    "options": [
      "YARN unterstützt Batch -Verarbeitung, interaktive Abfragen und Streaming-/ Near -Realtime -Workloads, die im ursprünglichen Hadoop -1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Workloads: YARN unterstützt Batch -Verarbeitung, interaktive Abfragen und Streaming-/ Near -Realtime -Workloads, die im ursprünglichen Hadoop -1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Workloads"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2230",
    "question": "Richtig oder Falsch: Workloads YARN unterstützt Batch -Verarbeitung, interaktive Abfragen und Streaming-/ Near -Realtime -Workloads, die im ursprünglichen Hadoop -1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Workloads: YARN unterstützt Batch -Verarbeitung, interaktive Abfragen und Streaming-/ Near -Realtime -Workloads, die im ursprünglichen Hadoop -1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Workloads"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2231",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Modell nicht oder nur eingeschränkt möglich waren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Modell nicht oder nur eingeschränkt möglich waren.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2232",
    "question": "Richtig oder Falsch: Reduce Modell nicht oder nur eingeschränkt möglich waren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Modell nicht oder nur eingeschränkt möglich waren.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2233",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "System zu einer allgemeinen Plattform für verteilte Datenverarbeitung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: System zu einer allgemeinen Plattform für verteilte Datenverarbeitung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2234",
    "question": "Richtig oder Falsch: Reduce System zu einer allgemeinen Plattform für verteilte Datenverarbeitung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: System zu einer allgemeinen Plattform für verteilte Datenverarbeitung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 57,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2235",
    "question": "Was ist Master?",
    "type": "single",
    "options": [
      "Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Master: Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Master"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2236",
    "question": "Richtig oder Falsch: Master Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Master: Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Master"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2237",
    "question": "Was ist Hauptkomponenten?",
    "type": "single",
    "options": [
      "dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hauptkomponenten: dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Hauptkomponenten"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2238",
    "question": "Richtig oder Falsch: Hauptkomponenten dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hauptkomponenten: dem Schedulerdem ApplicationManager SchedulerDer Scheduler ist für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Hauptkomponenten"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2239",
    "question": "Was ist Manager?",
    "type": "single",
    "options": [
      "die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Manager: die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Manager"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2240",
    "question": "Richtig oder Falsch: Manager die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Manager: die zentrale Master -Komponente von YARN, die über alle verfügbaren Cluster -Ressourcen (CPU, Speicher usw.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Manager"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2241",
    "question": "Was ist Scheduler?",
    "type": "single",
    "options": [
      "für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Scheduler: für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Scheduler"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2242",
    "question": "Richtig oder Falsch: Scheduler für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Scheduler: für die Zuweisung von Ressourcen an laufende Anwendungen verantwortlich.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 58,
    "tags": [
      "Scheduler"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2243",
    "question": "Was ist Status?",
    "type": "single",
    "options": [
      "und Ressourcendaten an den ResourceManager .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Status: und Ressourcendaten an den ResourceManager .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Status"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2244",
    "question": "Richtig oder Falsch: Status und Ressourcendaten an den ResourceManager .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Status: und Ressourcendaten an den ResourceManager .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Status"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2245",
    "question": "Was ist Manager?",
    "type": "single",
    "options": [
      "ein Agent auf jedem Cluster -Knoten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Manager: ein Agent auf jedem Cluster -Knoten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Manager"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2246",
    "question": "Richtig oder Falsch: Manager ein Agent auf jedem Cluster -Knoten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Manager: ein Agent auf jedem Cluster -Knoten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 59,
    "tags": [
      "Manager"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2247",
    "question": "Was ist Ressourcen?",
    "type": "single",
    "options": [
      "Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ressourcen: Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Ressourcen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2248",
    "question": "Richtig oder Falsch: Ressourcen Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ressourcen: Container mit dem Scheduler (über den ResourceManager ), die Überwachung des Status der zugewiesenen Container, das Monitoring des Fortschritts der Anwendung, sowie das Handling von Fehlern innerhalb der Anwendung.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Ressourcen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2249",
    "question": "Was ist Master?",
    "type": "single",
    "options": [
      "eine instanzierte, frameworkspezifische Komponente (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Master: eine instanzierte, frameworkspezifische Komponente (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Master"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2250",
    "question": "Richtig oder Falsch: Master eine instanzierte, frameworkspezifische Komponente (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Master: eine instanzierte, frameworkspezifische Komponente (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 60,
    "tags": [
      "Master"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2251",
    "question": "Was ist Betriebssystem?",
    "type": "single",
    "options": [
      "Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Betriebssystem: Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Betriebssystem"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2252",
    "question": "Richtig oder Falsch: Betriebssystem Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Betriebssystem: Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Betriebssystem"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2253",
    "question": "Was ist Container?",
    "type": "single",
    "options": [
      "isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Container: isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Container"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2254",
    "question": "Richtig oder Falsch: Container isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Container: isolierte Ausführungseinheiten, jedoch keine Virtualisierung im Sinne von VMs oder Containern wie Docker .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Container"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2255",
    "question": "Was ist Container?",
    "type": "single",
    "options": [
      "kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Container: kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Container"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2256",
    "question": "Richtig oder Falsch: Container kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Container: kein Betriebssystem -Container , sondern eine Ressourcenzuteilung , die von NodeManagern überwacht wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 61,
    "tags": [
      "Container"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2257",
    "question": "Was ist Multi?",
    "type": "single",
    "options": [
      "Tenant ) Datenverarbeitungsplattform weiterentwickelt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Multi: Tenant ) Datenverarbeitungsplattform weiterentwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Multi"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2258",
    "question": "Richtig oder Falsch: Multi Tenant ) Datenverarbeitungsplattform weiterentwickelt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Multi: Tenant ) Datenverarbeitungsplattform weiterentwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Multi"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2259",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "MapReduce- Paradigma dar, das primär für Batch-Verarbeitung mit MapReduce konzipiert war.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: MapReduce- Paradigma dar, das primär für Batch-Verarbeitung mit MapReduce konzipiert war.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2260",
    "question": "Richtig oder Falsch: Hadoop MapReduce- Paradigma dar, das primär für Batch-Verarbeitung mit MapReduce konzipiert war.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: MapReduce- Paradigma dar, das primär für Batch-Verarbeitung mit MapReduce konzipiert war.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2261",
    "question": "Was ist Manager?",
    "type": "single",
    "options": [
      "für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Manager: für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Manager"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2262",
    "question": "Richtig oder Falsch: Manager für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Manager: für die clusterweite Ressourcenplanung zuständig, während die NodeManager die Ausführung auf den einzelnen Rechenknoten übernehmen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 62,
    "tags": [
      "Manager"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2263",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Frameworks (Hadoop 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Frameworks (Hadoop 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2264",
    "question": "Richtig oder Falsch: Reduce Frameworks (Hadoop 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Frameworks (Hadoop 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2265",
    "question": "Was ist Task?",
    "type": "single",
    "options": [
      "Planung Überwachung von Jobs Fehlerbehandlung und Wiederherstellung In neueren Hadoop-Versionen (ab Hadoop 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Task: Planung Überwachung von Jobs Fehlerbehandlung und Wiederherstellung In neueren Hadoop-Versionen (ab Hadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Task"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2266",
    "question": "Richtig oder Falsch: Task Planung Überwachung von Jobs Fehlerbehandlung und Wiederherstellung In neueren Hadoop-Versionen (ab Hadoop 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Task: Planung Überwachung von Jobs Fehlerbehandlung und Wiederherstellung In neueren Hadoop-Versionen (ab Hadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Task"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2267",
    "question": "Was ist Tracker?",
    "type": "single",
    "options": [
      "eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Tracker: eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Tracker"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2268",
    "question": "Richtig oder Falsch: Tracker eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Tracker: eine zentrale Komponente des MapReduce-Frameworks (Hadoop 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 63,
    "tags": [
      "Tracker"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2269",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Schicht (Datenverarbeitung) und eine HDFS -Schicht (Datenspeicherung).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Schicht (Datenverarbeitung) und eine HDFS -Schicht (Datenspeicherung).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 64,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2270",
    "question": "Richtig oder Falsch: Reduce Schicht (Datenverarbeitung) und eine HDFS -Schicht (Datenspeicherung).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Schicht (Datenverarbeitung) und eine HDFS -Schicht (Datenspeicherung).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 64,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2271",
    "question": "Was ist Big Data Analytics Hadoop Ecosystem?",
    "type": "single",
    "options": [
      "HDFS 66 Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Hadoop Ecosystem: HDFS 66 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Big Data Analytics Hadoop Ecosystem"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2272",
    "question": "Richtig oder Falsch: Big Data Analytics Hadoop Ecosystem HDFS 66 Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Hadoop Ecosystem: HDFS 66 Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Big Data Analytics Hadoop Ecosystem"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2273",
    "question": "Was ist Dateisystem?",
    "type": "single",
    "options": [
      "Namespace und die Metadaten (Zuordnung von Dateien zu Datenblöcken).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Dateisystem: Namespace und die Metadaten (Zuordnung von Dateien zu Datenblöcken).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Dateisystem"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2274",
    "question": "Richtig oder Falsch: Dateisystem Namespace und die Metadaten (Zuordnung von Dateien zu Datenblöcken).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Dateisystem: Namespace und die Metadaten (Zuordnung von Dateien zu Datenblöcken).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Dateisystem"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2275",
    "question": "Was ist Koordiniert Lese?",
    "type": "single",
    "options": [
      "und Schreibzugriffe der Clients auf die DataNodes .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Koordiniert Lese: und Schreibzugriffe der Clients auf die DataNodes .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Koordiniert Lese"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2276",
    "question": "Richtig oder Falsch: Koordiniert Lese und Schreibzugriffe der Clients auf die DataNodes .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Koordiniert Lese: und Schreibzugriffe der Clients auf die DataNodes .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Koordiniert Lese"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2277",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "HA-Modus eingesetzt wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: HA-Modus eingesetzt wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2278",
    "question": "Richtig oder Falsch: Hadoop HA-Modus eingesetzt wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: HA-Modus eingesetzt wird.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2279",
    "question": "Was ist Hadoop?",
    "type": "single",
    "options": [
      "Cluster für Datenübertragung und Client -Zugriffe.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hadoop: Cluster für Datenübertragung und Client -Zugriffe.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2280",
    "question": "Richtig oder Falsch: Hadoop Cluster für Datenübertragung und Client -Zugriffe.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hadoop: Cluster für Datenübertragung und Client -Zugriffe.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Hadoop"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2281",
    "question": "Was ist Spark?",
    "type": "single",
    "options": [
      "Clients) sowie Werkzeuge zur Clusterverwaltung aus.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Spark: Clients) sowie Werkzeuge zur Clusterverwaltung aus.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Spark"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2282",
    "question": "Richtig oder Falsch: Spark Clients) sowie Werkzeuge zur Clusterverwaltung aus.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Spark: Clients) sowie Werkzeuge zur Clusterverwaltung aus.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Spark"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2283",
    "question": "Was ist Node?",
    "type": "single",
    "options": [
      "kein Teil der Datenverarbeitung, sondern die Schnittstelle zwischen Nutzern und Cluster.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Node: kein Teil der Datenverarbeitung, sondern die Schnittstelle zwischen Nutzern und Cluster.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Node"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2284",
    "question": "Richtig oder Falsch: Node kein Teil der Datenverarbeitung, sondern die Schnittstelle zwischen Nutzern und Cluster.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Node: kein Teil der Datenverarbeitung, sondern die Schnittstelle zwischen Nutzern und Cluster.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 65,
    "tags": [
      "Node"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2285",
    "question": "Was ist Die Client?",
    "type": "single",
    "options": [
      "API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Die Client: API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 66,
    "tags": [
      "Die Client"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2286",
    "question": "Richtig oder Falsch: Die Client API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Die Client: API berechnet anhand des Dateizeigers (Offset), welcher Datenblock benötigt wird, und sendet eine Anfrage an den NameNode.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 66,
    "tags": [
      "Die Client"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2287",
    "question": "Was ist Translation?",
    "type": "single",
    "options": [
      "Memory -(TM) -Datenbanken.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Translation: Memory -(TM) -Datenbanken.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Translation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2288",
    "question": "Richtig oder Falsch: Translation Memory -(TM) -Datenbanken.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Translation: Memory -(TM) -Datenbanken.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Translation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2289",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Programmiermodell verarbeitet diese großen Datenmengen, um Übereinstimmungen und Muster zu identifizieren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Programmiermodell verarbeitet diese großen Datenmengen, um Übereinstimmungen und Muster zu identifizieren.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2290",
    "question": "Richtig oder Falsch: Reduce Programmiermodell verarbeitet diese großen Datenmengen, um Übereinstimmungen und Muster zu identifizieren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Programmiermodell verarbeitet diese großen Datenmengen, um Übereinstimmungen und Muster zu identifizieren.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2291",
    "question": "Was ist Machine?",
    "type": "single",
    "options": [
      "Learning - Bibliotheken wie Apache Mahout oder Spark MLlib unterstützt Hadoop das Training maschineller Übersetzungsmodelle auf Parallelkorpora.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine: Learning - Bibliotheken wie Apache Mahout oder Spark MLlib unterstützt Hadoop das Training maschineller Übersetzungsmodelle auf Parallelkorpora.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Machine"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2292",
    "question": "Richtig oder Falsch: Machine Learning - Bibliotheken wie Apache Mahout oder Spark MLlib unterstützt Hadoop das Training maschineller Übersetzungsmodelle auf Parallelkorpora.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine: Learning - Bibliotheken wie Apache Mahout oder Spark MLlib unterstützt Hadoop das Training maschineller Übersetzungsmodelle auf Parallelkorpora.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Machine"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2293",
    "question": "Was ist Machine- Translation?",
    "type": "single",
    "options": [
      "Modelle entwickeln und kontinuierlich verbessern.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine- Translation: Modelle entwickeln und kontinuierlich verbessern.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Machine- Translation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2294",
    "question": "Richtig oder Falsch: Machine- Translation Modelle entwickeln und kontinuierlich verbessern.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine- Translation: Modelle entwickeln und kontinuierlich verbessern.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Machine- Translation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2295",
    "question": "Was ist Datensätze?",
    "type": "single",
    "options": [
      "häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Datensätze: häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Datensätze"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2296",
    "question": "Richtig oder Falsch: Datensätze häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Datensätze: häufig zu groß, als dass sie von klassischen relationalen Datenbanksystemen (RDBMS) effizient verarbeitet werden könnten – insbesondere bei unstrukturierten Textdaten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 70,
    "tags": [
      "Datensätze"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2297",
    "question": "Was ist Cloud?",
    "type": "single",
    "options": [
      "Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Cloud: Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 74,
    "tags": [
      "Cloud"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2298",
    "question": "Richtig oder Falsch: Cloud Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Cloud: Ressourcen Kosteneffizienz Bedarfsgerechte Ressourcennutzung Geringere Kosten als klassische RDBMS bei großen Datenmengen Besonders geeignet für stark wachsende TextdatenErgebnis (Outcome) Höhere operative Effizienz Konsistentere und qualitativ bessere Übersetzungen Schnellere Analyse- und Trainingszyklen Nachhaltiger Wettbewerbsvorteil Zusammenfassung Hadoop bildet den Data Lake, Spark liefert die Intelligenz darüber.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 74,
    "tags": [
      "Cloud"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2299",
    "question": "Was ist Task?",
    "type": "single",
    "options": [
      "Anfragen an die ausgewählten TaskTracker .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Task: Anfragen an die ausgewählten TaskTracker .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 79,
    "tags": [
      "Task"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2300",
    "question": "Richtig oder Falsch: Task Anfragen an die ausgewählten TaskTracker .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Task: Anfragen an die ausgewählten TaskTracker .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 79,
    "tags": [
      "Task"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2301",
    "question": "Was ist Jeder Reduce?",
    "type": "single",
    "options": [
      "Task liest die Zwischenergebnisse (Partitionen) remote, führt die Reduce- Funktion aus und schreibt die aggregierten Key -Value- Ergebnisse in die Ausgabedatei(eine Ausgabedatei pro Reducer ).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Jeder Reduce: Task liest die Zwischenergebnisse (Partitionen) remote, führt die Reduce- Funktion aus und schreibt die aggregierten Key -Value- Ergebnisse in die Ausgabedatei(eine Ausgabedatei pro Reducer ).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 79,
    "tags": [
      "Jeder Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2302",
    "question": "Richtig oder Falsch: Jeder Reduce Task liest die Zwischenergebnisse (Partitionen) remote, führt die Reduce- Funktion aus und schreibt die aggregierten Key -Value- Ergebnisse in die Ausgabedatei(eine Ausgabedatei pro Reducer ).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Jeder Reduce: Task liest die Zwischenergebnisse (Partitionen) remote, führt die Reduce- Funktion aus und schreibt die aggregierten Key -Value- Ergebnisse in die Ausgabedatei(eine Ausgabedatei pro Reducer ).",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 79,
    "tags": [
      "Jeder Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2303",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Schicht (Datenverarbeitung + Ressourcenmanagement) HDFS -Schicht (Datenspeicherung)MapReduce HDFSHadoop 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Schicht (Datenverarbeitung + Ressourcenmanagement) HDFS -Schicht (Datenspeicherung)MapReduce HDFSHadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 80,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2304",
    "question": "Richtig oder Falsch: Reduce Schicht (Datenverarbeitung + Ressourcenmanagement) HDFS -Schicht (Datenspeicherung)MapReduce HDFSHadoop 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Schicht (Datenverarbeitung + Ressourcenmanagement) HDFS -Schicht (Datenspeicherung)MapReduce HDFSHadoop 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 80,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2305",
    "question": "Was ist Einfaches Beispiel?",
    "type": "single",
    "options": [
      "Zählen, wie oft jedes Wort in einem Textdokument vorkommt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Einfaches Beispiel: Zählen, wie oft jedes Wort in einem Textdokument vorkommt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 82,
    "tags": [
      "Einfaches Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2306",
    "question": "Richtig oder Falsch: Einfaches Beispiel Zählen, wie oft jedes Wort in einem Textdokument vorkommt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Einfaches Beispiel: Zählen, wie oft jedes Wort in einem Textdokument vorkommt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 82,
    "tags": [
      "Einfaches Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2307",
    "question": "Was ist Value?",
    "type": "single",
    "options": [
      "Die Anzahl, wie oft dieses Wort vorkommt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Value: Die Anzahl, wie oft dieses Wort vorkommt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 82,
    "tags": [
      "Value"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2308",
    "question": "Richtig oder Falsch: Value Die Anzahl, wie oft dieses Wort vorkommt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Value: Die Anzahl, wie oft dieses Wort vorkommt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 82,
    "tags": [
      "Value"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2309",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 83,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2310",
    "question": "Richtig oder Falsch: Reduce Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Ausführunga)sind die Datenmengen deutlich größer, und b)der Prozess umfasst die Verteilung der Aufgaben auf mehrere Knoten eines Clusters, um eine parallele Verarbeitung zu ermöglichen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 83,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2311",
    "question": "Was ist Teilprogrammen?",
    "type": "single",
    "options": [
      "Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Teilprogrammen: Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Teilprogrammen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2312",
    "question": "Richtig oder Falsch: Teilprogrammen Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Teilprogrammen: Map-Task M Reduce-Task R Algorithmus (vereinfacht) 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Teilprogrammen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2313",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Tasks R auf ausgewählten Knoten aus.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Tasks R auf ausgewählten Knoten aus.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2314",
    "question": "Richtig oder Falsch: Reduce Tasks R auf ausgewählten Knoten aus.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Tasks R auf ausgewählten Knoten aus.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2315",
    "question": "Was ist Reduce?",
    "type": "single",
    "options": [
      "Phase, die das Endergebnis Y bilden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Reduce: Phase, die das Endergebnis Y bilden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Reduce"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2316",
    "question": "Richtig oder Falsch: Reduce Phase, die das Endergebnis Y bilden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Reduce: Phase, die das Endergebnis Y bilden.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 84,
    "tags": [
      "Reduce"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2317",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 91Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 91Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2318",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 91Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 91Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2319",
    "question": "Was ist Python?",
    "type": "single",
    "options": [
      "Programm, das Texte zeilenweise aus einer Datei einliest.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Python: Programm, das Texte zeilenweise aus einer Datei einliest.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Python"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2320",
    "question": "Richtig oder Falsch: Python Programm, das Texte zeilenweise aus einer Datei einliest.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Python: Programm, das Texte zeilenweise aus einer Datei einliest.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 85,
    "tags": [
      "Python"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2321",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 92Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 92Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 86,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2322",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 92Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 92Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 86,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2323",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 93Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 93Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 87,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2324",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 93Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 93Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 87,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2325",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 94Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 94Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 88,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2326",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 94Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 94Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 88,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2327",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 95Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 95Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 89,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2328",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 95Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 95Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 89,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2329",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithm – Python Beispiel 96Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithm – Python Beispiel 96Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 90,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2330",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithm – Python Beispiel 96Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithm – Python Beispiel 96Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 90,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2331",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithmus – Java and Hadoop Beispiel 97Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Beispiel 97Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 91,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2332",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithmus – Java and Hadoop Beispiel 97Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Beispiel 97Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 91,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2333",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithmus – Java and Hadoop Beispiel 98Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Beispiel 98Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 92,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2334",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithmus – Java and Hadoop Beispiel 98Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Beispiel 98Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 92,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2335",
    "question": "Was ist Big Data Analytics Map?",
    "type": "single",
    "options": [
      "Reduce Algorithmus – Java and Hadoop Example 99Big Data & Data Science - Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Example 99Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 93,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2336",
    "question": "Richtig oder Falsch: Big Data Analytics Map Reduce Algorithmus – Java and Hadoop Example 99Big Data & Data Science - Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Big Data Analytics Map: Reduce Algorithmus – Java and Hadoop Example 99Big Data & Data Science - Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 93,
    "tags": [
      "Big Data Analytics Map"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2337",
    "question": "Was ist Weitere Big?",
    "type": "single",
    "options": [
      "Data-Fragestellung: Wie viele Bewertungen gibt es je Bewertungsstufe (Rating)?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Weitere Big: Data-Fragestellung: Wie viele Bewertungen gibt es je Bewertungsstufe (Rating)?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 105,
    "tags": [
      "Weitere Big"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2338",
    "question": "Richtig oder Falsch: Weitere Big Data-Fragestellung: Wie viele Bewertungen gibt es je Bewertungsstufe (Rating)?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Weitere Big: Data-Fragestellung: Wie viele Bewertungen gibt es je Bewertungsstufe (Rating)?",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 105,
    "tags": [
      "Weitere Big"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2339",
    "question": "Was ist Open?",
    "type": "single",
    "options": [
      "Source In-Memory -Cluster -Computing-Framework, ursprünglich an der University of California, Berkeley entwickelt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Open: Source In-Memory -Cluster -Computing-Framework, ursprünglich an der University of California, Berkeley entwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 111,
    "tags": [
      "Open"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2340",
    "question": "Richtig oder Falsch: Open Source In-Memory -Cluster -Computing-Framework, ursprünglich an der University of California, Berkeley entwickelt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Open: Source In-Memory -Cluster -Computing-Framework, ursprünglich an der University of California, Berkeley entwickelt.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 111,
    "tags": [
      "Open"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2341",
    "question": "Was ist Wichtig?",
    "type": "single",
    "options": [
      "Spark ersetzt nicht Hadoop insgesamt, sondern primär MapReduce.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Wichtig: Spark ersetzt nicht Hadoop insgesamt, sondern primär MapReduce.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 111,
    "tags": [
      "Wichtig"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2342",
    "question": "Richtig oder Falsch: Wichtig Spark ersetzt nicht Hadoop insgesamt, sondern primär MapReduce.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Wichtig: Spark ersetzt nicht Hadoop insgesamt, sondern primär MapReduce.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 111,
    "tags": [
      "Wichtig"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2343",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "und Streaming- Daten Vereinheitlichte Verarbeitung von Batch-Daten und Echtzeit -Streams mit der bevorzugten Programmiersprache: Python, SQL, Scala, Java oder R.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: und Streaming- Daten Vereinheitlichte Verarbeitung von Batch-Daten und Echtzeit -Streams mit der bevorzugten Programmiersprache: Python, SQL, Scala, Java oder R.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2344",
    "question": "Richtig oder Falsch: Batch und Streaming- Daten Vereinheitlichte Verarbeitung von Batch-Daten und Echtzeit -Streams mit der bevorzugten Programmiersprache: Python, SQL, Scala, Java oder R.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: und Streaming- Daten Vereinheitlichte Verarbeitung von Batch-Daten und Echtzeit -Streams mit der bevorzugten Programmiersprache: Python, SQL, Scala, Java oder R.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2345",
    "question": "Was ist Petabyte?",
    "type": "single",
    "options": [
      "großen Datensätzen, ohne auf Downsampling zurückgreifen zu müssen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Petabyte: großen Datensätzen, ohne auf Downsampling zurückgreifen zu müssen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Petabyte"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2346",
    "question": "Richtig oder Falsch: Petabyte großen Datensätzen, ohne auf Downsampling zurückgreifen zu müssen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Petabyte: großen Datensätzen, ohne auf Downsampling zurückgreifen zu müssen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Petabyte"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2347",
    "question": "Was ist Machine?",
    "type": "single",
    "options": [
      "Learning-Algorithmen auf einem Laptop und nahtlose Skalierung desselben Codes auf fehlertolerante Cluster mit Tausenden von Knoten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine: Learning-Algorithmen auf einem Laptop und nahtlose Skalierung desselben Codes auf fehlertolerante Cluster mit Tausenden von Knoten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Machine"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2348",
    "question": "Richtig oder Falsch: Machine Learning-Algorithmen auf einem Laptop und nahtlose Skalierung desselben Codes auf fehlertolerante Cluster mit Tausenden von Knoten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine: Learning-Algorithmen auf einem Laptop und nahtlose Skalierung desselben Codes auf fehlertolerante Cluster mit Tausenden von Knoten.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 112,
    "tags": [
      "Machine"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2349",
    "question": "Was ist Bildquelle?",
    "type": "single",
    "options": [
      "By Apache Software Foundation [Apache License 2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Bildquelle: By Apache Software Foundation [Apache License 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 115,
    "tags": [
      "Bildquelle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2350",
    "question": "Richtig oder Falsch: Bildquelle By Apache Software Foundation [Apache License 2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Bildquelle: By Apache Software Foundation [Apache License 2.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 115,
    "tags": [
      "Bildquelle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2351",
    "question": "Was ist Konzept?",
    "type": "single",
    "options": [
      "dem Resilient Distributed Dataset (RDD) .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Konzept: dem Resilient Distributed Dataset (RDD) .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 116,
    "tags": [
      "Konzept"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2352",
    "question": "Richtig oder Falsch: Konzept dem Resilient Distributed Dataset (RDD) .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Konzept: dem Resilient Distributed Dataset (RDD) .",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 116,
    "tags": [
      "Konzept"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2353",
    "question": "Was ist Spark Bildquelle?",
    "type": "single",
    "options": [
      "https://trongkhoanguyen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Spark Bildquelle: https://trongkhoanguyen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 116,
    "tags": [
      "Spark Bildquelle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2354",
    "question": "Richtig oder Falsch: Spark Bildquelle https://trongkhoanguyen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Spark Bildquelle: https://trongkhoanguyen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 116,
    "tags": [
      "Spark Bildquelle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2355",
    "question": "Was ist Spark?",
    "type": "single",
    "options": [
      "Session, lädt einen Datensatz in ein DataFrame , führt eine Transformation durch und führt anschließend eine Aktion aus, um die Ergebnisse zu sammeln.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Spark: Session, lädt einen Datensatz in ein DataFrame , führt eine Transformation durch und führt anschließend eine Aktion aus, um die Ergebnisse zu sammeln.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 117,
    "tags": [
      "Spark"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2356",
    "question": "Richtig oder Falsch: Spark Session, lädt einen Datensatz in ein DataFrame , führt eine Transformation durch und führt anschließend eine Aktion aus, um die Ergebnisse zu sammeln.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Spark: Session, lädt einen Datensatz in ein DataFrame , führt eine Transformation durch und führt anschließend eine Aktion aus, um die Ergebnisse zu sammeln.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 117,
    "tags": [
      "Spark"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2357",
    "question": "Was ist Retrieval?",
    "type": "single",
    "options": [
      "Augmented Generation (RAG) kombiniert Large Language Models (LLMs) mit externen Wissensquellen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Retrieval: Augmented Generation (RAG) kombiniert Large Language Models (LLMs) mit externen Wissensquellen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 120,
    "tags": [
      "Retrieval"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2358",
    "question": "Richtig oder Falsch: Retrieval Augmented Generation (RAG) kombiniert Large Language Models (LLMs) mit externen Wissensquellen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Retrieval: Augmented Generation (RAG) kombiniert Large Language Models (LLMs) mit externen Wissensquellen.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 120,
    "tags": [
      "Retrieval"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2359",
    "question": "Was ist Grundlage?",
    "type": "single",
    "options": [
      "Datenmengen im TB/PB -Bereich Verteilte Speicherung (Data Lake, HDFS, Cloud Object Storage) Schnelle Suche & Filterung (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Grundlage: Datenmengen im TB/PB -Bereich Verteilte Speicherung (Data Lake, HDFS, Cloud Object Storage) Schnelle Suche & Filterung (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 120,
    "tags": [
      "Grundlage"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2360",
    "question": "Richtig oder Falsch: Grundlage Datenmengen im TB/PB -Bereich Verteilte Speicherung (Data Lake, HDFS, Cloud Object Storage) Schnelle Suche & Filterung (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Grundlage: Datenmengen im TB/PB -Bereich Verteilte Speicherung (Data Lake, HDFS, Cloud Object Storage) Schnelle Suche & Filterung (z.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 120,
    "tags": [
      "Grundlage"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2361",
    "question": "Was ist Retrieval?",
    "type": "single",
    "options": [
      "Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Retrieval: Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 121,
    "tags": [
      "Retrieval"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2362",
    "question": "Richtig oder Falsch: Retrieval Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Retrieval: Augmented Generation (RAG) Finden relevanter Dokumente für LLMs Kombination mit Data Lakes, Spark & Hadoop möglich Typische Systeme: FAISS, Milvus , Qdrant , Pinecone WS  Big Data & Data Science -Prof.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 121,
    "tags": [
      "Retrieval"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2363",
    "question": "Was ist Architektur?",
    "type": "single",
    "options": [
      "RAG auf Big -Data -Basis 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Architektur: RAG auf Big -Data -Basis 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 122,
    "tags": [
      "Architektur"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2364",
    "question": "Richtig oder Falsch: Architektur RAG auf Big -Data -Basis 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Architektur: RAG auf Big -Data -Basis 1.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 122,
    "tags": [
      "Architektur"
    ],
    "difficulty": 1
  },
  {
    "id": "q_2365",
    "question": "Was ist Verarbeitung?",
    "type": "single",
    "options": [
      "Spark für ETL, Chunking, Embeddings 3.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verarbeitung: Spark für ETL, Chunking, Embeddings 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 122,
    "tags": [
      "Verarbeitung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_2366",
    "question": "Richtig oder Falsch: Verarbeitung Spark für ETL, Chunking, Embeddings 3.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verarbeitung: Spark für ETL, Chunking, Embeddings 3.",
    "source_file": "12-bigdata_science_Big-Data-Analytics_v3.pdf",
    "source_page": 122,
    "tags": [
      "Verarbeitung"
    ],
    "difficulty": 1
  }
]