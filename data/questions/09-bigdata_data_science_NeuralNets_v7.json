[
  {
    "id": "q_721",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS Â© FOM Hochschule fÃ¼r Oekonomie & Management gemeinnÃ¼tzige Gesellschaft mbH (FOM), LeimkugelstraÃŸe 6, 45141 Essen Dieses Werk ist urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS Â© FOM Hochschule fÃ¼r Oekonomie & Management gemeinnÃ¼tzige Gesellschaft mbH (FOM), LeimkugelstraÃŸe 6, 45141 Essen Dieses Werk ist urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 2,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_722",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "Das Werk oder Teile daraus dÃ¼rfen nicht ohne schriftliche Genehmigung der FOM reproduziert oder unter Verwendung elektronischer Systeme verarbeitet, vervielfÃ¤ltigt oder verbreitet werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Das Werk oder Teile daraus dÃ¼rfen nicht ohne schriftliche Genehmigung der FOM reproduziert oder unter Verwendung elektronischer Systeme verarbeitet, vervielfÃ¤ltigt oder verbreitet werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 2,
    "tags": [
      "Das",
      "Werk",
      "Teile"
    ],
    "difficulty": 3
  },
  {
    "id": "q_723",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§KÃ¼nstliche neuronale Netze (ANN) sind Berechnungsmodelle, die sich an der Struktur des menschlichen Gehirns und seinen grundlegenden Bausteinen orientieren: Neuronen ï‚§KÃ¼nstliche Neuronen (auch \"Knoten\" genannt) stellen die grundlegende Recheneinheit eines kÃ¼nstlichen neuronalen Netzes dar ï‚§Jedes Neuron empfÃ¤ngt mehrere Eingabewerte ğ‘¥ğ‘¥ ğ‘–ğ‘–, die mit einer Reihe von Parametern w multipliziert und dann mit Hilfe einer Ãœbertragungsfunktion (in der Regel die Summe, gefolgt von einer Verzerrung (Bias) b aggregiert werden ï‚§AnschlieÃŸend werden die aggregierten Eingaben mit einer so genannten Aktivierungsfunktion f verarbeitet, was zu einer Ausgabe ğ‘¦ğ‘¦ fÃ¼hrt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§KÃ¼nstliche neuronale Netze (ANN) sind Berechnungsmodelle, die sich an der Struktur des menschlichen Gehirns und seinen grundlegenden Bausteinen orientieren: Neuronen ï‚§KÃ¼nstliche Neuronen (auch \"Knoten\" genannt) stellen die grundlegende Recheneinheit eines kÃ¼nstlichen neuronalen Netzes dar ï‚§Jedes Neuron empfÃ¤ngt mehrere Eingabewerte ğ‘¥ğ‘¥ ğ‘–ğ‘–, die mit einer Reihe von Parametern w multipliziert und dann mit Hilfe einer Ãœbertragungsfunktion (in der Regel die Summe, gefolgt von einer Verzerrung (Bias) b aggregiert werden ï‚§AnschlieÃŸend werden die aggregierten Eingaben mit einer so genannten Aktivierungsfunktion f verarbeitet, was zu einer Ausgabe ğ‘¦ğ‘¦ fÃ¼hrt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 5,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_724",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Beispiel: Logistische Regression dargestellt als kÃ¼nstliches NeuronMachine Learning Artificial Neural Networks ğ‘“ğ‘“ ğ‘¥ğ‘¥ğ‘ğ‘ ğ‘¤ğ‘¤ï¿½ğ‘¦ğ‘¦Aktivierungsfunktion : ï¿½ğ‘¦ğ‘¦=ğ’‡ğ’‡(ğ‘§ğ‘§)=1 1+ğ‘’ğ‘’âˆ’ğ‘§ğ‘§Transferfunktion : ğ‘§ğ‘§=ğ‘¤ğ‘¤ğ‘¥ğ‘¥+ğ‘ğ‘ ğ‘§ğ‘§=ğ‘¤ğ‘¤ğ‘¥ğ‘¥ +ğ‘ğ‘ Transfer funktionAktivierungs funktionGewichtBias Eingabe Ausgabe(Sigmoid -Funktion)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Beispiel: Logistische Regression dargestellt als kÃ¼nstliches NeuronMachine Learning Artificial Neural Networks ğ‘“ğ‘“ ğ‘¥ğ‘¥ğ‘ğ‘ ğ‘¤ğ‘¤ï¿½ğ‘¦ğ‘¦Aktivierungsfunktion : ï¿½ğ‘¦ğ‘¦=ğ’‡ğ’‡(ğ‘§ğ‘§)=1 1+ğ‘’ğ‘’âˆ’ğ‘§ğ‘§Transferfunktion : ğ‘§ğ‘§=ğ‘¤ğ‘¤ğ‘¥ğ‘¥+ğ‘ğ‘ ğ‘§ğ‘§=ğ‘¤ğ‘¤ğ‘¥ğ‘¥ +ğ‘ğ‘ Transfer funktionAktivierungs funktionGewichtBias Eingabe Ausgabe(Sigmoid -Funktion)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 11,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_725",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Aktivierungsfunktionen (activation function)Machine Learning Artificial Neural Networks Lineare Funktion â€¢Nicht nÃ¼tzlich fÃ¼r neuronale Netze, da die meisten Problemenichtlinear sind (ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Aktivierungsfunktionen (activation function)Machine Learning Artificial Neural Networks Lineare Funktion â€¢Nicht nÃ¼tzlich fÃ¼r neuronale Netze, da die meisten Problemenichtlinear sind (ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 14,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_726",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Das menschliche Gehirn besteht aus ~1011 Neuronen ï‚§Jedes Neuron hat etwa 104 bis 105 Verbindungen ï‚§Berechnungen in Neuronen dauern ~0,001 Sekunden ï‚§Kognitive Aufgaben (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Das menschliche Gehirn besteht aus ~1011 Neuronen ï‚§Jedes Neuron hat etwa 104 bis 105 Verbindungen ï‚§Berechnungen in Neuronen dauern ~0,001 Sekunden ï‚§Kognitive Aufgaben (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 15,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_727",
    "question": "Welche Aussage Ã¼ber Gesichtserkennung ist korrekt?",
    "type": "single",
    "options": [
      "Gesichtserkennung) dauern ~0,1 Sekunden ï‚§Daher werden wÃ¤hrend einer kognitiven Aufgabe nur ~100 Berechnungen in einem einzigen Neuron durchgefÃ¼hrt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Gesichtserkennung) dauern ~0,1 Sekunden ï‚§Daher werden wÃ¤hrend einer kognitiven Aufgabe nur ~100 Berechnungen in einem einzigen Neuron durchgefÃ¼hrt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 15,
    "tags": [
      "Gesichtserkennung",
      "Sekunden",
      "Daher"
    ],
    "difficulty": 3
  },
  {
    "id": "q_728",
    "question": "Welche Aussage Ã¼ber Daraus ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Daraus folgt: Berechnungen mÃ¼ssen Ã¼ber viele Neuronen hinweg parallelisiert werden ï‚§KÃ¼nstliche neuronale Netze: Parallele Berechnungen werden durch die Gruppierung mehrerer Neuronen in sogenannten Schichten erreichtMachine Learning Artificial Neural Networks",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Daraus folgt: Berechnungen mÃ¼ssen Ã¼ber viele Neuronen hinweg parallelisiert werden ï‚§KÃ¼nstliche neuronale Netze: Parallele Berechnungen werden durch die Gruppierung mehrerer Neuronen in sogenannten Schichten erreichtMachine Learning Artificial Neural Networks",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 15,
    "tags": [
      "Daraus",
      "Berechnungen",
      "Neuronen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_729",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Multilayer Perceptron (MLP) ï‚§Mehrschichtiges Perzeptron (MLP) ï‚§Jedes Neuron einer Schicht ist mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\"",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Multilayer Perceptron (MLP) ï‚§Mehrschichtiges Perzeptron (MLP) ï‚§Jedes Neuron einer Schicht ist mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\"",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_730",
    "question": "Welche Aussage Ã¼ber Jede ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Jede Verbindung (grauer Pfeil) hat ein Gewicht ğ‘¤ğ‘¤ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™, jede Schicht hat einen Biasterm ğ‘ğ‘ğ‘™ğ‘™ ï‚§Die Eingangswerte eines Neurons werden mit den Gewichten ğ‘¤ğ‘¤ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™der entsprechenden Verbindungen multipliziert, aufsummiert, zum Bias ğ‘ğ‘ğ‘™ğ‘™, addiert und dann mit einer Aktivierungsfunktion transformiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Jede Verbindung (grauer Pfeil) hat ein Gewicht ğ‘¤ğ‘¤ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™, jede Schicht hat einen Biasterm ğ‘ğ‘ğ‘™ğ‘™ ï‚§Die Eingangswerte eines Neurons werden mit den Gewichten ğ‘¤ğ‘¤ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™der entsprechenden Verbindungen multipliziert, aufsummiert, zum Bias ğ‘ğ‘ğ‘™ğ‘™, addiert und dann mit einer Aktivierungsfunktion transformiert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Jede",
      "Verbindung",
      "Pfeil"
    ],
    "difficulty": 3
  },
  {
    "id": "q_731",
    "question": "Welche Aussage Ã¼ber Auf ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Auf diese Weise werden die Eingabewerte durch das Netz weitergeleitet, wobei sie von den verschiedenen Neuronenschichten transformiert werden, bis die letzte Ausgangsschicht eine Vorhersage liefert (VorwÃ¤rtspropagation, forward propagation) ï‚§Die Vorhersagen des Netzes kÃ¶nnen anhand einer Verlustfunktion (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Auf diese Weise werden die Eingabewerte durch das Netz weitergeleitet, wobei sie von den verschiedenen Neuronenschichten transformiert werden, bis die letzte Ausgangsschicht eine Vorhersage liefert (VorwÃ¤rtspropagation, forward propagation) ï‚§Die Vorhersagen des Netzes kÃ¶nnen anhand einer Verlustfunktion (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Auf",
      "Weise",
      "Eingabewerte"
    ],
    "difficulty": 3
  },
  {
    "id": "q_732",
    "question": "Welche Aussage Ã¼ber Cross ist korrekt?",
    "type": "single",
    "options": [
      "Cross -Entropy - Loss) bewertet werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Cross -Entropy - Loss) bewertet werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Cross",
      "Entropy",
      "Loss"
    ],
    "difficulty": 3
  },
  {
    "id": "q_733",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die Gewichte ğ‘¤ğ‘¤ ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™und Verzerrungen ğ‘ğ‘l des Netzes werden mit Hilfe des Gradientenabstiegs in Bezug auf die Fehlerfunktion aktualisiert (RÃ¼ckwÃ¤rtspropagation, backward propagation)Machine Learning Artificial Neural Networks",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die Gewichte ğ‘¤ğ‘¤ ğ‘–ğ‘–,ğ‘—ğ‘—ğ‘™ğ‘™und Verzerrungen ğ‘ğ‘l des Netzes werden mit Hilfe des Gradientenabstiegs in Bezug auf die Fehlerfunktion aktualisiert (RÃ¼ckwÃ¤rtspropagation, backward propagation)Machine Learning Artificial Neural Networks",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Die",
      "Gewichte",
      "Verzerrungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_734",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "Die Eingabedaten werden sequentiell durch die Schichten der Neuronen geleitet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Die Eingabedaten werden sequentiell durch die Schichten der Neuronen geleitet",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 19,
    "tags": [
      "Die",
      "Eingabedaten",
      "Schichten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_735",
    "question": "Welche Aussage Ã¼ber Lehrwert ist korrekt?",
    "type": "single",
    "options": [
      "Lehrwert ) ğ’ğ’â‚“ = Ausgabewert (berechneter Wert) ğ’ğ’áµ¢ = Eingabewert Die Delta -Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Lehrwert ) ğ’ğ’â‚“ = Ausgabewert (berechneter Wert) ğ’ğ’áµ¢ = Eingabewert Die Delta -Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Lehrwert",
      "Ausgabewert",
      "Wert"
    ],
    "difficulty": 3
  },
  {
    "id": "q_736",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "Das Gewicht wird in Richtung des Fehlers korrigiert, skaliert durch die Lernrate und den Eingabewert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Das Gewicht wird in Richtung des Fehlers korrigiert, skaliert durch die Lernrate und den Eingabewert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Das",
      "Gewicht",
      "Richtung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_737",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Einfache Perzeptrons sind auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Einfache Perzeptrons sind auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 27,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_738",
    "question": "Welche Aussage Ã¼ber Keine ist korrekt?",
    "type": "single",
    "options": [
      "Keine versteckten Schichten ï‚§Das Modell besteht nur aus Eingabe- und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Keine versteckten Schichten ï‚§Das Modell besteht nur aus Eingabe- und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Keine",
      "Schichten",
      "Das"
    ],
    "difficulty": 3
  },
  {
    "id": "q_739",
    "question": "Welche Aussage Ã¼ber Eingaben ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Eingaben mÃ¼ssen meist normalisiert oder skaliert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Eingaben mÃ¼ssen meist normalisiert oder skaliert werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Eingaben"
    ],
    "difficulty": 3
  },
  {
    "id": "q_740",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Deep Neural Networks ï‚§Weitaus komplexer als ein einfaches MLP (tiefer und umfassender) ï‚§Sie sind in der Lage, komplexe nicht -lineare Beziehungen in Daten zu erfassen, die von einfacheren Modellen nicht gelernt werden kÃ¶nnen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Deep Neural Networks ï‚§Weitaus komplexer als ein einfaches MLP (tiefer und umfassender) ï‚§Sie sind in der Lage, komplexe nicht -lineare Beziehungen in Daten zu erfassen, die von einfacheren Modellen nicht gelernt werden kÃ¶nnen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_741",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Das Training ist teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe ,",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Das Training ist teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe ,",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Das",
      "Training",
      "Speicherbedarf"
    ],
    "difficulty": 3
  },
  {
    "id": "q_742",
    "question": "Welche Aussage Ã¼ber Proben ist korrekt?",
    "type": "single",
    "options": [
      "Proben), um fÃ¼r viele Anwendungen korrekt trainiert zu werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Proben), um fÃ¼r viele Anwendungen korrekt trainiert zu werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Proben",
      "Anwendungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_743",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die resultierenden Modelle sind sehr schwer zu interpretierenMachine Learning Artificial Neural Networks - CNN",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die resultierenden Modelle sind sehr schwer zu interpretierenMachine Learning Artificial Neural Networks - CNN",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Die",
      "Modelle",
      "Learning"
    ],
    "difficulty": 3
  },
  {
    "id": "q_744",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Tiefe Faltungsneuronale Netze (CNN) ï‚§Multi Layer Perceptrons sind nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Tiefe Faltungsneuronale Netze (CNN) ï‚§Multi Layer Perceptrons sind nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 32,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_745",
    "question": "Welche Aussage Ã¼ber Bilder ist korrekt?",
    "type": "single",
    "options": [
      "Bilder, Videodaten) -> die Anzahl der Parameter wÃ¤re unrealistisch groÃŸ ï‚§Eingabebild ( 200x 200 px) -> 40000 Eingabewerte, die mit min",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Bilder, Videodaten) -> die Anzahl der Parameter wÃ¤re unrealistisch groÃŸ ï‚§Eingabebild ( 200x 200 px) -> 40000 Eingabewerte, die mit min",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 32,
    "tags": [
      "Bilder",
      "Videodaten",
      "Anzahl"
    ],
    "difficulty": 3
  },
  {
    "id": "q_746",
    "question": "Welche Aussage Ã¼ber Neuronen ist korrekt?",
    "type": "single",
    "options": [
      "40000 Neuronen in der ersten versteckten Schicht verbunden werden mÃ¼ssen: 40000x 40000= 160mio Parameter fÃ¼r 1 vollstÃ¤ndig verbundene Schicht ï‚§Faltungsneuronale Netze ersetzen die ersten n \"voll verbundenen\" Schichten durch sogenannte Faltungsschichten ï‚§Faltungsschichten verwenden \" Weight Sharing\", um die Anzahl der Parameter bei gleichbleibender Leistung Machine Learning Artificial Neural Networks - CNN",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "40000 Neuronen in der ersten versteckten Schicht verbunden werden mÃ¼ssen: 40000x 40000= 160mio Parameter fÃ¼r 1 vollstÃ¤ndig verbundene Schicht ï‚§Faltungsneuronale Netze ersetzen die ersten n \"voll verbundenen\" Schichten durch sogenannte Faltungsschichten ï‚§Faltungsschichten verwenden \" Weight Sharing\", um die Anzahl der Parameter bei gleichbleibender Leistung Machine Learning Artificial Neural Networks - CNN",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 32,
    "tags": [
      "Neuronen",
      "Schicht",
      "Parameter"
    ],
    "difficulty": 3
  },
  {
    "id": "q_747",
    "question": "Welche Aussage Ã¼ber Kanten ist korrekt?",
    "type": "single",
    "options": [
      "Kanten, Linien ï‚§Diese Filter werden entweder bei einfachen Modellen von Hand vorgegeben oder werden im Training erlernt ï‚§Der Kernel der GrÃ¶ÃŸe iÃ—j wird Ã¼ber das Eingabefeld (meist Bild mit nÃ—m Pixel, 2 Dimensionen) bewegt ï‚§Bei RGB werden diese auf jeden Kanal angewendetï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabeschicht multipliziert und summiert und ergeben die entsprechende Aktivierung ï‚§GrÃ¶ÃŸe des Kernels (Windows) bestimmt die GrÃ¶ÃŸe der Ausgabematrix: n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Kanten, Linien ï‚§Diese Filter werden entweder bei einfachen Modellen von Hand vorgegeben oder werden im Training erlernt ï‚§Der Kernel der GrÃ¶ÃŸe iÃ—j wird Ã¼ber das Eingabefeld (meist Bild mit nÃ—m Pixel, 2 Dimensionen) bewegt ï‚§Bei RGB werden diese auf jeden Kanal angewendetï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabeschicht multipliziert und summiert und ergeben die entsprechende Aktivierung ï‚§GrÃ¶ÃŸe des Kernels (Windows) bestimmt die GrÃ¶ÃŸe der Ausgabematrix: n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 34,
    "tags": [
      "Kanten",
      "Linien",
      "Diese"
    ],
    "difficulty": 3
  },
  {
    "id": "q_748",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Filter trainieren ï‚§Mittels Backpropagation mit Nebenbedingungen ï‚§FÃ¼r jeden der drei KanÃ¤le eines Farbbildes werden verschiedene Conv2D- Filter erstellt ï‚§Die Filter fÃ¼r jede Ebene werden nach dem Zufallsprinzip auf der Grundlage einer Normal - oder GauÃŸverteilung initialisiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Filter trainieren ï‚§Mittels Backpropagation mit Nebenbedingungen ï‚§FÃ¼r jeden der drei KanÃ¤le eines Farbbildes werden verschiedene Conv2D- Filter erstellt ï‚§Die Filter fÃ¼r jede Ebene werden nach dem Zufallsprinzip auf der Grundlage einer Normal - oder GauÃŸverteilung initialisiert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 35,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_749",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Feature maps (â€Filterâ€œ) einfach ï‚§Kernel wird Ã¼ber das Eingabefeld bewegt ï‚§Conv2D( channels =1, kernel_size=(3,3))Machine Learning Artificial Neural Networks - CNN https://medium",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Feature maps (â€Filterâ€œ) einfach ï‚§Kernel wird Ã¼ber das Eingabefeld bewegt ï‚§Conv2D( channels =1, kernel_size=(3,3))Machine Learning Artificial Neural Networks - CNN https://medium",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 37,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_750",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Dilatation ï‚§Kernel wird erweitert um einen Faktor i Ã— j ï‚§Conv2D( channels =1, kernel_size=(3,3), dilation=(2,2))Machine Learning Artificial Neural Networks - CNN https://medium",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Dilatation ï‚§Kernel wird erweitert um einen Faktor i Ã— j ï‚§Conv2D( channels =1, kernel_size=(3,3), dilation=(2,2))Machine Learning Artificial Neural Networks - CNN https://medium",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 42,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_751",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Artificial Neural Networks - CNN Pooling Layer ï‚§Gruppe von Neuronen einer Ebene zu einem Neuron zusammenfassen (Unterstichprobe des Bildes) ï‚§Vermeidet, dass kleine Ã„nderungen wie Verschiebungen, Rotationen das Ergebnis beeinflussen ï‚§Besitzt keine Gewichte ï‚§Es wird wieder ein i Ã— i Fenster Ã¼ber die Eingabeschicht n Ã— m bewegt ï‚§Es werden iÃ—i Pixel (Pooling-Kernel) zusammengefasst ï‚§durch Mittelwertbildung ï‚§durch maximalen Wert ï‚§Ausgabeschicht dann Matrix mit n-i+1Ã—m-i+1ï‚§MaxPooling2D( pool_size=(2, 2)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Artificial Neural Networks - CNN Pooling Layer ï‚§Gruppe von Neuronen einer Ebene zu einem Neuron zusammenfassen (Unterstichprobe des Bildes) ï‚§Vermeidet, dass kleine Ã„nderungen wie Verschiebungen, Rotationen das Ergebnis beeinflussen ï‚§Besitzt keine Gewichte ï‚§Es wird wieder ein i Ã— i Fenster Ã¼ber die Eingabeschicht n Ã— m bewegt ï‚§Es werden iÃ—i Pixel (Pooling-Kernel) zusammengefasst ï‚§durch Mittelwertbildung ï‚§durch maximalen Wert ï‚§Ausgabeschicht dann Matrix mit n-i+1Ã—m-i+1ï‚§MaxPooling2D( pool_size=(2, 2)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 45,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_752",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Artificial Neural Networks - CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Artificial Neural Networks - CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 46,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_753",
    "question": "Welche Aussage Ã¼ber Neuronale ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Neuronale Netze kÃ¶nnen eine groÃŸe Anzahl von Parametern enthalten, die eingestellt und optimiert werden kÃ¶nnen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Neuronale Netze kÃ¶nnen eine groÃŸe Anzahl von Parametern enthalten, die eingestellt und optimiert werden kÃ¶nnen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 61,
    "tags": [
      "Neuronale",
      "Netze",
      "Anzahl"
    ],
    "difficulty": 3
  },
  {
    "id": "q_754",
    "question": "Welche Aussage Ã¼ber AusfÃ¼hrungszeit ist korrekt?",
    "type": "single",
    "options": [
      "AusfÃ¼hrungszeit in der Praxis) ï‚§Speicherbedarf ï‚§KomplexitÃ¤t, VerstÃ¤ndlichkeit / ErklÃ¤rbarkeit Hyperparameter ï‚§Backpropagation: Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "AusfÃ¼hrungszeit in der Praxis) ï‚§Speicherbedarf ï‚§KomplexitÃ¤t, VerstÃ¤ndlichkeit / ErklÃ¤rbarkeit Hyperparameter ï‚§Backpropagation: Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "AusfÃ¼hrungszeit",
      "Praxis",
      "Speicherbedarf"
    ],
    "difficulty": 3
  },
  {
    "id": "q_755",
    "question": "Welche Aussage Ã¼ber Data ist korrekt?",
    "type": "single",
    "options": [
      "durch Data Scientists oder beim Modell -Setup) ï‚§Automodellierung: automatische Auswahl und Anpassung von Modellen und Hyperparametern ï‚§(Datenmenge) ï‚§(Hardware)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "durch Data Scientists oder beim Modell -Setup) ï‚§Automodellierung: automatische Auswahl und Anpassung von Modellen und Hyperparametern ï‚§(Datenmenge) ï‚§(Hardware)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "Data",
      "Scientists",
      "Modell"
    ],
    "difficulty": 3
  },
  {
    "id": "q_756",
    "question": "Welche Aussage Ã¼ber Dadurch ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Dadurch werden Schwankungen geglÃ¤ttet und das Modell kann sich schneller und stabiler einem Minimum annÃ¤hern",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Dadurch werden Schwankungen geglÃ¤ttet und das Modell kann sich schneller und stabiler einem Minimum annÃ¤hern",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 63,
    "tags": [
      "Dadurch",
      "Schwankungen",
      "Modell"
    ],
    "difficulty": 3
  },
  {
    "id": "q_757",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Gewichte ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘—ğ‘—: GroÃŸe neuronale Netze besitzen Millionen von Parametern, die angepasst werden kÃ¶nnen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Gewichte ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘—ğ‘—: GroÃŸe neuronale Netze besitzen Millionen von Parametern, die angepasst werden kÃ¶nnen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 65,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_758",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "Das bedeutet: Das Training erfolgt in einem 25 Millionen-dimensionalen Raum",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Das bedeutet: Das Training erfolgt in einem 25 Millionen-dimensionalen Raum",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 65,
    "tags": [
      "Das",
      "Das",
      "Training"
    ],
    "difficulty": 3
  },
  {
    "id": "q_759",
    "question": "Welche Aussage Ã¼ber Ziel ist korrekt?",
    "type": "single",
    "options": [
      "Ziel: ï‚§Vereinfachung des Modells ï‚§Geringerer Speicher - und Rechenaufwand ï‚§Schnellere AusfÃ¼hrung bei nahezu gleicher Leistung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Ziel: ï‚§Vereinfachung des Modells ï‚§Geringerer Speicher - und Rechenaufwand ï‚§Schnellere AusfÃ¼hrung bei nahezu gleicher Leistung",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Ziel",
      "Vereinfachung",
      "Modells"
    ],
    "difficulty": 3
  },
  {
    "id": "q_760",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Optimizing Neural Networks Tuningoptionen : Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Optimizing Neural Networks Tuningoptionen : Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_761",
    "question": "Welche Aussage Ã¼ber SchÃ¤tze ist korrekt?",
    "type": "single",
    "options": [
      "SchÃ¤tze die Wichtigkeit ( Saliency ) jedes Gewichts â€“ sie wird definiert durch die Ã„nderung der Verlustfunktion, wenn das Gewicht leicht verÃ¤ndert wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "SchÃ¤tze die Wichtigkeit ( Saliency ) jedes Gewichts â€“ sie wird definiert durch die Ã„nderung der Verlustfunktion, wenn das Gewicht leicht verÃ¤ndert wird",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "SchÃ¤tze",
      "Wichtigkeit",
      "Saliency"
    ],
    "difficulty": 3
  },
  {
    "id": "q_762",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Optimizing Neural Networks Tuningoptionen : Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Optimizing Neural Networks Tuningoptionen : Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_763",
    "question": "Welche Aussage Ã¼ber Ziel ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§ Ziel Ein neuronales Netz zu finden, das die gleiche Genauigkeit erreicht wie das vollstÃ¤ndige (groÃŸe) Netz, aber mit nicht mehr Trainingsschritten â€“ also effizienter trainiert werden kann",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§ Ziel Ein neuronales Netz zu finden, das die gleiche Genauigkeit erreicht wie das vollstÃ¤ndige (groÃŸe) Netz, aber mit nicht mehr Trainingsschritten â€“ also effizienter trainiert werden kann",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Ziel",
      "Ein",
      "Netz"
    ],
    "difficulty": 3
  },
  {
    "id": "q_764",
    "question": "Welche Aussage Ã¼ber Initialisierung ist korrekt?",
    "type": "single",
    "options": [
      "Initialisierung: Das neuronale Netz wird zufÃ¤llig initialisiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Initialisierung: Das neuronale Netz wird zufÃ¤llig initialisiert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Initialisierung",
      "Das",
      "Netz"
    ],
    "difficulty": 3
  },
  {
    "id": "q_765",
    "question": "Welche Aussage Ã¼ber Alternative ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Alternative Idee:Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Alternative Idee:Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Alternative",
      "Idee",
      "Beginne"
    ],
    "difficulty": 3
  },
  {
    "id": "q_766",
    "question": "Welche Aussage Ã¼ber Dieses ist korrekt?",
    "type": "single",
    "options": [
      "Dieses Weight -Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Dieses Weight -Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Dieses",
      "Weight",
      "Sharing"
    ],
    "difficulty": 3
  },
  {
    "id": "q_767",
    "question": "Welche Aussage Ã¼ber Nach ist korrekt?",
    "type": "single",
    "options": [
      "Nach Leistung & KomplexitÃ¤t ranken: Ordne die Netze nach Performance und KomplexitÃ¤t",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Nach Leistung & KomplexitÃ¤t ranken: Ordne die Netze nach Performance und KomplexitÃ¤t",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Nach",
      "Leistung",
      "KomplexitÃ¤t"
    ],
    "difficulty": 3
  },
  {
    "id": "q_768",
    "question": "Welche Aussage Ã¼ber Middle ist korrekt?",
    "type": "single",
    "options": [
      "Middle: Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Middle: Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Middle",
      "Networks",
      "Insert"
    ],
    "difficulty": 3
  },
  {
    "id": "q_769",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Standard-NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Standard-NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 73,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_770",
    "question": "Welche Aussage Ã¼ber Speicherzellen ist korrekt?",
    "type": "single",
    "options": [
      "y(0) ï‚§\"Speicherzellen\" ï‚§Jedes Neuron hat zwei Gewichte: wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "y(0) ï‚§\"Speicherzellen\" ï‚§Jedes Neuron hat zwei Gewichte: wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Speicherzellen",
      "Jedes",
      "Neuron"
    ],
    "difficulty": 3
  },
  {
    "id": "q_771",
    "question": "Welche Aussage Ã¼ber Vektoren ist korrekt?",
    "type": "single",
    "options": [
      "als Vektoren/Matrizen ï‚§Der Zustand einer Zelle ist gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "als Vektoren/Matrizen ï‚§Der Zustand einer Zelle ist gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Vektoren",
      "Matrizen",
      "Der"
    ],
    "difficulty": 3
  },
  {
    "id": "q_772",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Training RNNs ï‚§Back propagation durch (Ã¼ber) Zeit (BPTT) ï‚§Feed forward ï‚§Das Ergebnis wird mit einer Kostenfunktion bewertet, die n vorherige Ausgaben einschlieÃŸt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Training RNNs ï‚§Back propagation durch (Ã¼ber) Zeit (BPTT) ï‚§Feed forward ï‚§Das Ergebnis wird mit einer Kostenfunktion bewertet, die n vorherige Ausgaben einschlieÃŸt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 75,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_773",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Zwei Arten interner ZustÃ¤nde: h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Zwei Arten interner ZustÃ¤nde: h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 78,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_774",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§LSMT verwendet eine Vielzahl von Parametern ï‚§Vereinfachte Variante von LSMT ï‚§Scheint fast so gut zu funktionieren wie ein LSTM ï‚§Nur ein Zustand h(t) ï‚§r(t) RÃ¼cksetzgatter, Ã¤hnlich dem Vergessensgatter ï‚§z(t) AktualisierungstorMachine Learning Gated Recurrent Unit (GRU) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§LSMT verwendet eine Vielzahl von Parametern ï‚§Vereinfachte Variante von LSMT ï‚§Scheint fast so gut zu funktionieren wie ein LSTM ï‚§Nur ein Zustand h(t) ï‚§r(t) RÃ¼cksetzgatter, Ã¤hnlich dem Vergessensgatter ï‚§z(t) AktualisierungstorMachine Learning Gated Recurrent Unit (GRU) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 79,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_775",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Evaluation - Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Evaluation - Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_776",
    "question": "Welche Aussage Ã¼ber Model ist korrekt?",
    "type": "single",
    "options": [
      "(â€Model Selection â€œ) ï‚§Wie gut sind die Vorhersagen eines Modells auf â€ungesehenen â€œ Daten (Daten auf denen es nicht trainiert wurde)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "(â€Model Selection â€œ) ï‚§Wie gut sind die Vorhersagen eines Modells auf â€ungesehenen â€œ Daten (Daten auf denen es nicht trainiert wurde)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Model",
      "Selection",
      "Wie"
    ],
    "difficulty": 3
  },
  {
    "id": "q_777",
    "question": "Welche Aussage Ã¼ber Wie ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Wie Robust ist ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Wie Robust ist ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Wie",
      "Robust",
      "Modell"
    ],
    "difficulty": 3
  },
  {
    "id": "q_778",
    "question": "Welche Aussage Ã¼ber ErfÃ¼llt ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§ErfÃ¼llt das Modell gÃ¤ngige Anforderungen hinsichtlich Datenschutz und sicherheit (â€ Model Privacy â€œ / â€Model Security â€œ) ï‚§Sind zusÃ¤tzliche Tests nÃ¶tig um die NeutralitÃ¤t des Modells bei der Verarbeitung personenbezogener Daten zu gewÃ¤hrleisten (Geschlecht, EthnizitÃ¤t, Sexueller Orientierung, usw",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§ErfÃ¼llt das Modell gÃ¤ngige Anforderungen hinsichtlich Datenschutz und sicherheit (â€ Model Privacy â€œ / â€Model Security â€œ) ï‚§Sind zusÃ¤tzliche Tests nÃ¶tig um die NeutralitÃ¤t des Modells bei der Verarbeitung personenbezogener Daten zu gewÃ¤hrleisten (Geschlecht, EthnizitÃ¤t, Sexueller Orientierung, usw",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "ErfÃ¼llt",
      "Modell",
      "Anforderungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_779",
    "question": "Welche Aussage Ã¼ber Bias ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Bias / Fairness: Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Bias / Fairness: Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Bias",
      "Fairness",
      "Modelle"
    ],
    "difficulty": 3
  },
  {
    "id": "q_780",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26OpenAI Microscope ï‚§Das OpenAI Microscope ist eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26OpenAI Microscope ï‚§Das OpenAI Microscope ist eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 93,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_781",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Microsoft â€ Tayâ€œ Bot: Rassismus durch manipulierte Tweets ï‚§MS Chatbot ï‚§Ziel: Ein KI -System, das auf Twitter mit Menschen interagiert und aus diesen GesprÃ¤chen â€lerntâ€œ, um immer menschlicher zu werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Microsoft â€ Tayâ€œ Bot: Rassismus durch manipulierte Tweets ï‚§MS Chatbot ï‚§Ziel: Ein KI -System, das auf Twitter mit Menschen interagiert und aus diesen GesprÃ¤chen â€lerntâ€œ, um immer menschlicher zu werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 94,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_782",
    "question": "Welche Aussage Ã¼ber Kurz ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Kurz nach dem Start begannen Nutzer, gezielt manipulierte Tweets an Tay zu schicken â€“ mit rassistischen, sexistischen und beleidigenden Inhalten",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Kurz nach dem Start begannen Nutzer, gezielt manipulierte Tweets an Tay zu schicken â€“ mit rassistischen, sexistischen und beleidigenden Inhalten",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 94,
    "tags": [
      "Kurz",
      "Start",
      "Nutzer"
    ],
    "difficulty": 3
  },
  {
    "id": "q_783",
    "question": "Welche Aussage Ã¼ber Jonathon ist korrekt?",
    "type": "single",
    "options": [
      ", Jonathon Shlens and Christian Szegedy",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": ", Jonathon Shlens and Christian Szegedy",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 96,
    "tags": [
      "Jonathon",
      "Shlens",
      "Christian"
    ],
    "difficulty": 3
  },
  {
    "id": "q_784",
    "question": "Welche Aussage Ã¼ber Ein ist korrekt?",
    "type": "single",
    "options": [
      "Ein Bild eines Pandas wird vom KI -Modell korrekt als â€Pandaâ€œ erkannt (Confidence â‰ˆ 57 %)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Ein Bild eines Pandas wird vom KI -Modell korrekt als â€Pandaâ€œ erkannt (Confidence â‰ˆ 57 %)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 96,
    "tags": [
      "Ein",
      "Bild",
      "Pandas"
    ],
    "difficulty": 3
  },
  {
    "id": "q_785",
    "question": "Welche Aussage Ã¼ber Dann ist korrekt?",
    "type": "single",
    "options": [
      "Dann werden kaum sichtbare Rauschmuster (gezielt berechnet) hinzugefÃ¼gt â†’ das neue Bild sieht fÃ¼r Menschen identisch aus, aber das Modell klassifiziert es plÃ¶tzlich als â€Gibbonâ€œ mit 99 % Sicherheit",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Dann werden kaum sichtbare Rauschmuster (gezielt berechnet) hinzugefÃ¼gt â†’ das neue Bild sieht fÃ¼r Menschen identisch aus, aber das Modell klassifiziert es plÃ¶tzlich als â€Gibbonâ€œ mit 99 % Sicherheit",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 96,
    "tags": [
      "Dann",
      "Rauschmuster",
      "Bild"
    ],
    "difficulty": 3
  },
  {
    "id": "q_786",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Physische Adversarial Attacks auf Verkehrsschilder ï‚§Neuronale Netze, die Verkehrszeichen erkennen, werden in autonomen Fahrsystemen eingesetzt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Physische Adversarial Attacks auf Verkehrsschilder ï‚§Neuronale Netze, die Verkehrszeichen erkennen, werden in autonomen Fahrsystemen eingesetzt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 98,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_787",
    "question": "Welche Aussage Ã¼ber Diese ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Diese Netze kÃ¶nnen jedoch durch gezielt verÃ¤nderte oder beklebte Schilder in die Irre gefÃ¼hrt werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Diese Netze kÃ¶nnen jedoch durch gezielt verÃ¤nderte oder beklebte Schilder in die Irre gefÃ¼hrt werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 98,
    "tags": [
      "Diese",
      "Netze",
      "Schilder"
    ],
    "difficulty": 3
  },
  {
    "id": "q_788",
    "question": "Welche Aussage Ã¼ber Kleine ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Kleine, visuell harmlose VerÃ¤nderungen kÃ¶nnen die Klassifikation verÃ¤ndern ï‚§Manche Stoppschilder werden fÃ¤lschlich als â€Speed Limit 45â€œ oder â€ Yield â€œ erkannt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Kleine, visuell harmlose VerÃ¤nderungen kÃ¶nnen die Klassifikation verÃ¤ndern ï‚§Manche Stoppschilder werden fÃ¤lschlich als â€Speed Limit 45â€œ oder â€ Yield â€œ erkannt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 98,
    "tags": [
      "Kleine",
      "VerÃ¤nderungen",
      "Klassifikation"
    ],
    "difficulty": 3
  },
  {
    "id": "q_789",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Model Fairness - Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias)",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Model Fairness - Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias)",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_790",
    "question": "Welche Aussage Ã¼ber Twitter ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Twitter Benutzer stellten im September 2020 fest, dass das verwendete â€Croppingâ€œ-Verfahren Gesichter mit hellerer Hautfarbe bevorzugt ( â€Racial -Bias â€œ) ï‚§Beispiel: Mitch McConnell vs",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Twitter Benutzer stellten im September 2020 fest, dass das verwendete â€Croppingâ€œ-Verfahren Gesichter mit hellerer Hautfarbe bevorzugt ( â€Racial -Bias â€œ) ï‚§Beispiel: Mitch McConnell vs",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Twitter",
      "Benutzer",
      "September"
    ],
    "difficulty": 3
  },
  {
    "id": "q_791",
    "question": "Welche Aussage Ã¼ber Geschlecht ist korrekt?",
    "type": "single",
    "options": [
      "â€Geschlechtâ€œ) nicht direkt im Modell verwendet wird,kÃ¶nnen korrelierte Variablen (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "â€Geschlechtâ€œ) nicht direkt im Modell verwendet wird,kÃ¶nnen korrelierte Variablen (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Geschlecht",
      "Modell",
      "Variablen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_792",
    "question": "Welche Aussage Ã¼ber Bei ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Bei hochdimensionalen Eingabedaten sind die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Bei hochdimensionalen Eingabedaten sind die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Bei",
      "Eingabedaten",
      "ZusammenhÃ¤nge"
    ],
    "difficulty": 3
  },
  {
    "id": "q_793",
    "question": "Welche Aussage Ã¼ber Ausgabefunktion ist korrekt?",
    "type": "single",
    "options": [
      "ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ =ï¿½ ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘¥ğ‘¥ğ‘–ğ‘–+ğ‘ğ‘Transferfunktion: (net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ =ï¿½ ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘–ğ‘–ğ‘¥ğ‘¥ğ‘–ğ‘–+ğ‘ğ‘Transferfunktion: (net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Ausgabefunktion",
      "Die",
      "Ausgabe"
    ],
    "difficulty": 3
  },
  {
    "id": "q_794",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/ 26Batch -Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/ 26Batch -Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_795",
    "question": "Welche Aussage Ã¼ber AnschlieÃŸend ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§AnschlieÃŸend werden die Gradienten Ã¼ber alle Beispiele gemittelt , und erst dann werden die Gewichte einmal pro Epoche aktualisiert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§AnschlieÃŸend werden die Gradienten Ã¼ber alle Beispiele gemittelt , und erst dann werden die Gewichte einmal pro Epoche aktualisiert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "AnschlieÃŸend",
      "Gradienten",
      "Beispiele"
    ],
    "difficulty": 3
  },
  {
    "id": "q_796",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Das Verfahren ist mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Das Verfahren ist mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Das",
      "Verfahren",
      "Rechenleistung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_797",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Online Learning (Inkrementelles Lernen) ï‚§FÃ¼r jedes neue Trainingsbeispiel werden die Gewichte sofort angepasst",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Online Learning (Inkrementelles Lernen) ï‚§FÃ¼r jedes neue Trainingsbeispiel werden die Gewichte sofort angepasst",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_798",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Fehler wird fÃ¼r jedes einzelne Beispiel berechnet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Fehler wird fÃ¼r jedes einzelne Beispiel berechnet",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Der",
      "Fehler",
      "Beispiel"
    ],
    "difficulty": 3
  },
  {
    "id": "q_799",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Das Modell reagiert unmittelbar auf neue Daten, kann dadurch aber auch instabil werden (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Das Modell reagiert unmittelbar auf neue Daten, kann dadurch aber auch instabil werden (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Das",
      "Modell",
      "Daten"
    ],
    "difficulty": 3
  },
  {
    "id": "q_800",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die Gewichte werden nach einer kleinen Teilmenge von Beispielen (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die Gewichte werden nach einer kleinen Teilmenge von Beispielen (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Die",
      "Gewichte",
      "Teilmenge"
    ],
    "difficulty": 3
  },
  {
    "id": "q_801",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Backpropagation â€“Training Variants Merkmal Batch -Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Backpropagation â€“Training Variants Merkmal Batch -Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_802",
    "question": "Welche Aussage Ã¼ber Samples ist korrekt?",
    "type": "single",
    "options": [
      "50â€“ 200 Samples) aufgeteiltJedes einzelne Trainingsbeispiel wird sofort verarbeitet Gewichts - aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "50â€“ 200 Samples) aufgeteiltJedes einzelne Trainingsbeispiel wird sofort verarbeitet Gewichts - aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Samples",
      "Trainingsbeispiel",
      "Gewichts"
    ],
    "difficulty": 3
  },
  {
    "id": "q_803",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Backpropagation â€“ Fehlerberechnung Verlustfunktion (Loss Function) ï‚§Optimierungsalgorithmus (Optimization Algorithm ) ï‚§Die Funktion, die verwendet wird, um eine mÃ¶gliche LÃ¶sung (z",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Machine Learning Backpropagation â€“ Fehlerberechnung Verlustfunktion (Loss Function) ï‚§Optimierungsalgorithmus (Optimization Algorithm ) ï‚§Die Funktion, die verwendet wird, um eine mÃ¶gliche LÃ¶sung (z",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_804",
    "question": "Welche Aussage Ã¼ber Satz ist korrekt?",
    "type": "single",
    "options": [
      "einen Satz von Gewichten) zu bewerten, wird Zielfunktion (Objective Function ) genannt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "einen Satz von Gewichten) zu bewerten, wird Zielfunktion (Objective Function ) genannt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Satz",
      "Gewichten",
      "Zielfunktion"
    ],
    "difficulty": 3
  },
  {
    "id": "q_805",
    "question": "Welche Aussage Ã¼ber Ziel ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Ziel ist es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Ziel ist es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Ziel",
      "Zielfunktion",
      "LÃ¶sung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_806",
    "question": "Welche Aussage Ã¼ber In ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§In neuronalen Netzen bedeutet das meist:Den Fehler minimieren",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§In neuronalen Netzen bedeutet das meist:Den Fehler minimieren",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "In",
      "Netzen",
      "Den"
    ],
    "difficulty": 3
  },
  {
    "id": "q_807",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die Zielfunktion wird auch als Kostenfunktion (Cost Function ) oder Verlustfunktion (Loss Function ) bezeichnet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die Zielfunktion wird auch als Kostenfunktion (Cost Function ) oder Verlustfunktion (Loss Function ) bezeichnet",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Die",
      "Zielfunktion",
      "Kostenfunktion"
    ],
    "difficulty": 3
  },
  {
    "id": "q_808",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Fehler E wird somit aus der Verlustfunktion berechnet",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Fehler E wird somit aus der Verlustfunktion berechnet",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Der",
      "Fehler",
      "Verlustfunktion"
    ],
    "difficulty": 3
  },
  {
    "id": "q_809",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Das Backpropagation-Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Das Backpropagation-Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Das",
      "Backpropagation",
      "Lernverfahren"
    ],
    "difficulty": 3
  },
  {
    "id": "q_810",
    "question": "Welche Aussage Ã¼ber Ziel ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Ziel: Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Ziel: Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Ziel",
      "Alle",
      "Gewichte"
    ],
    "difficulty": 3
  },
  {
    "id": "q_811",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Fehler E(W â±¼) des Neurons j ist eine Funktion aller eingehenden Gewichte",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Fehler E(W â±¼) des Neurons j ist eine Funktion aller eingehenden Gewichte",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Der",
      "Fehler",
      "Neurons"
    ],
    "difficulty": 3
  },
  {
    "id": "q_812",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die Gewichtsanpassung ergibt sich zu: Î”wáµ¢â±¼ = -Î» Â· âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wáµ¢â±¼ ï‚§Hierbei beschreibt oâ±¼ die Ausgabe des Neurons j, welche wiederum eine Verkettung mehrerer Funktionen ist: Eingabe â†’ Aktivierungsfunktion â†’ ggf",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die Gewichtsanpassung ergibt sich zu: Î”wáµ¢â±¼ = -Î» Â· âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wáµ¢â±¼ ï‚§Hierbei beschreibt oâ±¼ die Ausgabe des Neurons j, welche wiederum eine Verkettung mehrerer Funktionen ist: Eingabe â†’ Aktivierungsfunktion â†’ ggf",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Die",
      "Gewichtsanpassung",
      "Hierbei"
    ],
    "difficulty": 3
  },
  {
    "id": "q_813",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS â€Das Backpropagation -Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS â€Das Backpropagation -Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_814",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "Die GewichtsÃ¤nderung wird schichtenweise, beginnend mit den Verbindungen zur Ausgabeschicht rÃ¼ckwÃ¤rts in Richtung Eingabeschicht, vorgenommen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Die GewichtsÃ¤nderung wird schichtenweise, beginnend mit den Verbindungen zur Ausgabeschicht rÃ¼ckwÃ¤rts in Richtung Eingabeschicht, vorgenommen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Die",
      "GewichtsÃ¤nderung",
      "Verbindungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_815",
    "question": "Welche Aussage Ã¼ber Grundidee ist korrekt?",
    "type": "single",
    "options": [
      "212) ï‚§Grundidee:Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "212) ï‚§Grundidee:Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Grundidee",
      "Alle",
      "Gewichte"
    ],
    "difficulty": 3
  },
  {
    "id": "q_816",
    "question": "Welche Aussage Ã¼ber Hinweis ist korrekt?",
    "type": "single",
    "options": [
      "212- 215) Hinweis: In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "212- 215) Hinweis: In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Hinweis",
      "In",
      "Gleichungen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_817",
    "question": "Welche Aussage Ã¼ber GewichtsÃ¤nderung ist korrekt?",
    "type": "single",
    "options": [
      "GewichtsÃ¤nderung (Korrektur) mit Lernrate Î»Der Fehler E(W â±¼) der Ausgabe des Neurons j ist eine Funktion aller eingehenden Gewichte",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "GewichtsÃ¤nderung (Korrektur) mit Lernrate Î»Der Fehler E(W â±¼) der Ausgabe des Neurons j ist eine Funktion aller eingehenden Gewichte",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "GewichtsÃ¤nderung",
      "Korrektur",
      "Lernrate"
    ],
    "difficulty": 3
  },
  {
    "id": "q_818",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "Die Ausgabe o â±¼ ist eine Verkettung mehrerer Funktionen â€“ beginnend mit dem Netzeingang (net), gefolgt von der Aktivierungsfunktion und anschlieÃŸend der Ausgabefunktion",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Die Ausgabe o â±¼ ist eine Verkettung mehrerer Funktionen â€“ beginnend mit dem Netzeingang (net), gefolgt von der Aktivierungsfunktion und anschlieÃŸend der Ausgabefunktion",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Die",
      "Ausgabe",
      "Verkettung"
    ],
    "difficulty": 3
  },
  {
    "id": "q_819",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die partielle Ableitung âˆ‚E/âˆ‚w â‚áµ¢â±¼â‚ kann mithilfe der Kettenregel in drei Teile zerlegt werden: Î”wâ‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§1",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die partielle Ableitung âˆ‚E/âˆ‚w â‚áµ¢â±¼â‚ kann mithilfe der Kettenregel in drei Teile zerlegt werden: Î”wâ‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§1",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 112,
    "tags": [
      "Die",
      "Ableitung",
      "Kettenregel"
    ],
    "difficulty": 3
  },
  {
    "id": "q_820",
    "question": "Welche Aussage Ã¼ber Die ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Die logistische ( sigmoid) Aktivierungsfunktion ist eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Die logistische ( sigmoid) Aktivierungsfunktion ist eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Die",
      "Aktivierungsfunktion",
      "Aktivierungsfunktionen"
    ],
    "difficulty": 3
  },
  {
    "id": "q_821",
    "question": "Welche Aussage Ã¼ber Machine ist korrekt?",
    "type": "single",
    "options": [
      "Machine Learning Beispiel: Logistische Aktivierungsfunktion",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Beispiel: Logistische Aktivierungsfunktion",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Machine",
      "Learning",
      "Beispiel"
    ],
    "difficulty": 3
  },
  {
    "id": "q_822",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Beispiel: Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS ï‚§Beispiel: Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 115,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_823",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Gesamtfehler eines neuronalen Netzes wird definiert als: E = Â½ Î£(t â±¼ - oâ±¼)Â² â†’ Differenz zwischen Soll - und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Gesamtfehler eines neuronalen Netzes wird definiert als: E = Â½ Î£(t â±¼ - oâ±¼)Â² â†’ Differenz zwischen Soll - und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Der",
      "Gesamtfehler",
      "Netzes"
    ],
    "difficulty": 3
  },
  {
    "id": "q_824",
    "question": "Welche Aussage Ã¼ber Einsetzen ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Einsetzen in die Backpropagation-Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Einsetzen in die Backpropagation-Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Einsetzen",
      "Backpropagation",
      "Regel"
    ],
    "difficulty": 3
  },
  {
    "id": "q_825",
    "question": "Welche Aussage Ã¼ber Training ist korrekt?",
    "type": "single",
    "options": [
      "212 -215) Training -Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "212 -215) Training -Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 117,
    "tags": [
      "Training",
      "Ausgabe",
      "Der"
    ],
    "difficulty": 3
  },
  {
    "id": "q_826",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "com//17/a- step- by-step- backpropagation- example/comment -page- 16/#comments Der Gesamtfehler ist die Summe aller Fehler der Ausgabeneuronen",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "com//17/a- step- by-step- backpropagation- example/comment -page- 16/#comments Der Gesamtfehler ist die Summe aller Fehler der Ausgabeneuronen",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 118,
    "tags": [
      "Der",
      "Gesamtfehler",
      "Summe"
    ],
    "difficulty": 3
  },
  {
    "id": "q_827",
    "question": "Welche Aussage Ã¼ber In ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§In den versteckten Schichten (Hidden Layers) wird der Fehler nicht direkt durch den Sollwert bestimmt, sondern muss Ã¼ber die Fehler der nachfolgenden Schichten zurÃ¼ckpropagiert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§In den versteckten Schichten (Hidden Layers) wird der Fehler nicht direkt durch den Sollwert bestimmt, sondern muss Ã¼ber die Fehler der nachfolgenden Schichten zurÃ¼ckpropagiert werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "In",
      "Schichten",
      "Hidden"
    ],
    "difficulty": 3
  },
  {
    "id": "q_828",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Fehler âˆ‚E/âˆ‚oâ±¼ ergibt sich daher aus der Summe der Fehler der nachfolgenden Neuronen (Index k):âˆ‚E/âˆ‚o â±¼ = Î£â‚â‚–â‚ (Î´â‚– Â· wâ±¼â‚–) ï‚§Dabei ist Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Fehler âˆ‚E/âˆ‚oâ±¼ ergibt sich daher aus der Summe der Fehler der nachfolgenden Neuronen (Index k):âˆ‚E/âˆ‚o â±¼ = Î£â‚â‚–â‚ (Î´â‚– Â· wâ±¼â‚–) ï‚§Dabei ist Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Der",
      "Fehler",
      "Summe"
    ],
    "difficulty": 3
  },
  {
    "id": "q_829",
    "question": "Welche Aussage Ã¼ber Damit ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Damit kann der Fehlerterm fÃ¼r jedes Hidden Neuron berechnet und rÃ¼ckwÃ¤rts propagiert werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Damit kann der Fehlerterm fÃ¼r jedes Hidden Neuron berechnet und rÃ¼ckwÃ¤rts propagiert werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Damit",
      "Fehlerterm",
      "Hidden"
    ],
    "difficulty": 3
  },
  {
    "id": "q_830",
    "question": "Welche Aussage Ã¼ber Diese ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Diese RÃ¼ckwÃ¤rtsweitergabe der Fehler ermÃ¶glicht das Training tiefer neuronaler Netze",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Diese RÃ¼ckwÃ¤rtsweitergabe der Fehler ermÃ¶glicht das Training tiefer neuronaler Netze",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Diese",
      "RÃ¼ckwÃ¤rtsweitergabe",
      "Fehler"
    ],
    "difficulty": 3
  },
  {
    "id": "q_831",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "212- 215) ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0 Der Index k bezeichnet die nÃ¤chste Schicht, j ist der Index der aktuell betrachteten Schicht",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "212- 215) ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0 Der Index k bezeichnet die nÃ¤chste Schicht, j ist der Index der aktuell betrachteten Schicht",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 120,
    "tags": [
      "Der",
      "Index",
      "Schicht"
    ],
    "difficulty": 3
  },
  {
    "id": "q_832",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Logistic function used tanh function usedMachine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Logistic function used tanh function usedMachine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 122,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_833",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "com/ /17/a-step-by -step- backpropagation-example/comment -page-16/#comments ï‚§Das verwendete Tool ist GeoGebra",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "com/ /17/a-step-by -step- backpropagation-example/comment -page-16/#comments ï‚§Das verwendete Tool ist GeoGebra",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 124,
    "tags": [
      "Das",
      "Tool"
    ],
    "difficulty": 3
  },
  {
    "id": "q_834",
    "question": "Welche Aussage Ã¼ber Das ist korrekt?",
    "type": "single",
    "options": [
      "org/classic/dyq 2rcup ï‚§Das Beispiel kann entweder von der Website heruntergeladen oder interaktiv online verwendet werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "org/classic/dyq 2rcup ï‚§Das Beispiel kann entweder von der Website heruntergeladen oder interaktiv online verwendet werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 124,
    "tags": [
      "Das",
      "Beispiel",
      "Website"
    ],
    "difficulty": 3
  },
  {
    "id": "q_835",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Quickprop ï‚§Die Fehlerfunktion wird lokal besser durch eine quadratische Funktion angenÃ¤hert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Quickprop ï‚§Die Fehlerfunktion wird lokal besser durch eine quadratische Funktion angenÃ¤hert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 129,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_836",
    "question": "Welche Aussage Ã¼ber Dabei ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Dabei ist w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Dabei ist w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 129,
    "tags": [
      "Dabei",
      "Gewicht",
      "Neurons"
    ],
    "difficulty": 3
  },
  {
    "id": "q_837",
    "question": "Welche Aussage Ã¼ber Back ist korrekt?",
    "type": "single",
    "options": [
      "Back percolation ï‚§Beim klassischen Backpropagation werden die GewichtsÃ¤nderungen von Schicht zu Schicht nach hinten immer kleiner â€“ die Gewichte der ersten Schichten Ã¤ndern sich daher meist nur minimal",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Back percolation ï‚§Beim klassischen Backpropagation werden die GewichtsÃ¤nderungen von Schicht zu Schicht nach hinten immer kleiner â€“ die Gewichte der ersten Schichten Ã¤ndern sich daher meist nur minimal",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 130,
    "tags": [
      "Back",
      "Beim",
      "Backpropagation"
    ],
    "difficulty": 3
  },
  {
    "id": "q_838",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Learning Rate Î» (Î·)â€“Hyperparameter ï‚§Diese muss manuell gewÃ¤hlt werden",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26Learning Rate Î» (Î·)â€“Hyperparameter ï‚§Diese muss manuell gewÃ¤hlt werden",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_839",
    "question": "Welche Aussage Ã¼ber Der ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Der Wert der Lernrate beeinflusst, ob und wie schnell ein akzeptabler Fehler (Loss) erreicht wird",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Der Wert der Lernrate beeinflusst, ob und wie schnell ein akzeptabler Fehler (Loss) erreicht wird",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Der",
      "Wert",
      "Lernrate"
    ],
    "difficulty": 3
  },
  {
    "id": "q_840",
    "question": "Welche Aussage Ã¼ber Verbesserungen ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Verbesserungen sind mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Verbesserungen sind mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Verbesserungen",
      "Einsatz",
      "Optimierungsverfahren"
    ],
    "difficulty": 3
  },
  {
    "id": "q_841",
    "question": "Welche Aussage Ã¼ber Dadurch ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Dadurch wird der Lernprozess geglÃ¤ttet und Richtungstrends aus frÃ¼heren Schritten beibehalten â€“dieses Verfahren ist als â€Momentum -Termâ€œ bekannt",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Dadurch wird der Lernprozess geglÃ¤ttet und Richtungstrends aus frÃ¼heren Schritten beibehalten â€“dieses Verfahren ist als â€Momentum -Termâ€œ bekannt",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Dadurch",
      "Lernprozess",
      "Richtungstrends"
    ],
    "difficulty": 3
  },
  {
    "id": "q_842",
    "question": "Welche Aussage Ã¼ber Klemens ist korrekt?",
    "type": "single",
    "options": [
      "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26AdaGrad ï‚§Passt die Lernrate adaptiv fÃ¼r jede Dimension an â€“ steilere Dimensionen werden schneller skaliert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "Klemens WaldhÃ¶r / Big Data & Data Science WS 2025/26AdaGrad ï‚§Passt die Lernrate adaptiv fÃ¼r jede Dimension an â€“ steilere Dimensionen werden schneller skaliert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 132,
    "tags": [
      "Klemens",
      "WaldhÃ¶r",
      "Big"
    ],
    "difficulty": 3
  },
  {
    "id": "q_843",
    "question": "Welche Aussage Ã¼ber FÃ¼r ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§FÃ¼r tiefe neuronale Netze meist nicht empfehlenswert",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§FÃ¼r tiefe neuronale Netze meist nicht empfehlenswert",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 132,
    "tags": [
      "FÃ¼r",
      "Netze"
    ],
    "difficulty": 3
  },
  {
    "id": "q_844",
    "question": "Welche Aussage Ã¼ber Einer ist korrekt?",
    "type": "single",
    "options": [
      "ï‚§Einer der heute am hÃ¤ufigsten verwendeten Optimierer fÃ¼r tiefe neuronale Netze",
      "Diese Information ist nicht in den Quellen enthalten",
      "Das Gegenteil ist der Fall",
      "Keine Aussage mÃ¶glich"
    ],
    "correct_answer": 0,
    "explanation": "ï‚§Einer der heute am hÃ¤ufigsten verwendeten Optimierer fÃ¼r tiefe neuronale Netze",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 132,
    "tags": [
      "Einer",
      "Optimierer",
      "Netze"
    ],
    "difficulty": 3
  },
  {
    "id": "q_845",
    "question": "Was ist Werk?",
    "type": "single",
    "options": [
      "urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Werk: urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 2,
    "tags": [
      "Werk"
    ],
    "difficulty": 2
  },
  {
    "id": "q_846",
    "question": "Richtig oder Falsch: Werk urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Werk: urheberrechtlich geschÃ¼tzt und nur fÃ¼r den persÃ¶nlichen Gebrauch im Rahmen der Veranstaltungen der FOM bestimmt.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 2,
    "tags": [
      "Werk"
    ],
    "difficulty": 1
  },
  {
    "id": "q_847",
    "question": "Was ist Datensatz?",
    "type": "single",
    "options": [
      "Sample ï‚§Attribute eines Samples = Features ï‚§Anzahl der Features = Anzahl der Dimensionen im NN=Hypothesenraum Visualisierung, Playgrounds ï‚§https://playground.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Datensatz: Sample ï‚§Attribute eines Samples = Features ï‚§Anzahl der Features = Anzahl der Dimensionen im NN=Hypothesenraum Visualisierung, Playgrounds ï‚§https://playground.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 6,
    "tags": [
      "Datensatz"
    ],
    "difficulty": 2
  },
  {
    "id": "q_848",
    "question": "Richtig oder Falsch: Datensatz Sample ï‚§Attribute eines Samples = Features ï‚§Anzahl der Features = Anzahl der Dimensionen im NN=Hypothesenraum Visualisierung, Playgrounds ï‚§https://playground.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Datensatz: Sample ï‚§Attribute eines Samples = Features ï‚§Anzahl der Features = Anzahl der Dimensionen im NN=Hypothesenraum Visualisierung, Playgrounds ï‚§https://playground.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 6,
    "tags": [
      "Datensatz"
    ],
    "difficulty": 1
  },
  {
    "id": "q_849",
    "question": "Was ist Nicht?",
    "type": "single",
    "options": [
      "linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Nicht: linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 14,
    "tags": [
      "Nicht"
    ],
    "difficulty": 2
  },
  {
    "id": "q_850",
    "question": "Richtig oder Falsch: Nicht linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Nicht: linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 14,
    "tags": [
      "Nicht"
    ],
    "difficulty": 1
  },
  {
    "id": "q_851",
    "question": "Was ist Problemenichtlinear?",
    "type": "single",
    "options": [
      "(ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Problemenichtlinear: (ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 14,
    "tags": [
      "Problemenichtlinear"
    ],
    "difficulty": 2
  },
  {
    "id": "q_852",
    "question": "Richtig oder Falsch: Problemenichtlinear (ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Problemenichtlinear: (ein Menge linearer Funktionen ist auch eine lineare Funktion)Sigmoid â€¢Nicht -linear â€¢Neigt zu verschwindendenGradienten(Lernen hÃ¶rt auf, wenn die Werte von x sehr klein oder sehr groÃŸ werden) tanh â€¢Nicht -linear â€¢Ã„hnlich dem Sigmoid â€¢Weniger anfÃ¤llig fÃ¼r verschwindendeGradienten ( vanishing gradients )Rectified Linear Unit ( ReLU) â€¢Nicht -lineare â€¢Meistgenutzte Aktivierungsfunktion â€¢Vereinfacht den Gradientenabstieg in tiefen Netzen(Deep Networks )ğ’‡ğ’‡(ğ‘¥ğ‘¥)=ğ‘šğ‘šğ‘¥ğ‘¥ ğ’‡ğ’‡(ğ‘¥ğ‘¥)=1 1+ğ‘¤ğ‘¤âˆ’ğ‘¥ğ‘¥ ğ’‡ğ’‡ğ‘¥ğ‘¥=tanhğ‘¥ğ‘¥=2 1+ğ‘¤ğ‘¤âˆ’2ğ‘¥ğ‘¥âˆ’1 ğ’‡ğ’‡ğ‘¥ğ‘¥=ï¿½0,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥<0 ğ‘¥ğ‘¥,ğ‘“ğ‘“ğ‘œğ‘œğ‘“ğ‘“ ğ‘¥ğ‘¥â‰¥0 https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 14,
    "tags": [
      "Problemenichtlinear"
    ],
    "difficulty": 1
  },
  {
    "id": "q_853",
    "question": "Was ist Ãœbertragungs?",
    "type": "single",
    "options": [
      "und Aktivierungsfunktionen (unter Verwendung der Gewichte) ï‚§Ãœbergabe der Ergebnisse an die nÃ¤chste Schicht (versteckte Schicht oder Ausgabeschicht) ï‚§Die KomplexitÃ¤t eines neuronalen Netzmodells nimmt mit der Anzahl der verborgenen Schichten zu Ausgabeschicht ï‚§Umwandlung der Ergebnisse aus der vorherigen versteckten Schicht in die gewÃ¼nschte Ausgabe (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ãœbertragungs: und Aktivierungsfunktionen (unter Verwendung der Gewichte) ï‚§Ãœbergabe der Ergebnisse an die nÃ¤chste Schicht (versteckte Schicht oder Ausgabeschicht) ï‚§Die KomplexitÃ¤t eines neuronalen Netzmodells nimmt mit der Anzahl der verborgenen Schichten zu Ausgabeschicht ï‚§Umwandlung der Ergebnisse aus der vorherigen versteckten Schicht in die gewÃ¼nschte Ausgabe (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 16,
    "tags": [
      "Ãœbertragungs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_854",
    "question": "Richtig oder Falsch: Ãœbertragungs und Aktivierungsfunktionen (unter Verwendung der Gewichte) ï‚§Ãœbergabe der Ergebnisse an die nÃ¤chste Schicht (versteckte Schicht oder Ausgabeschicht) ï‚§Die KomplexitÃ¤t eines neuronalen Netzmodells nimmt mit der Anzahl der verborgenen Schichten zu Ausgabeschicht ï‚§Umwandlung der Ergebnisse aus der vorherigen versteckten Schicht in die gewÃ¼nschte Ausgabe (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ãœbertragungs: und Aktivierungsfunktionen (unter Verwendung der Gewichte) ï‚§Ãœbergabe der Ergebnisse an die nÃ¤chste Schicht (versteckte Schicht oder Ausgabeschicht) ï‚§Die KomplexitÃ¤t eines neuronalen Netzmodells nimmt mit der Anzahl der verborgenen Schichten zu Ausgabeschicht ï‚§Umwandlung der Ergebnisse aus der vorherigen versteckten Schicht in die gewÃ¼nschte Ausgabe (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 16,
    "tags": [
      "Ãœbertragungs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_855",
    "question": "Was ist Cross?",
    "type": "single",
    "options": [
      "Entropy - Loss) bewertet werden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Cross: Entropy - Loss) bewertet werden.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Cross"
    ],
    "difficulty": 2
  },
  {
    "id": "q_856",
    "question": "Richtig oder Falsch: Cross Entropy - Loss) bewertet werden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Cross: Entropy - Loss) bewertet werden.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Cross"
    ],
    "difficulty": 1
  },
  {
    "id": "q_857",
    "question": "Was ist Schicht?",
    "type": "single",
    "options": [
      "mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\".",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Schicht: mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\".",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Schicht"
    ],
    "difficulty": 2
  },
  {
    "id": "q_858",
    "question": "Richtig oder Falsch: Schicht mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\".",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Schicht: mit allen Neuronen der vorhergehenden Schicht \"vollstÃ¤ndig verbunden\".",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 18,
    "tags": [
      "Schicht"
    ],
    "difficulty": 1
  },
  {
    "id": "q_859",
    "question": "Was ist Back?",
    "type": "single",
    "options": [
      "propagationVorwÃ¤rtspropagation 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Back: propagationVorwÃ¤rtspropagation 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 19,
    "tags": [
      "Back"
    ],
    "difficulty": 2
  },
  {
    "id": "q_860",
    "question": "Richtig oder Falsch: Back propagationVorwÃ¤rtspropagation 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Back: propagationVorwÃ¤rtspropagation 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 19,
    "tags": [
      "Back"
    ],
    "difficulty": 1
  },
  {
    "id": "q_861",
    "question": "Was ist VorwÃ¤rts?",
    "type": "single",
    "options": [
      "RÃ¼ckwÃ¤rts-Zyklus fÃ¼r die nÃ¤chste Probe (bis zur Konvergenz).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "VorwÃ¤rts: RÃ¼ckwÃ¤rts-Zyklus fÃ¼r die nÃ¤chste Probe (bis zur Konvergenz).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 19,
    "tags": [
      "VorwÃ¤rts"
    ],
    "difficulty": 2
  },
  {
    "id": "q_862",
    "question": "Richtig oder Falsch: VorwÃ¤rts RÃ¼ckwÃ¤rts-Zyklus fÃ¼r die nÃ¤chste Probe (bis zur Konvergenz).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. VorwÃ¤rts: RÃ¼ckwÃ¤rts-Zyklus fÃ¼r die nÃ¤chste Probe (bis zur Konvergenz).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 19,
    "tags": [
      "VorwÃ¤rts"
    ],
    "difficulty": 1
  },
  {
    "id": "q_863",
    "question": "Was ist Delta?",
    "type": "single",
    "options": [
      "Regel (einfaches Perzeptron ) ğ’ğ’ğ’ğ’ğ’ğ’ =ï¿½ ğ’Šğ’Šğ’ğ’ ğ’˜ğ’˜ğ’Šğ’Šï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Delta: Regel (einfaches Perzeptron ) ğ’ğ’ğ’ğ’ğ’ğ’ =ï¿½ ğ’Šğ’Šğ’ğ’ ğ’˜ğ’˜ğ’Šğ’Šï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Delta"
    ],
    "difficulty": 2
  },
  {
    "id": "q_864",
    "question": "Richtig oder Falsch: Delta Regel (einfaches Perzeptron ) ğ’ğ’ğ’ğ’ğ’ğ’ =ï¿½ ğ’Šğ’Šğ’ğ’ ğ’˜ğ’˜ğ’Šğ’Šï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Delta: Regel (einfaches Perzeptron ) ğ’ğ’ğ’ğ’ğ’ğ’ =ï¿½ ğ’Šğ’Šğ’ğ’ ğ’˜ğ’˜ğ’Šğ’Šï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Delta"
    ],
    "difficulty": 1
  },
  {
    "id": "q_865",
    "question": "Was ist Fehler?",
    "type": "single",
    "options": [
      "Training - Vorhersageğ’˜ğ’˜â€² = neues Gewicht ğ’˜ğ’˜ = altes Gewicht ğ€ğ€ (lambda ) = Lernrate ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Fehler: Training - Vorhersageğ’˜ğ’˜â€² = neues Gewicht ğ’˜ğ’˜ = altes Gewicht ğ€ğ€ (lambda ) = Lernrate ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Fehler"
    ],
    "difficulty": 2
  },
  {
    "id": "q_866",
    "question": "Richtig oder Falsch: Fehler Training - Vorhersageğ’˜ğ’˜â€² = neues Gewicht ğ’˜ğ’˜ = altes Gewicht ğ€ğ€ (lambda ) = Lernrate ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Fehler: Training - Vorhersageğ’˜ğ’˜â€² = neues Gewicht ğ’˜ğ’˜ = altes Gewicht ğ€ğ€ (lambda ) = Lernrate ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Fehler"
    ],
    "difficulty": 1
  },
  {
    "id": "q_867",
    "question": "Was ist Eingabewert Die Delta?",
    "type": "single",
    "options": [
      "Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Eingabewert Die Delta: Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Eingabewert Die Delta"
    ],
    "difficulty": 2
  },
  {
    "id": "q_868",
    "question": "Richtig oder Falsch: Eingabewert Die Delta Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Eingabewert Die Delta: Regel passt die Gewichte so an, dass die Differenz zwischen dem Soll -Wert (tâ‚“) und dem tatsÃ¤chlichen Ausgabewert (oâ‚“) kleiner wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 21,
    "tags": [
      "Eingabewert Die Delta"
    ],
    "difficulty": 1
  },
  {
    "id": "q_869",
    "question": "Was ist Regel?",
    "type": "single",
    "options": [
      "w'= w+lambda* oi*(tx-ox) Lernrate Lambda 0,200 Delta Regel: Logisches And, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Regel: w'= w+lambda* oi*(tx-ox) Lernrate Lambda 0,200 Delta Regel: Logisches And, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 23,
    "tags": [
      "Regel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_870",
    "question": "Richtig oder Falsch: Regel w'= w+lambda* oi*(tx-ox) Lernrate Lambda 0,200 Delta Regel: Logisches And, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Regel: w'= w+lambda* oi*(tx-ox) Lernrate Lambda 0,200 Delta Regel: Logisches And, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 23,
    "tags": [
      "Regel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_871",
    "question": "Was ist Input?",
    "type": "single",
    "options": [
      "neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Input: neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 23,
    "tags": [
      "Input"
    ],
    "difficulty": 2
  },
  {
    "id": "q_872",
    "question": "Richtig oder Falsch: Input neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Input: neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 23,
    "tags": [
      "Input"
    ],
    "difficulty": 1
  },
  {
    "id": "q_873",
    "question": "Was ist Regel?",
    "type": "single",
    "options": [
      "w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches OR, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches OR, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 24,
    "tags": [
      "Regel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_874",
    "question": "Richtig oder Falsch: Regel w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches OR, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches OR, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 24,
    "tags": [
      "Regel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_875",
    "question": "Was ist Input?",
    "type": "single",
    "options": [
      "neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Input: neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 24,
    "tags": [
      "Input"
    ],
    "difficulty": 2
  },
  {
    "id": "q_876",
    "question": "Richtig oder Falsch: Input neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Input: neuronen- SchichtwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 1 0,000 0 1,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 24,
    "tags": [
      "Input"
    ],
    "difficulty": 1
  },
  {
    "id": "q_877",
    "question": "Was ist Machine Learning Aufgabe?",
    "type": "single",
    "options": [
      "Grenzen (Limitierungen) einfacher Perzeptrons Wende Deltaregel auf xor an Implementiere in Excel, Python, â€¦A Â¬A A B A B A B A â†’ B A â†” B T F T T T T T T F T T F F T F F F T F T T F F F F F T T A B A B A | B A B T T F F F T F T T F F T T T F F F F T Tğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜â€² = neues Gewicht, ğ’˜ğ’˜ = altes Gewicht, ğ€ğ€ (lambda ) = Lernrate, ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Aufgabe: Grenzen (Limitierungen) einfacher Perzeptrons Wende Deltaregel auf xor an Implementiere in Excel, Python, â€¦A Â¬A A B A B A B A â†’ B A â†” B T F T T T T T T F T T F F T F F F T F T T F F F F F T T A B A B A | B A B T T F F F T F T T F F T T T F F F F T Tğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜â€² = neues Gewicht, ğ’˜ğ’˜ = altes Gewicht, ğ€ğ€ (lambda ) = Lernrate, ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 25,
    "tags": [
      "Machine Learning Aufgabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_878",
    "question": "Richtig oder Falsch: Machine Learning Aufgabe Grenzen (Limitierungen) einfacher Perzeptrons Wende Deltaregel auf xor an Implementiere in Excel, Python, â€¦A Â¬A A B A B A B A â†’ B A â†” B T F T T T T T T F T T F F T F F F T F T T F F F F F T T A B A B A | B A B T T F F F T F T T F F T T T F F F F T Tğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜â€² = neues Gewicht, ğ’˜ğ’˜ = altes Gewicht, ğ€ğ€ (lambda ) = Lernrate, ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Aufgabe: Grenzen (Limitierungen) einfacher Perzeptrons Wende Deltaregel auf xor an Implementiere in Excel, Python, â€¦A Â¬A A B A B A B A â†’ B A â†” B T F T T T T T T F T T F F T F F F T F T T F F F F F T T A B A B A | B A B T T F F F T F T T F F T T T F F F F T Tğ’˜ğ’˜ğ’Šğ’Šâ€²=ğ’˜ğ’˜ğ’Šğ’Š+ğ€ğ€ï¿½(ğ’ğ’ğ’™ğ’™âˆ’ğ’ğ’ğ’™ğ’™)ï¿½ğ’ğ’ğ’Šğ’Š ğ’˜ğ’˜â€² = neues Gewicht, ğ’˜ğ’˜ = altes Gewicht, ğ€ğ€ (lambda ) = Lernrate, ğ’ğ’â‚“ = Trainingslabel (Soll- bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 25,
    "tags": [
      "Machine Learning Aufgabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_879",
    "question": "Was ist Machine Learning Aufgabe?",
    "type": "single",
    "options": [
      "Grenzen (Limitierungen) einfacher Perzeptrons Anpassung der Gewichte nach der Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches xor, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Aufgabe: Grenzen (Limitierungen) einfacher Perzeptrons Anpassung der Gewichte nach der Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches xor, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 26,
    "tags": [
      "Machine Learning Aufgabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_880",
    "question": "Richtig oder Falsch: Machine Learning Aufgabe Grenzen (Limitierungen) einfacher Perzeptrons Anpassung der Gewichte nach der Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches xor, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Aufgabe: Grenzen (Limitierungen) einfacher Perzeptrons Anpassung der Gewichte nach der Regel: w'=w+lambda*oi*(tx -ox) Lernrate Lambda 0,200 Delta Regel: Logisches xor, Activation ox: Aktivierungsfunktion = 0 wenn Net < 0.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 26,
    "tags": [
      "Machine Learning Aufgabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_881",
    "question": "Was ist Input?",
    "type": "single",
    "options": [
      "neuronenwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 0 0,000 0 0,0001 2 0,000 Gewichte nach 1.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Input: neuronenwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 0 0,000 0 0,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 26,
    "tags": [
      "Input"
    ],
    "difficulty": 2
  },
  {
    "id": "q_882",
    "question": "Richtig oder Falsch: Input neuronenwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 0 0,000 0 0,0001 2 0,000 Gewichte nach 1.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Input: neuronenwOutput - neurontx training labelNet = wi*oi ox Delta tx -ox Startphase - Gewicht 01 1 0,0001 0 0,000 0 0,0001 2 0,000 Gewichte nach 1.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 26,
    "tags": [
      "Input"
    ],
    "difficulty": 1
  },
  {
    "id": "q_883",
    "question": "Was ist Perzeptrons?",
    "type": "single",
    "options": [
      "auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Perzeptrons: auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 27,
    "tags": [
      "Perzeptrons"
    ],
    "difficulty": 2
  },
  {
    "id": "q_884",
    "question": "Richtig oder Falsch: Perzeptrons auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Perzeptrons: auf linear trennbare Probleme beschrÃ¤nkt und kÃ¶nnen keine komplexen Muster oder nichtlinearen ZusammenhÃ¤nge erfassen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 27,
    "tags": [
      "Perzeptrons"
    ],
    "difficulty": 1
  },
  {
    "id": "q_885",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "Das XOR -Problem kann ein einfaches Perzeptron nicht lÃ¶sen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: Das XOR -Problem kann ein einfaches Perzeptron nicht lÃ¶sen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_886",
    "question": "Richtig oder Falsch: Beispiel Das XOR -Problem kann ein einfaches Perzeptron nicht lÃ¶sen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: Das XOR -Problem kann ein einfaches Perzeptron nicht lÃ¶sen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_887",
    "question": "Was ist Eingabe?",
    "type": "single",
    "options": [
      "und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Eingabe: und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Eingabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_888",
    "question": "Richtig oder Falsch: Eingabe und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Eingabe: und Ausgabeschicht â†’ keine Hierarchie oder Abstraktion.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Eingabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_889",
    "question": "Was ist Delta?",
    "type": "single",
    "options": [
      "Regel) ï‚§Die Anpassung erfolgt nur lokal und linear; es gibt keine RÃ¼ckpropagation von Fehlern durch mehrere Schichten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Delta: Regel) ï‚§Die Anpassung erfolgt nur lokal und linear; es gibt keine RÃ¼ckpropagation von Fehlern durch mehrere Schichten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Delta"
    ],
    "difficulty": 2
  },
  {
    "id": "q_890",
    "question": "Richtig oder Falsch: Delta Regel) ï‚§Die Anpassung erfolgt nur lokal und linear; es gibt keine RÃ¼ckpropagation von Fehlern durch mehrere Schichten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Delta: Regel) ï‚§Die Anpassung erfolgt nur lokal und linear; es gibt keine RÃ¼ckpropagation von Fehlern durch mehrere Schichten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Delta"
    ],
    "difficulty": 1
  },
  {
    "id": "q_891",
    "question": "Was ist Keine GedÃ¤chtnis?",
    "type": "single",
    "options": [
      "oder KontextfÃ¤higkeit ï‚§Es berÃ¼cksichtigt keine zeitlichen oder sequentiellen AbhÃ¤ngigkeiten (im Gegensatz zu rekurrenten Netzen).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Keine GedÃ¤chtnis: oder KontextfÃ¤higkeit ï‚§Es berÃ¼cksichtigt keine zeitlichen oder sequentiellen AbhÃ¤ngigkeiten (im Gegensatz zu rekurrenten Netzen).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Keine GedÃ¤chtnis"
    ],
    "difficulty": 2
  },
  {
    "id": "q_892",
    "question": "Richtig oder Falsch: Keine GedÃ¤chtnis oder KontextfÃ¤higkeit ï‚§Es berÃ¼cksichtigt keine zeitlichen oder sequentiellen AbhÃ¤ngigkeiten (im Gegensatz zu rekurrenten Netzen).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Keine GedÃ¤chtnis: oder KontextfÃ¤higkeit ï‚§Es berÃ¼cksichtigt keine zeitlichen oder sequentiellen AbhÃ¤ngigkeiten (im Gegensatz zu rekurrenten Netzen).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 28,
    "tags": [
      "Keine GedÃ¤chtnis"
    ],
    "difficulty": 1
  },
  {
    "id": "q_893",
    "question": "Was ist Vorhersage?",
    "type": "single",
    "options": [
      "> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Vorhersage: > nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Vorhersage"
    ],
    "difficulty": 2
  },
  {
    "id": "q_894",
    "question": "Richtig oder Falsch: Vorhersage > nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Vorhersage: > nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Vorhersage"
    ],
    "difficulty": 1
  },
  {
    "id": "q_895",
    "question": "Was ist Training?",
    "type": "single",
    "options": [
      "teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Training: teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Training"
    ],
    "difficulty": 2
  },
  {
    "id": "q_896",
    "question": "Richtig oder Falsch: Training teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Training: teuer (erfordert normalerweise GPUs) ï‚§hoher Speicherbedarf und Rechenaufwand des Modells wÃ¤hrend des Trainings und der Vorhersage -> nicht fÃ¼r GerÃ¤te mit geringer Leistung geeignet ï‚§Es gibt eine Vielzahl von CPU - und GPU -basierten Frameworks fÃ¼r das einfache Training von Deep Networks (Tensorflow, Keras, Theano, Caffe , .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 31,
    "tags": [
      "Training"
    ],
    "difficulty": 1
  },
  {
    "id": "q_897",
    "question": "Was ist Perceptrons?",
    "type": "single",
    "options": [
      "nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Perceptrons: nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 32,
    "tags": [
      "Perceptrons"
    ],
    "difficulty": 2
  },
  {
    "id": "q_898",
    "question": "Richtig oder Falsch: Perceptrons nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Perceptrons: nicht geeignet fÃ¼r hochdimensionale Eingabedaten (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 32,
    "tags": [
      "Perceptrons"
    ],
    "difficulty": 1
  },
  {
    "id": "q_899",
    "question": "Was ist Convolution Layer?",
    "type": "single",
    "options": [
      "Architektur ï‚§ConvNet, CNN ï‚§â€Flache NNsâ€œ kÃ¶nnen Bilder (2- dimensional) nur schwer korrekt abbilden 33 Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Convolution Layer: Architektur ï‚§ConvNet, CNN ï‚§â€Flache NNsâ€œ kÃ¶nnen Bilder (2- dimensional) nur schwer korrekt abbilden 33 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 33,
    "tags": [
      "Convolution Layer"
    ],
    "difficulty": 2
  },
  {
    "id": "q_900",
    "question": "Richtig oder Falsch: Convolution Layer Architektur ï‚§ConvNet, CNN ï‚§â€Flache NNsâ€œ kÃ¶nnen Bilder (2- dimensional) nur schwer korrekt abbilden 33 Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Convolution Layer: Architektur ï‚§ConvNet, CNN ï‚§â€Flache NNsâ€œ kÃ¶nnen Bilder (2- dimensional) nur schwer korrekt abbilden 33 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 33,
    "tags": [
      "Convolution Layer"
    ],
    "difficulty": 1
  },
  {
    "id": "q_901",
    "question": "Was ist Machine Learning Artificial Neural Networks?",
    "type": "single",
    "options": [
      "CNN https://towardsdatascience.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Artificial Neural Networks: CNN https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 33,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 2
  },
  {
    "id": "q_902",
    "question": "Richtig oder Falsch: Machine Learning Artificial Neural Networks CNN https://towardsdatascience.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Artificial Neural Networks: CNN https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 33,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 1
  },
  {
    "id": "q_903",
    "question": "Was ist Machine Learning Artificial Neural Networks?",
    "type": "single",
    "options": [
      "CNN Convolution Layer / Filter ï‚§Filter (Gewichte der Neuronen; Convolution- Kernel) sollen bestimmte Eigenschaften des Bildes betonen, z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Artificial Neural Networks: CNN Convolution Layer / Filter ï‚§Filter (Gewichte der Neuronen; Convolution- Kernel) sollen bestimmte Eigenschaften des Bildes betonen, z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 34,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 2
  },
  {
    "id": "q_904",
    "question": "Richtig oder Falsch: Machine Learning Artificial Neural Networks CNN Convolution Layer / Filter ï‚§Filter (Gewichte der Neuronen; Convolution- Kernel) sollen bestimmte Eigenschaften des Bildes betonen, z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Artificial Neural Networks: CNN Convolution Layer / Filter ï‚§Filter (Gewichte der Neuronen; Convolution- Kernel) sollen bestimmte Eigenschaften des Bildes betonen, z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 34,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 1
  },
  {
    "id": "q_905",
    "question": "Was ist Ausgabematrix?",
    "type": "single",
    "options": [
      "n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ausgabematrix: n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 34,
    "tags": [
      "Ausgabematrix"
    ],
    "difficulty": 2
  },
  {
    "id": "q_906",
    "question": "Richtig oder Falsch: Ausgabematrix n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ausgabematrix: n- i+1 Ã—m-j+1 ï‚§Der Gewichte des Kernels werden mit den passenden Werten der Eingabe- schicht multipliziert und summiert und ergeben die entsprechende Aktivierung https://www.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 34,
    "tags": [
      "Ausgabematrix"
    ],
    "difficulty": 1
  },
  {
    "id": "q_907",
    "question": "Was ist Normal?",
    "type": "single",
    "options": [
      "oder GauÃŸverteilung initialisiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Normal: oder GauÃŸverteilung initialisiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 35,
    "tags": [
      "Normal"
    ],
    "difficulty": 2
  },
  {
    "id": "q_908",
    "question": "Richtig oder Falsch: Normal oder GauÃŸverteilung initialisiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Normal: oder GauÃŸverteilung initialisiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 35,
    "tags": [
      "Normal"
    ],
    "difficulty": 1
  },
  {
    "id": "q_909",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 38,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_910",
    "question": "Richtig oder Falsch: Beispiel Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 38,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_911",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 39,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_912",
    "question": "Richtig oder Falsch: Beispiel Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: Padding 1x1 (rechts, links, oben, unten) ï‚§Conv2D(channels=1, kernel_size=(3,3), padding=(1,1))Machine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 39,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_913",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "Senkrechter StrichMachine Learning Artificial Neural Networks - CNN https://medium.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: Senkrechter StrichMachine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 40,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_914",
    "question": "Richtig oder Falsch: Beispiel Senkrechter StrichMachine Learning Artificial Neural Networks - CNN https://medium.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: Senkrechter StrichMachine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 40,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_915",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "PfeilMachine Learning Artificial Neural Networks - CNN https://medium.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: PfeilMachine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 41,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_916",
    "question": "Richtig oder Falsch: Beispiel PfeilMachine Learning Artificial Neural Networks - CNN https://medium.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: PfeilMachine Learning Artificial Neural Networks - CNN https://medium.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 41,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_917",
    "question": "Was ist Machine Learning Artificial Neural Networks?",
    "type": "single",
    "options": [
      "CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Artificial Neural Networks: CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 46,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 2
  },
  {
    "id": "q_918",
    "question": "Richtig oder Falsch: Machine Learning Artificial Neural Networks CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Artificial Neural Networks: CNN Dropout Layer ï‚§Regularisierungsmethode um Overfitting zu vermeiden ï‚§Schaltet zufÃ¤llig einen bestimmten %-Satz von Eingabeneuronen in einer Schicht aus, wird wÃ¤hrend des Trainings ignoriert (Drop-Out -Rate) ï‚§Nach dem Trainieren werden keine Neuronen weggelassen Flatten Layer ï‚§Konvertiert die Conv Schicht in eine eindimensionalen Schicht Dense Layer ï‚§Voll verbundene Schichten https://towardsdatascience.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 46,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 1
  },
  {
    "id": "q_919",
    "question": "Was ist Machine Learning Artificial Neural Networks?",
    "type": "single",
    "options": [
      "CNN Filterbeispiel MM Model Layer 0 ï‚§model.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Artificial Neural Networks: CNN Filterbeispiel MM Model Layer 0 ï‚§model.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 49,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 2
  },
  {
    "id": "q_920",
    "question": "Richtig oder Falsch: Machine Learning Artificial Neural Networks CNN Filterbeispiel MM Model Layer 0 ï‚§model.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Artificial Neural Networks: CNN Filterbeispiel MM Model Layer 0 ï‚§model.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 49,
    "tags": [
      "Machine Learning Artificial Neural Networks"
    ],
    "difficulty": 1
  },
  {
    "id": "q_921",
    "question": "Was ist Optimierung Neuraler Netze?",
    "type": "single",
    "options": [
      "Weight Pruning 60 Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimierung Neuraler Netze: Weight Pruning 60 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 60,
    "tags": [
      "Optimierung Neuraler Netze"
    ],
    "difficulty": 2
  },
  {
    "id": "q_922",
    "question": "Richtig oder Falsch: Optimierung Neuraler Netze Weight Pruning 60 Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimierung Neuraler Netze: Weight Pruning 60 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 60,
    "tags": [
      "Optimierung Neuraler Netze"
    ],
    "difficulty": 1
  },
  {
    "id": "q_923",
    "question": "Was ist Ziel?",
    "type": "single",
    "options": [
      "Reduktion ï‚§Trainingszeit ï‚§Echtzeit -Anwendungsdauer (bzw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ziel: Reduktion ï‚§Trainingszeit ï‚§Echtzeit -Anwendungsdauer (bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "Ziel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_924",
    "question": "Richtig oder Falsch: Ziel Reduktion ï‚§Trainingszeit ï‚§Echtzeit -Anwendungsdauer (bzw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ziel: Reduktion ï‚§Trainingszeit ï‚§Echtzeit -Anwendungsdauer (bzw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "Ziel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_925",
    "question": "Was ist Backpropagation?",
    "type": "single",
    "options": [
      "Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Backpropagation: Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_926",
    "question": "Richtig oder Falsch: Backpropagation Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Backpropagation: Art der Aktivierungsfunktion, Lernrate ï‚§Architektur (Schichten, Neuronen, Verbindungen) ï‚§NN-TopologieParameter ï‚§Initialisierung der Gewichte Tuning Optionen ï‚§Parameter: Koeffizienten, die das Modell selbst wÃ¤hlt(gemÃ¤ÃŸ einer vorgegebenen Optimierungsstrategie) ï‚§Hyperparameter: Parameter, die von auÃŸen festgelegt werden(z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 62,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_927",
    "question": "Was ist Ziel?",
    "type": "single",
    "options": [
      "Ãœberanpassung ( Overfitting ) vermeiden und das Modell robuster machen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ziel: Ãœberanpassung ( Overfitting ) vermeiden und das Modell robuster machen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 64,
    "tags": [
      "Ziel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_928",
    "question": "Richtig oder Falsch: Ziel Ãœberanpassung ( Overfitting ) vermeiden und das Modell robuster machen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ziel: Ãœberanpassung ( Overfitting ) vermeiden und das Modell robuster machen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 64,
    "tags": [
      "Ziel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_929",
    "question": "Was ist Eine Epoche?",
    "type": "single",
    "options": [
      "einmal alle Trainingsdaten gesehen und Gewichte angepasst.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Eine Epoche: einmal alle Trainingsdaten gesehen und Gewichte angepasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 64,
    "tags": [
      "Eine Epoche"
    ],
    "difficulty": 2
  },
  {
    "id": "q_930",
    "question": "Richtig oder Falsch: Eine Epoche einmal alle Trainingsdaten gesehen und Gewichte angepasst.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Eine Epoche: einmal alle Trainingsdaten gesehen und Gewichte angepasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 64,
    "tags": [
      "Eine Epoche"
    ],
    "difficulty": 1
  },
  {
    "id": "q_931",
    "question": "Was ist Optimizing Neural Networks Tuningoptionen?",
    "type": "single",
    "options": [
      "Gewichtspruning Problem ï‚§â€Ein n -dimensionaler WÃ¼rfel besitzt 2â¿ Ecken â€“ das heiÃŸt: in 25 Millionen Dimensionen sprechen wir von 2Â²âµâ°â°â°â°â°â°â° Punkten!",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimizing Neural Networks Tuningoptionen: Gewichtspruning Problem ï‚§â€Ein n -dimensionaler WÃ¼rfel besitzt 2â¿ Ecken â€“ das heiÃŸt: in 25 Millionen Dimensionen sprechen wir von 2Â²âµâ°â°â°â°â°â°â° Punkten!",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_932",
    "question": "Richtig oder Falsch: Optimizing Neural Networks Tuningoptionen Gewichtspruning Problem ï‚§â€Ein n -dimensionaler WÃ¼rfel besitzt 2â¿ Ecken â€“ das heiÃŸt: in 25 Millionen Dimensionen sprechen wir von 2Â²âµâ°â°â°â°â°â°â° Punkten!",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimizing Neural Networks Tuningoptionen: Gewichtspruning Problem ï‚§â€Ein n -dimensionaler WÃ¼rfel besitzt 2â¿ Ecken â€“ das heiÃŸt: in 25 Millionen Dimensionen sprechen wir von 2Â²âµâ°â°â°â°â°â°â° Punkten!",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_933",
    "question": "Was ist Zum Vergleich?",
    "type": "single",
    "options": [
      "Das Universum enthÃ¤lt schÃ¤tzungsweise nur etwa 10â¸Â² Atome.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Zum Vergleich: Das Universum enthÃ¤lt schÃ¤tzungsweise nur etwa 10â¸Â² Atome.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Zum Vergleich"
    ],
    "difficulty": 2
  },
  {
    "id": "q_934",
    "question": "Richtig oder Falsch: Zum Vergleich Das Universum enthÃ¤lt schÃ¤tzungsweise nur etwa 10â¸Â² Atome.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Zum Vergleich: Das Universum enthÃ¤lt schÃ¤tzungsweise nur etwa 10â¸Â² Atome.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Zum Vergleich"
    ],
    "difficulty": 1
  },
  {
    "id": "q_935",
    "question": "Was ist Fazit?",
    "type": "single",
    "options": [
      "Eine Reduzierung der Parameterzahl verringert sowohl die Trainingszeit als auch die AusfÃ¼hrungszeit in realen Anwendungen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Fazit: Eine Reduzierung der Parameterzahl verringert sowohl die Trainingszeit als auch die AusfÃ¼hrungszeit in realen Anwendungen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Fazit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_936",
    "question": "Richtig oder Falsch: Fazit Eine Reduzierung der Parameterzahl verringert sowohl die Trainingszeit als auch die AusfÃ¼hrungszeit in realen Anwendungen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Fazit: Eine Reduzierung der Parameterzahl verringert sowohl die Trainingszeit als auch die AusfÃ¼hrungszeit in realen Anwendungen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Fazit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_937",
    "question": "Was ist Achtung?",
    "type": "single",
    "options": [
      "Zu viele Parameter fÃ¼hren leicht zu Overfitting â€“ das Modell lernt die Trainingsdaten auswendig, statt zu generalisieren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Achtung: Zu viele Parameter fÃ¼hren leicht zu Overfitting â€“ das Modell lernt die Trainingsdaten auswendig, statt zu generalisieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Achtung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_938",
    "question": "Richtig oder Falsch: Achtung Zu viele Parameter fÃ¼hren leicht zu Overfitting â€“ das Modell lernt die Trainingsdaten auswendig, statt zu generalisieren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Achtung: Zu viele Parameter fÃ¼hren leicht zu Overfitting â€“ das Modell lernt die Trainingsdaten auswendig, statt zu generalisieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 66,
    "tags": [
      "Achtung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_939",
    "question": "Was ist Optimizing Neural Networks Tuningoptionen?",
    "type": "single",
    "options": [
      "Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimizing Neural Networks Tuningoptionen: Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_940",
    "question": "Richtig oder Falsch: Optimizing Neural Networks Tuningoptionen Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimizing Neural Networks Tuningoptionen: Gewichtspruning Optimal Brain Damage ï‚§Nur die wichtigsten Verbindungen im neuronalen Netz bleiben erhalten, die anderen werden gelÃ¶scht, um das Modell kleiner, schneller und effizienter zu machen â€“ ohne die Genauigkeit wesentlich zu beeintrÃ¤chtigen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_941",
    "question": "Was ist Wichtigkeit?",
    "type": "single",
    "options": [
      "Setze ihre Werte auf Null und belasse sie so fÃ¼r den weiteren Prozess.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Wichtigkeit: Setze ihre Werte auf Null und belasse sie so fÃ¼r den weiteren Prozess.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "Wichtigkeit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_942",
    "question": "Richtig oder Falsch: Wichtigkeit Setze ihre Werte auf Null und belasse sie so fÃ¼r den weiteren Prozess.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Wichtigkeit: Setze ihre Werte auf Null und belasse sie so fÃ¼r den weiteren Prozess.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 67,
    "tags": [
      "Wichtigkeit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_943",
    "question": "Was ist Optimizing Neural Networks Tuningoptionen?",
    "type": "single",
    "options": [
      "Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimizing Neural Networks Tuningoptionen: Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_944",
    "question": "Richtig oder Falsch: Optimizing Neural Networks Tuningoptionen Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimizing Neural Networks Tuningoptionen: Gewichtspruning Lotterie Ticket Hypothese ï‚§Diese Hypothese besagt, dass in einem groÃŸen neuronalen Netz kleinere Teilnetze existieren, die bereits optimal initialisierte Gewichte besitzen, um das gleiche Leistungsniveau zu erreichen â€“ wenn sie getrennt trainiert werden.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_945",
    "question": "Was ist Initialisierung?",
    "type": "single",
    "options": [
      "Das neuronale Netz wird zufÃ¤llig initialisiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Initialisierung: Das neuronale Netz wird zufÃ¤llig initialisiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Initialisierung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_946",
    "question": "Richtig oder Falsch: Initialisierung Das neuronale Netz wird zufÃ¤llig initialisiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Initialisierung: Das neuronale Netz wird zufÃ¤llig initialisiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Initialisierung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_947",
    "question": "Was ist Training?",
    "type": "single",
    "options": [
      "Trainiere das Netz fÃ¼r n Trainingsschritte.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Training: Trainiere das Netz fÃ¼r n Trainingsschritte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Training"
    ],
    "difficulty": 2
  },
  {
    "id": "q_948",
    "question": "Richtig oder Falsch: Training Trainiere das Netz fÃ¼r n Trainingsschritte.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Training: Trainiere das Netz fÃ¼r n Trainingsschritte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Training"
    ],
    "difficulty": 1
  },
  {
    "id": "q_949",
    "question": "Was ist Pruning?",
    "type": "single",
    "options": [
      "Entferne k % der Gewichte mit der kleinsten BetragsgrÃ¶ÃŸe (also jene mit geringster Bedeutung).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Pruning: Entferne k % der Gewichte mit der kleinsten BetragsgrÃ¶ÃŸe (also jene mit geringster Bedeutung).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Pruning"
    ],
    "difficulty": 2
  },
  {
    "id": "q_950",
    "question": "Richtig oder Falsch: Pruning Entferne k % der Gewichte mit der kleinsten BetragsgrÃ¶ÃŸe (also jene mit geringster Bedeutung).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Pruning: Entferne k % der Gewichte mit der kleinsten BetragsgrÃ¶ÃŸe (also jene mit geringster Bedeutung).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Pruning"
    ],
    "difficulty": 1
  },
  {
    "id": "q_951",
    "question": "Was ist ZurÃ¼cksetzen?",
    "type": "single",
    "options": [
      "Setze die verbleibenden Gewichte wieder auf ihre ursprÃ¼nglichen, zufÃ¤lligen Startwerte zurÃ¼ck.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "ZurÃ¼cksetzen: Setze die verbleibenden Gewichte wieder auf ihre ursprÃ¼nglichen, zufÃ¤lligen Startwerte zurÃ¼ck.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "ZurÃ¼cksetzen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_952",
    "question": "Richtig oder Falsch: ZurÃ¼cksetzen Setze die verbleibenden Gewichte wieder auf ihre ursprÃ¼nglichen, zufÃ¤lligen Startwerte zurÃ¼ck.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. ZurÃ¼cksetzen: Setze die verbleibenden Gewichte wieder auf ihre ursprÃ¼nglichen, zufÃ¤lligen Startwerte zurÃ¼ck.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "ZurÃ¼cksetzen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_953",
    "question": "Was ist Iteration?",
    "type": "single",
    "options": [
      "Wiederhole Schritt 2 und 3 â€“ trainiere und beschneide das Netz mehrfach.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Iteration: Wiederhole Schritt 2 und 3 â€“ trainiere und beschneide das Netz mehrfach.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Iteration"
    ],
    "difficulty": 2
  },
  {
    "id": "q_954",
    "question": "Richtig oder Falsch: Iteration Wiederhole Schritt 2 und 3 â€“ trainiere und beschneide das Netz mehrfach.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Iteration: Wiederhole Schritt 2 und 3 â€“ trainiere und beschneide das Netz mehrfach.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 68,
    "tags": [
      "Iteration"
    ],
    "difficulty": 1
  },
  {
    "id": "q_955",
    "question": "Was ist Optimizing Neural Networks Tuningoptionen?",
    "type": "single",
    "options": [
      "Gewichtspruning Weight Agnostic Neural Networks ï‚§Problem: Bei herkÃ¶mmlichen AnsÃ¤tzen beginnen wir mit einem groÃŸen, komplexen Netz und entfernen anschlieÃŸend Ã¼berflÃ¼ssige Gewichte (Pruning).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimizing Neural Networks Tuningoptionen: Gewichtspruning Weight Agnostic Neural Networks ï‚§Problem: Bei herkÃ¶mmlichen AnsÃ¤tzen beginnen wir mit einem groÃŸen, komplexen Netz und entfernen anschlieÃŸend Ã¼berflÃ¼ssige Gewichte (Pruning).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_956",
    "question": "Richtig oder Falsch: Optimizing Neural Networks Tuningoptionen Gewichtspruning Weight Agnostic Neural Networks ï‚§Problem: Bei herkÃ¶mmlichen AnsÃ¤tzen beginnen wir mit einem groÃŸen, komplexen Netz und entfernen anschlieÃŸend Ã¼berflÃ¼ssige Gewichte (Pruning).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimizing Neural Networks Tuningoptionen: Gewichtspruning Weight Agnostic Neural Networks ï‚§Problem: Bei herkÃ¶mmlichen AnsÃ¤tzen beginnen wir mit einem groÃŸen, komplexen Netz und entfernen anschlieÃŸend Ã¼berflÃ¼ssige Gewichte (Pruning).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_957",
    "question": "Was ist Alternative Idee?",
    "type": "single",
    "options": [
      "Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Alternative Idee: Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Alternative Idee"
    ],
    "difficulty": 2
  },
  {
    "id": "q_958",
    "question": "Richtig oder Falsch: Alternative Idee Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Alternative Idee: Beginne stattdessen mit einer minimalen Netzwerkarchitektur und erweitere sie schrittweise, bis die gewÃ¼nschte Leistung erreicht ist.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Alternative Idee"
    ],
    "difficulty": 1
  },
  {
    "id": "q_959",
    "question": "Was ist Parent?",
    "type": "single",
    "options": [
      "Architektur einbetten lassen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Parent: Architektur einbetten lassen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Parent"
    ],
    "difficulty": 2
  },
  {
    "id": "q_960",
    "question": "Richtig oder Falsch: Parent Architektur einbetten lassen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Parent: Architektur einbetten lassen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Parent"
    ],
    "difficulty": 1
  },
  {
    "id": "q_961",
    "question": "Was ist Dieses Weight?",
    "type": "single",
    "options": [
      "Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Dieses Weight: Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Dieses Weight"
    ],
    "difficulty": 2
  },
  {
    "id": "q_962",
    "question": "Richtig oder Falsch: Dieses Weight Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Dieses Weight: Sharing ist entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Dieses Weight"
    ],
    "difficulty": 1
  },
  {
    "id": "q_963",
    "question": "Was ist Weight?",
    "type": "single",
    "options": [
      "Sharing spiegelt die gemessene Performance auch die Weight -Agnostic -FÃ¤higkeit wider.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Weight: Sharing spiegelt die gemessene Performance auch die Weight -Agnostic -FÃ¤higkeit wider.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Weight"
    ],
    "difficulty": 2
  },
  {
    "id": "q_964",
    "question": "Richtig oder Falsch: Weight Sharing spiegelt die gemessene Performance auch die Weight -Agnostic -FÃ¤higkeit wider.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Weight: Sharing spiegelt die gemessene Performance auch die Weight -Agnostic -FÃ¤higkeit wider.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Weight"
    ],
    "difficulty": 1
  },
  {
    "id": "q_965",
    "question": "Was ist Iterieren?",
    "type": "single",
    "options": [
      "Verwende die so entstandenen Netze und springe zu Schritt 2 zurÃ¼ck (testen â†’ ranken â†’ variieren).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Iterieren: Verwende die so entstandenen Netze und springe zu Schritt 2 zurÃ¼ck (testen â†’ ranken â†’ variieren).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Iterieren"
    ],
    "difficulty": 2
  },
  {
    "id": "q_966",
    "question": "Richtig oder Falsch: Iterieren Verwende die so entstandenen Netze und springe zu Schritt 2 zurÃ¼ck (testen â†’ ranken â†’ variieren).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Iterieren: Verwende die so entstandenen Netze und springe zu Schritt 2 zurÃ¼ck (testen â†’ ranken â†’ variieren).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Iterieren"
    ],
    "difficulty": 1
  },
  {
    "id": "q_967",
    "question": "Was ist Sharing?",
    "type": "single",
    "options": [
      "entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Sharing: entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Sharing"
    ],
    "difficulty": 2
  },
  {
    "id": "q_968",
    "question": "Richtig oder Falsch: Sharing entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Sharing: entscheidend, weil es die Suche dazu zwingt, gewichts -agnostische Architekturen zu bevorzugen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 69,
    "tags": [
      "Sharing"
    ],
    "difficulty": 1
  },
  {
    "id": "q_969",
    "question": "Was ist Optimizing Neural Networks Tuningoptionen?",
    "type": "single",
    "options": [
      "Gewichtspruning Operators for searching the space of network topologies Left: A minimal network topology, with input and outputs only partially connected.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Optimizing Neural Networks Tuningoptionen: Gewichtspruning Operators for searching the space of network topologies Left: A minimal network topology, with input and outputs only partially connected.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_970",
    "question": "Richtig oder Falsch: Optimizing Neural Networks Tuningoptionen Gewichtspruning Operators for searching the space of network topologies Left: A minimal network topology, with input and outputs only partially connected.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Optimizing Neural Networks Tuningoptionen: Gewichtspruning Operators for searching the space of network topologies Left: A minimal network topology, with input and outputs only partially connected.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Optimizing Neural Networks Tuningoptionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_971",
    "question": "Was ist Middle?",
    "type": "single",
    "options": [
      "Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Middle: Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Middle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_972",
    "question": "Richtig oder Falsch: Middle Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Middle: Networks are altered in one of three ways:(1) Insert Node: a new node is inserted by splitting an existing connection.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Middle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_973",
    "question": "Was ist Add Connection?",
    "type": "single",
    "options": [
      "a new connection is added by connecting two previously unconnected nodes.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Add Connection: a new connection is added by connecting two previously unconnected nodes.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Add Connection"
    ],
    "difficulty": 2
  },
  {
    "id": "q_974",
    "question": "Richtig oder Falsch: Add Connection a new connection is added by connecting two previously unconnected nodes.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Add Connection: a new connection is added by connecting two previously unconnected nodes.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Add Connection"
    ],
    "difficulty": 1
  },
  {
    "id": "q_975",
    "question": "Was ist Change Activation?",
    "type": "single",
    "options": [
      "the activation function of a hidden node is reassigned.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Change Activation: the activation function of a hidden node is reassigned.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Change Activation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_976",
    "question": "Richtig oder Falsch: Change Activation the activation function of a hidden node is reassigned.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Change Activation: the activation function of a hidden node is reassigned.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Change Activation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_977",
    "question": "Was ist Right?",
    "type": "single",
    "options": [
      "Possible activation functions (linear, step, sin, cosine, Gaussian, tanh, sigmoid, inverse, absolute value, ReLU ) https://ai.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Right: Possible activation functions (linear, step, sin, cosine, Gaussian, tanh, sigmoid, inverse, absolute value, ReLU ) https://ai.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Right"
    ],
    "difficulty": 2
  },
  {
    "id": "q_978",
    "question": "Richtig oder Falsch: Right Possible activation functions (linear, step, sin, cosine, Gaussian, tanh, sigmoid, inverse, absolute value, ReLU ) https://ai.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Right: Possible activation functions (linear, step, sin, cosine, Gaussian, tanh, sigmoid, inverse, absolute value, ReLU ) https://ai.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 70,
    "tags": [
      "Right"
    ],
    "difficulty": 1
  },
  {
    "id": "q_979",
    "question": "Was ist Left?",
    "type": "single",
    "options": [
      "A hand -engineered, fully -connected deep neural network with 2760 weight connections.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Left: A hand -engineered, fully -connected deep neural network with 2760 weight connections.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 71,
    "tags": [
      "Left"
    ],
    "difficulty": 2
  },
  {
    "id": "q_980",
    "question": "Richtig oder Falsch: Left A hand -engineered, fully -connected deep neural network with 2760 weight connections.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Left: A hand -engineered, fully -connected deep neural network with 2760 weight connections.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 71,
    "tags": [
      "Left"
    ],
    "difficulty": 1
  },
  {
    "id": "q_981",
    "question": "Was ist Right?",
    "type": "single",
    "options": [
      "A weight agnostic neural network architecture with 44 connections that can perform the same Bipedal Walker task.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Right: A weight agnostic neural network architecture with 44 connections that can perform the same Bipedal Walker task.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 71,
    "tags": [
      "Right"
    ],
    "difficulty": 2
  },
  {
    "id": "q_982",
    "question": "Richtig oder Falsch: Right A weight agnostic neural network architecture with 44 connections that can perform the same Bipedal Walker task.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Right: A weight agnostic neural network architecture with 44 connections that can perform the same Bipedal Walker task.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 71,
    "tags": [
      "Right"
    ],
    "difficulty": 1
  },
  {
    "id": "q_983",
    "question": "Was ist Standard?",
    "type": "single",
    "options": [
      "NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Standard: NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 73,
    "tags": [
      "Standard"
    ],
    "difficulty": 2
  },
  {
    "id": "q_984",
    "question": "Richtig oder Falsch: Standard NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Standard: NNs kÃ¶nnen keine Zeitreihen modellieren ï‚§RNNs modellieren ZeitabhÃ¤ngigkeiten ï‚§Verbindungen zwischen ZustÃ¤nden von (gleichen) Knotenpunkten ï‚§Zeitliche Reihenfolge der Speicherzellen ï‚§Reihenfolge der Trainingsdaten ist wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 73,
    "tags": [
      "Standard"
    ],
    "difficulty": 1
  },
  {
    "id": "q_985",
    "question": "Was ist Trainingsdaten?",
    "type": "single",
    "options": [
      "wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Trainingsdaten: wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 73,
    "tags": [
      "Trainingsdaten"
    ],
    "difficulty": 2
  },
  {
    "id": "q_986",
    "question": "Richtig oder Falsch: Trainingsdaten wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Trainingsdaten: wichtigMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 73,
    "tags": [
      "Trainingsdaten"
    ],
    "difficulty": 1
  },
  {
    "id": "q_987",
    "question": "Was ist Schritt?",
    "type": "single",
    "options": [
      "1y(t), abhÃ¤ngig von x(t) und y(t -1), y(t - 2), .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Schritt: 1y(t), abhÃ¤ngig von x(t) und y(t -1), y(t - 2), .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Schritt"
    ],
    "difficulty": 2
  },
  {
    "id": "q_988",
    "question": "Richtig oder Falsch: Schritt 1y(t), abhÃ¤ngig von x(t) und y(t -1), y(t - 2), .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Schritt: 1y(t), abhÃ¤ngig von x(t) und y(t -1), y(t - 2), .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Schritt"
    ],
    "difficulty": 1
  },
  {
    "id": "q_989",
    "question": "Was ist Gewichte?",
    "type": "single",
    "options": [
      "wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Gewichte: wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Gewichte"
    ],
    "difficulty": 2
  },
  {
    "id": "q_990",
    "question": "Richtig oder Falsch: Gewichte wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Gewichte: wx und wy ï‚§Die Ausgabe y fÃ¼r ein rekurrentes Neuron wird berechnet als: ï‚§Resp.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Gewichte"
    ],
    "difficulty": 1
  },
  {
    "id": "q_991",
    "question": "Was ist Scikit?",
    "type": "single",
    "options": [
      "Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Scikit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_992",
    "question": "Richtig oder Falsch: Scikit Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Scikit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_993",
    "question": "Was ist Zelle?",
    "type": "single",
    "options": [
      "gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Zelle: gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Zelle"
    ],
    "difficulty": 2
  },
  {
    "id": "q_994",
    "question": "Richtig oder Falsch: Zelle gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Zelle: gegeben durch: h(t)=f(h(t -1), x(t))y(t)=f(h(t -1), x(t)) ï‚§h(t) und y(t) kÃ¶nnen je nach Zellarchitektur unterschiedlich seinMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 74,
    "tags": [
      "Zelle"
    ],
    "difficulty": 1
  },
  {
    "id": "q_995",
    "question": "Was ist Scikit?",
    "type": "single",
    "options": [
      "Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 75,
    "tags": [
      "Scikit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_996",
    "question": "Richtig oder Falsch: Scikit Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 75,
    "tags": [
      "Scikit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_997",
    "question": "Was ist Scikit?",
    "type": "single",
    "options": [
      "Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 76,
    "tags": [
      "Scikit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_998",
    "question": "Richtig oder Falsch: Scikit Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 76,
    "tags": [
      "Scikit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_999",
    "question": "Was ist Einzeleingabe?",
    "type": "single",
    "options": [
      "Sequenz aus Bild ein - Beschreibung aus ï‚§(4) Sequenz in - Vektor out (Encoder) in - Sequenz out (Decoder)Ausgangssprache in - Zielsprache out, Maschinelle ÃœbersetzungMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Einzeleingabe: Sequenz aus Bild ein - Beschreibung aus ï‚§(4) Sequenz in - Vektor out (Encoder) in - Sequenz out (Decoder)Ausgangssprache in - Zielsprache out, Maschinelle ÃœbersetzungMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 77,
    "tags": [
      "Einzeleingabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1000",
    "question": "Richtig oder Falsch: Einzeleingabe Sequenz aus Bild ein - Beschreibung aus ï‚§(4) Sequenz in - Vektor out (Encoder) in - Sequenz out (Decoder)Ausgangssprache in - Zielsprache out, Maschinelle ÃœbersetzungMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Einzeleingabe: Sequenz aus Bild ein - Beschreibung aus ï‚§(4) Sequenz in - Vektor out (Encoder) in - Sequenz out (Decoder)Ausgangssprache in - Zielsprache out, Maschinelle ÃœbersetzungMachine Learning Recurrent neural networks (RNN) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 77,
    "tags": [
      "Einzeleingabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1001",
    "question": "Was ist ZustÃ¤nde?",
    "type": "single",
    "options": [
      "h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "ZustÃ¤nde: h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 78,
    "tags": [
      "ZustÃ¤nde"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1002",
    "question": "Richtig oder Falsch: ZustÃ¤nde h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. ZustÃ¤nde: h(t) KurzzeitgedÃ¤chtnis, c(t) LangzeitgedÃ¤chtnis ï‚§NN lernt, was im LTM zu speichern ist und was es vergessen kann ï‚§g(t) kontrolliert, was im LTM gespeichert wird ( tanh) ï‚§Torsteuerung: (logistisch 0- 1) f(t) Forget Gate steuert LTM -LÃ¶schungen Input Gate steuert, was zum LTM hinzugefÃ¼gt wird o(t) Output Gate steuert, welche Teile des LTM als Output geschrieben werdenMachine Learning Long Short Term Memory (LSTM) GÃ©ron A (2018) Praxiseinstieg Machine Learning mit Scikit -Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 78,
    "tags": [
      "ZustÃ¤nde"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1003",
    "question": "Was ist Scikit?",
    "type": "single",
    "options": [
      "Learn und TensorFlow .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 79,
    "tags": [
      "Scikit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1004",
    "question": "Richtig oder Falsch: Scikit Learn und TensorFlow .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Scikit: Learn und TensorFlow .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 79,
    "tags": [
      "Scikit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1005",
    "question": "Was ist Seconds?",
    "type": "single",
    "options": [
      "float(totalNoFrames) / float( fps) file_size = (width,height) print(\"Neural Net: \", prtxt, model) print(\"Number of classes: \", len( classes)) print(\"Input Video: \", filename, \" Output Video: \", output_filename)print(\"Video Size: \", file_size, \" FPS: \", fps, \" totalNoFrames: \", totalNoFrames, \" durationInSeconds: \", durationInSeconds) # Create a VideoWriter object so we can save the video output fourcc = cv2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Seconds: float(totalNoFrames) / float( fps) file_size = (width,height) print(\"Neural Net: \", prtxt, model) print(\"Number of classes: \", len( classes)) print(\"Input Video: \", filename, \" Output Video: \", output_filename)print(\"Video Size: \", file_size, \" FPS: \", fps, \" totalNoFrames: \", totalNoFrames, \" durationInSeconds: \", durationInSeconds) # Create a VideoWriter object so we can save the video output fourcc = cv2.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 85,
    "tags": [
      "Seconds"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1006",
    "question": "Richtig oder Falsch: Seconds float(totalNoFrames) / float( fps) file_size = (width,height) print(\"Neural Net: \", prtxt, model) print(\"Number of classes: \", len( classes)) print(\"Input Video: \", filename, \" Output Video: \", output_filename)print(\"Video Size: \", file_size, \" FPS: \", fps, \" totalNoFrames: \", totalNoFrames, \" durationInSeconds: \", durationInSeconds) # Create a VideoWriter object so we can save the video output fourcc = cv2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Seconds: float(totalNoFrames) / float( fps) file_size = (width,height) print(\"Neural Net: \", prtxt, model) print(\"Number of classes: \", len( classes)) print(\"Input Video: \", filename, \" Output Video: \", output_filename)print(\"Video Size: \", file_size, \" FPS: \", fps, \" totalNoFrames: \", totalNoFrames, \" durationInSeconds: \", durationInSeconds) # Create a VideoWriter object so we can save the video output fourcc = cv2.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 85,
    "tags": [
      "Seconds"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1007",
    "question": "Was ist Chair?",
    "type": "single",
    "options": [
      "Cup_WIN_20211228_19_47_09_Pro_obj_detected.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Chair: Cup_WIN_20211228_19_47_09_Pro_obj_detected.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 88,
    "tags": [
      "Chair"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1008",
    "question": "Richtig oder Falsch: Chair Cup_WIN_20211228_19_47_09_Pro_obj_detected.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Chair: Cup_WIN_20211228_19_47_09_Pro_obj_detected.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 88,
    "tags": [
      "Chair"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1009",
    "question": "Was ist Machine Learning Evaluation?",
    "type": "single",
    "options": [
      "Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Evaluation: Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Machine Learning Evaluation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1010",
    "question": "Richtig oder Falsch: Machine Learning Evaluation Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Evaluation: Fragestellungen ï‚§Welches Modell ist am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Machine Learning Evaluation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1011",
    "question": "Was ist Modell?",
    "type": "single",
    "options": [
      "am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Modell: am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Modell"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1012",
    "question": "Richtig oder Falsch: Modell am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Modell: am besten fÃ¼r die LÃ¶sung des Problems geeignet?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Modell"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1013",
    "question": "Was ist Robust?",
    "type": "single",
    "options": [
      "ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Robust: ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Robust"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1014",
    "question": "Richtig oder Falsch: Robust ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Robust: ein Modell gegenÃ¼ber Manipulation (insbesondere â€Adversarial Examplesâ€œ )?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 90,
    "tags": [
      "Robust"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1015",
    "question": "Was ist Datenmenge?",
    "type": "single",
    "options": [
      "GroÃŸe Netze benÃ¶tigen enorme Mengen an Trainingsdaten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Datenmenge: GroÃŸe Netze benÃ¶tigen enorme Mengen an Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Datenmenge"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1016",
    "question": "Richtig oder Falsch: Datenmenge GroÃŸe Netze benÃ¶tigen enorme Mengen an Trainingsdaten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Datenmenge: GroÃŸe Netze benÃ¶tigen enorme Mengen an Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Datenmenge"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1017",
    "question": "Was ist DatenqualitÃ¤t?",
    "type": "single",
    "options": [
      "Falsche, unvollstÃ¤ndige oder verzerrte Daten fÃ¼hren zu schlechten Ergebnissen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "DatenqualitÃ¤t: Falsche, unvollstÃ¤ndige oder verzerrte Daten fÃ¼hren zu schlechten Ergebnissen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "DatenqualitÃ¤t"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1018",
    "question": "Richtig oder Falsch: DatenqualitÃ¤t Falsche, unvollstÃ¤ndige oder verzerrte Daten fÃ¼hren zu schlechten Ergebnissen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. DatenqualitÃ¤t: Falsche, unvollstÃ¤ndige oder verzerrte Daten fÃ¼hren zu schlechten Ergebnissen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "DatenqualitÃ¤t"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1019",
    "question": "Was ist Fairness?",
    "type": "single",
    "options": [
      "Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Fairness: Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Fairness"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1020",
    "question": "Richtig oder Falsch: Fairness Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Fairness: Modelle Ã¼bernehmen gesellschaftliche oder statistische Verzerrungen aus Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Fairness"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1021",
    "question": "Was ist Overfitting?",
    "type": "single",
    "options": [
      "Modell lernt Trainingsdaten auswendig statt Muster zu generalisieren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Overfitting: Modell lernt Trainingsdaten auswendig statt Muster zu generalisieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Overfitting"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1022",
    "question": "Richtig oder Falsch: Overfitting Modell lernt Trainingsdaten auswendig statt Muster zu generalisieren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Overfitting: Modell lernt Trainingsdaten auswendig statt Muster zu generalisieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Overfitting"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1023",
    "question": "Was ist Hyperparameter?",
    "type": "single",
    "options": [
      "Tuning: Viele Stellschrauben (Lernrate, Schichten, BatchgrÃ¶ÃŸe).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hyperparameter: Tuning: Viele Stellschrauben (Lernrate, Schichten, BatchgrÃ¶ÃŸe).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Hyperparameter"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1024",
    "question": "Richtig oder Falsch: Hyperparameter Tuning: Viele Stellschrauben (Lernrate, Schichten, BatchgrÃ¶ÃŸe).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hyperparameter: Tuning: Viele Stellschrauben (Lernrate, Schichten, BatchgrÃ¶ÃŸe).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "Hyperparameter"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1025",
    "question": "Was ist KomplexitÃ¤t?",
    "type": "single",
    "options": [
      "Millionen Parameter â†’ schwer zu optimieren und zu interpretieren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "KomplexitÃ¤t: Millionen Parameter â†’ schwer zu optimieren und zu interpretieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "KomplexitÃ¤t"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1026",
    "question": "Richtig oder Falsch: KomplexitÃ¤t Millionen Parameter â†’ schwer zu optimieren und zu interpretieren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. KomplexitÃ¤t: Millionen Parameter â†’ schwer zu optimieren und zu interpretieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "KomplexitÃ¤t"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1027",
    "question": "Was ist ErklÃ¤rbarkeit?",
    "type": "single",
    "options": [
      "Black-Box -Charakter erschwert Nachvollziehbarkeit.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "ErklÃ¤rbarkeit: Black-Box -Charakter erschwert Nachvollziehbarkeit.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "ErklÃ¤rbarkeit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1028",
    "question": "Richtig oder Falsch: ErklÃ¤rbarkeit Black-Box -Charakter erschwert Nachvollziehbarkeit.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. ErklÃ¤rbarkeit: Black-Box -Charakter erschwert Nachvollziehbarkeit.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 91,
    "tags": [
      "ErklÃ¤rbarkeit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1029",
    "question": "Was ist Rechenaufwand?",
    "type": "single",
    "options": [
      "Training groÃŸer Netze benÃ¶tigt spezialisierte Hardware (GPU/TPU).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Rechenaufwand: Training groÃŸer Netze benÃ¶tigt spezialisierte Hardware (GPU/TPU).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Rechenaufwand"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1030",
    "question": "Richtig oder Falsch: Rechenaufwand Training groÃŸer Netze benÃ¶tigt spezialisierte Hardware (GPU/TPU).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Rechenaufwand: Training groÃŸer Netze benÃ¶tigt spezialisierte Hardware (GPU/TPU).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Rechenaufwand"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1031",
    "question": "Was ist Speicherbedarf?",
    "type": "single",
    "options": [
      "Modelle wie GPT oder ResNet enthalten Milliarden Parameter.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Speicherbedarf: Modelle wie GPT oder ResNet enthalten Milliarden Parameter.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Speicherbedarf"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1032",
    "question": "Richtig oder Falsch: Speicherbedarf Modelle wie GPT oder ResNet enthalten Milliarden Parameter.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Speicherbedarf: Modelle wie GPT oder ResNet enthalten Milliarden Parameter.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Speicherbedarf"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1033",
    "question": "Was ist Application Time?",
    "type": "single",
    "options": [
      "Lange Trainingszeiten, hohe Energiekosten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Application Time: Lange Trainingszeiten, hohe Energiekosten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Application Time"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1034",
    "question": "Richtig oder Falsch: Application Time Lange Trainingszeiten, hohe Energiekosten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Application Time: Lange Trainingszeiten, hohe Energiekosten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Application Time"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1035",
    "question": "Was ist Sicherheits?",
    "type": "single",
    "options": [
      "und Robustheitsaspekte ï‚§Adversarial Examples : Kleine EingabeÃ¤nderungen fÃ¼hren zu falschen Ausgaben.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Sicherheits: und Robustheitsaspekte ï‚§Adversarial Examples : Kleine EingabeÃ¤nderungen fÃ¼hren zu falschen Ausgaben.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Sicherheits"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1036",
    "question": "Richtig oder Falsch: Sicherheits und Robustheitsaspekte ï‚§Adversarial Examples : Kleine EingabeÃ¤nderungen fÃ¼hren zu falschen Ausgaben.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Sicherheits: und Robustheitsaspekte ï‚§Adversarial Examples : Kleine EingabeÃ¤nderungen fÃ¼hren zu falschen Ausgaben.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Sicherheits"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1037",
    "question": "Was ist Robustheit?",
    "type": "single",
    "options": [
      "Sensitiv gegenÃ¼ber Rauschen oder unerwarteten Eingaben.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Robustheit: Sensitiv gegenÃ¼ber Rauschen oder unerwarteten Eingaben.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Robustheit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1038",
    "question": "Richtig oder Falsch: Robustheit Sensitiv gegenÃ¼ber Rauschen oder unerwarteten Eingaben.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Robustheit: Sensitiv gegenÃ¼ber Rauschen oder unerwarteten Eingaben.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Robustheit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1039",
    "question": "Was ist Sicherheit?",
    "type": "single",
    "options": [
      "Gefahr durch Datenvergiftung ( â€Data Poisoningâ€œ).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Sicherheit: Gefahr durch Datenvergiftung ( â€Data Poisoningâ€œ).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Sicherheit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1040",
    "question": "Richtig oder Falsch: Sicherheit Gefahr durch Datenvergiftung ( â€Data Poisoningâ€œ).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Sicherheit: Gefahr durch Datenvergiftung ( â€Data Poisoningâ€œ).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Sicherheit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1041",
    "question": "Was ist Transparenz?",
    "type": "single",
    "options": [
      "Entscheidungen mÃ¼ssen erklÃ¤rbar und Ã¼berprÃ¼fbar sein.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Transparenz: Entscheidungen mÃ¼ssen erklÃ¤rbar und Ã¼berprÃ¼fbar sein.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Transparenz"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1042",
    "question": "Richtig oder Falsch: Transparenz Entscheidungen mÃ¼ssen erklÃ¤rbar und Ã¼berprÃ¼fbar sein.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Transparenz: Entscheidungen mÃ¼ssen erklÃ¤rbar und Ã¼berprÃ¼fbar sein.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Transparenz"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1043",
    "question": "Was ist Verantwortung?",
    "type": "single",
    "options": [
      "Wer haftet bei Fehlentscheidungen eines Modells?",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verantwortung: Wer haftet bei Fehlentscheidungen eines Modells?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Verantwortung"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1044",
    "question": "Richtig oder Falsch: Verantwortung Wer haftet bei Fehlentscheidungen eines Modells?",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verantwortung: Wer haftet bei Fehlentscheidungen eines Modells?",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Verantwortung"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1045",
    "question": "Was ist Nachhaltigkeit?",
    "type": "single",
    "options": [
      "Hoher Energieverbrauch bei groÃŸem Training.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Nachhaltigkeit: Hoher Energieverbrauch bei groÃŸem Training.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Nachhaltigkeit"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1046",
    "question": "Richtig oder Falsch: Nachhaltigkeit Hoher Energieverbrauch bei groÃŸem Training.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Nachhaltigkeit: Hoher Energieverbrauch bei groÃŸem Training.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 92,
    "tags": [
      "Nachhaltigkeit"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1047",
    "question": "Was ist Visualisierungs?",
    "type": "single",
    "options": [
      "Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Visualisierungs: Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 93,
    "tags": [
      "Visualisierungs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1048",
    "question": "Richtig oder Falsch: Visualisierungs Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Visualisierungs: Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 93,
    "tags": [
      "Visualisierungs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1049",
    "question": "Was ist Microscope?",
    "type": "single",
    "options": [
      "eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Microscope: eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 93,
    "tags": [
      "Microscope"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1050",
    "question": "Richtig oder Falsch: Microscope eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Microscope: eine interaktive Visualisierungs -Plattform, entwickelt von OpenAI, mit dem Ziel, die inneren Funktionsweisen von tiefen neuronalen Netzen besser zu verstehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 93,
    "tags": [
      "Microscope"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1051",
    "question": "Was ist Kassischer Reinforcement?",
    "type": "single",
    "options": [
      "Learning-Fehler ï‚§Ziel: Eine gute Rennzeit oder hohe Punktzahl erreichen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Kassischer Reinforcement: Learning-Fehler ï‚§Ziel: Eine gute Rennzeit oder hohe Punktzahl erreichen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 95,
    "tags": [
      "Kassischer Reinforcement"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1052",
    "question": "Richtig oder Falsch: Kassischer Reinforcement Learning-Fehler ï‚§Ziel: Eine gute Rennzeit oder hohe Punktzahl erreichen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Kassischer Reinforcement: Learning-Fehler ï‚§Ziel: Eine gute Rennzeit oder hohe Punktzahl erreichen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 95,
    "tags": [
      "Kassischer Reinforcement"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1053",
    "question": "Was ist Problem?",
    "type": "single",
    "options": [
      "Die Belohnungsfunktion war falsch definiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Problem: Die Belohnungsfunktion war falsch definiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 95,
    "tags": [
      "Problem"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1054",
    "question": "Richtig oder Falsch: Problem Die Belohnungsfunktion war falsch definiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Problem: Die Belohnungsfunktion war falsch definiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 95,
    "tags": [
      "Problem"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1055",
    "question": "Was ist Pixel?",
    "type": "single",
    "options": [
      "Manipulation ï‚§Absichtlich verÃ¤nderte Eingabedaten, die ein neuronales Netz in die Irre fÃ¼hren, obwohl sie fÃ¼r Menschen unverÃ¤ndert aussehen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Pixel: Manipulation ï‚§Absichtlich verÃ¤nderte Eingabedaten, die ein neuronales Netz in die Irre fÃ¼hren, obwohl sie fÃ¼r Menschen unverÃ¤ndert aussehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 96,
    "tags": [
      "Pixel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1056",
    "question": "Richtig oder Falsch: Pixel Manipulation ï‚§Absichtlich verÃ¤nderte Eingabedaten, die ein neuronales Netz in die Irre fÃ¼hren, obwohl sie fÃ¼r Menschen unverÃ¤ndert aussehen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Pixel: Manipulation ï‚§Absichtlich verÃ¤nderte Eingabedaten, die ein neuronales Netz in die Irre fÃ¼hren, obwohl sie fÃ¼r Menschen unverÃ¤ndert aussehen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 96,
    "tags": [
      "Pixel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1057",
    "question": "Was ist Menschen?",
    "type": "single",
    "options": [
      "eindeutig eine SchildkrÃ¶te ï‚§FÃ¼r das Modell: hohe Klassifikationswahrscheinlichkeit auf rifle ï‚§Methode: Textur der 3D -SchildkrÃ¶te gezielt pixelweise verÃ¤ndert ï‚§Ziel war, dass die TÃ¤uschung robust aus verschiedenen Blickwinkeln funktioniert â€“ also auch bei realen Aufnahmen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Menschen: eindeutig eine SchildkrÃ¶te ï‚§FÃ¼r das Modell: hohe Klassifikationswahrscheinlichkeit auf rifle ï‚§Methode: Textur der 3D -SchildkrÃ¶te gezielt pixelweise verÃ¤ndert ï‚§Ziel war, dass die TÃ¤uschung robust aus verschiedenen Blickwinkeln funktioniert â€“ also auch bei realen Aufnahmen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 97,
    "tags": [
      "Menschen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1058",
    "question": "Richtig oder Falsch: Menschen eindeutig eine SchildkrÃ¶te ï‚§FÃ¼r das Modell: hohe Klassifikationswahrscheinlichkeit auf rifle ï‚§Methode: Textur der 3D -SchildkrÃ¶te gezielt pixelweise verÃ¤ndert ï‚§Ziel war, dass die TÃ¤uschung robust aus verschiedenen Blickwinkeln funktioniert â€“ also auch bei realen Aufnahmen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Menschen: eindeutig eine SchildkrÃ¶te ï‚§FÃ¼r das Modell: hohe Klassifikationswahrscheinlichkeit auf rifle ï‚§Methode: Textur der 3D -SchildkrÃ¶te gezielt pixelweise verÃ¤ndert ï‚§Ziel war, dass die TÃ¤uschung robust aus verschiedenen Blickwinkeln funktioniert â€“ also auch bei realen Aufnahmen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 97,
    "tags": [
      "Menschen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1059",
    "question": "Was ist Robust Physical?",
    "type": "single",
    "options": [
      "World Attacks on Deep Learning Models\".",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Robust Physical: World Attacks on Deep Learning Models\".",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 98,
    "tags": [
      "Robust Physical"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1060",
    "question": "Richtig oder Falsch: Robust Physical World Attacks on Deep Learning Models\".",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Robust Physical: World Attacks on Deep Learning Models\".",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 98,
    "tags": [
      "Robust Physical"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1061",
    "question": "Was ist Machine Learning Model Fairness?",
    "type": "single",
    "options": [
      "Beispiel â€“ Google Fotos Image Auto Labeling ï‚§Die Auto-Labeling Funktion in Google Fotos taggte Fotos von dunkelhÃ¤utigen Menschen mitunter fÃ¤lschlicherweise mit der Klasse â€Gorillas â€œ ï‚§Mangels einfacher technischer LÃ¶sungen fÃ¼r das Problem wurde die â€Gorillas â€œ-Klasse aus dem Auto- Labeling entfernt https://www.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Model Fairness: Beispiel â€“ Google Fotos Image Auto Labeling ï‚§Die Auto-Labeling Funktion in Google Fotos taggte Fotos von dunkelhÃ¤utigen Menschen mitunter fÃ¤lschlicherweise mit der Klasse â€Gorillas â€œ ï‚§Mangels einfacher technischer LÃ¶sungen fÃ¼r das Problem wurde die â€Gorillas â€œ-Klasse aus dem Auto- Labeling entfernt https://www.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 99,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1062",
    "question": "Richtig oder Falsch: Machine Learning Model Fairness Beispiel â€“ Google Fotos Image Auto Labeling ï‚§Die Auto-Labeling Funktion in Google Fotos taggte Fotos von dunkelhÃ¤utigen Menschen mitunter fÃ¤lschlicherweise mit der Klasse â€Gorillas â€œ ï‚§Mangels einfacher technischer LÃ¶sungen fÃ¼r das Problem wurde die â€Gorillas â€œ-Klasse aus dem Auto- Labeling entfernt https://www.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Model Fairness: Beispiel â€“ Google Fotos Image Auto Labeling ï‚§Die Auto-Labeling Funktion in Google Fotos taggte Fotos von dunkelhÃ¤utigen Menschen mitunter fÃ¤lschlicherweise mit der Klasse â€Gorillas â€œ ï‚§Mangels einfacher technischer LÃ¶sungen fÃ¼r das Problem wurde die â€Gorillas â€œ-Klasse aus dem Auto- Labeling entfernt https://www.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 99,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1063",
    "question": "Was ist Machine Learning Model Fairness?",
    "type": "single",
    "options": [
      "Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias).",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Model Fairness: Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1064",
    "question": "Richtig oder Falsch: Machine Learning Model Fairness Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias).",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Model Fairness: Beispiel â€“ Twitter Cropping ï‚§Bilder in Tweets werden in der Feed-Ansicht nur als Ausschnitt dargestellt ( â€Croppingâ€œ) ï‚§Der Ausschnitt wird Ã¼ber ein Machine Learning Modell bestimmt, das den â€relevantestenâ€œ Teil des Bildes ermittelt ï‚§Der automatische Zuschneide-Algorithmus zeigte eine unbeabsichtigte rassistische Verzerrung ( racial bias).",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1065",
    "question": "Was ist Racial?",
    "type": "single",
    "options": [
      "Bias â€œ) ï‚§Beispiel: Mitch McConnell vs.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Racial: Bias â€œ) ï‚§Beispiel: Mitch McConnell vs.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Racial"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1066",
    "question": "Richtig oder Falsch: Racial Bias â€œ) ï‚§Beispiel: Mitch McConnell vs.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Racial: Bias â€œ) ï‚§Beispiel: Mitch McConnell vs.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 100,
    "tags": [
      "Racial"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1067",
    "question": "Was ist Machine Learning Model Fairness?",
    "type": "single",
    "options": [
      "Feature Importance / Correlation ï‚§Ein Modell soll unvoreingenommen (unbiased) und gerecht entscheiden â€“ unabhÃ¤ngig von sensiblen Merkmalen wie Geschlecht, Alter, Herkunft usw.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Model Fairness: Feature Importance / Correlation ï‚§Ein Modell soll unvoreingenommen (unbiased) und gerecht entscheiden â€“ unabhÃ¤ngig von sensiblen Merkmalen wie Geschlecht, Alter, Herkunft usw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1068",
    "question": "Richtig oder Falsch: Machine Learning Model Fairness Feature Importance / Correlation ï‚§Ein Modell soll unvoreingenommen (unbiased) und gerecht entscheiden â€“ unabhÃ¤ngig von sensiblen Merkmalen wie Geschlecht, Alter, Herkunft usw.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Model Fairness: Feature Importance / Correlation ï‚§Ein Modell soll unvoreingenommen (unbiased) und gerecht entscheiden â€“ unabhÃ¤ngig von sensiblen Merkmalen wie Geschlecht, Alter, Herkunft usw.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Machine Learning Model Fairness"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1069",
    "question": "Was ist Eingabedaten?",
    "type": "single",
    "options": [
      "die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Eingabedaten: die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Eingabedaten"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1070",
    "question": "Richtig oder Falsch: Eingabedaten die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Eingabedaten: die ZusammenhÃ¤nge unter UmstÃ¤nden nur durch Validierung auf zusÃ¤tzlichen diversen Datasets sichtbar.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 101,
    "tags": [
      "Eingabedaten"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1071",
    "question": "Was ist Exkurs?",
    "type": "single",
    "options": [
      "Backpropagation Training 102 Prof.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Exkurs: Backpropagation Training 102 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 102,
    "tags": [
      "Exkurs"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1072",
    "question": "Richtig oder Falsch: Exkurs Backpropagation Training 102 Prof.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Exkurs: Backpropagation Training 102 Prof.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 102,
    "tags": [
      "Exkurs"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1073",
    "question": "Was ist Machine Learning Artificial Neural Networks Aktivierungsfunktion?",
    "type": "single",
    "options": [
      "ğ‘ğ‘=ğ’‡ğ’‡ğ’‚ğ’‚(ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ ) beschreibt die Aktivierung des Neurons.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Machine Learning Artificial Neural Networks Aktivierungsfunktion: ğ‘ğ‘=ğ’‡ğ’‡ğ’‚ğ’‚(ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ ) beschreibt die Aktivierung des Neurons.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Machine Learning Artificial Neural Networks Aktivierungsfunktion"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1074",
    "question": "Richtig oder Falsch: Machine Learning Artificial Neural Networks Aktivierungsfunktion ğ‘ğ‘=ğ’‡ğ’‡ğ’‚ğ’‚(ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ ) beschreibt die Aktivierung des Neurons.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Machine Learning Artificial Neural Networks Aktivierungsfunktion: ğ‘ğ‘=ğ’‡ğ’‡ğ’‚ğ’‚(ğ‘–ğ‘–ğ‘¤ğ‘¤ğ‘œğ‘œ ) beschreibt die Aktivierung des Neurons.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Machine Learning Artificial Neural Networks Aktivierungsfunktion"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1075",
    "question": "Was ist Transferfunktion?",
    "type": "single",
    "options": [
      "(net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Transferfunktion: (net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Transferfunktion"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1076",
    "question": "Richtig oder Falsch: Transferfunktion (net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Transferfunktion: (net input ): Ausgabefunktion: =ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘ ğ’‡ğ’‡ğ’ğ’ğ’ğ’ğ’ğ’ğ‘ğ‘= id(ğ’‡ğ’‡(ğ‘ğ‘)) Die Ausgabe ist in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Transferfunktion"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1077",
    "question": "Was ist Ausgabe?",
    "type": "single",
    "options": [
      "in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ausgabe: in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Ausgabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1078",
    "question": "Richtig oder Falsch: Ausgabe in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ausgabe: in den meisten FÃ¤llen identisch mit dem AktivitÃ¤tswert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 103,
    "tags": [
      "Ausgabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1079",
    "question": "Was ist Back?",
    "type": "single",
    "options": [
      "propagationForward Propagation ( VorwÃ¤rtspropagation) â€¢FÃ¼hre die Eingabedaten nacheinander durch die Schichten der Neuronen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Back: propagationForward Propagation ( VorwÃ¤rtspropagation) â€¢FÃ¼hre die Eingabedaten nacheinander durch die Schichten der Neuronen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Back"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1080",
    "question": "Richtig oder Falsch: Back propagationForward Propagation ( VorwÃ¤rtspropagation) â€¢FÃ¼hre die Eingabedaten nacheinander durch die Schichten der Neuronen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Back: propagationForward Propagation ( VorwÃ¤rtspropagation) â€¢FÃ¼hre die Eingabedaten nacheinander durch die Schichten der Neuronen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Back"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1081",
    "question": "Was ist Bias?",
    "type": "single",
    "options": [
      "Werte), um die Aktivierungen in jedem Neuron zu berechnen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Bias: Werte), um die Aktivierungen in jedem Neuron zu berechnen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Bias"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1082",
    "question": "Richtig oder Falsch: Bias Werte), um die Aktivierungen in jedem Neuron zu berechnen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Bias: Werte), um die Aktivierungen in jedem Neuron zu berechnen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Bias"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1083",
    "question": "Was ist Back?",
    "type": "single",
    "options": [
      "propagation ( FehlerrÃ¼ckfÃ¼hrung) â€¢Verwende den Fehler, um die Gradienten in Bezug auf alle Parameter im Netzwerk zu berechnen â€“ rÃ¼ckwÃ¤rts von der Ausgabeschicht zur Eingabeschicht.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Back: propagation ( FehlerrÃ¼ckfÃ¼hrung) â€¢Verwende den Fehler, um die Gradienten in Bezug auf alle Parameter im Netzwerk zu berechnen â€“ rÃ¼ckwÃ¤rts von der Ausgabeschicht zur Eingabeschicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Back"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1084",
    "question": "Richtig oder Falsch: Back propagation ( FehlerrÃ¼ckfÃ¼hrung) â€¢Verwende den Fehler, um die Gradienten in Bezug auf alle Parameter im Netzwerk zu berechnen â€“ rÃ¼ckwÃ¤rts von der Ausgabeschicht zur Eingabeschicht.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Back: propagation ( FehlerrÃ¼ckfÃ¼hrung) â€¢Verwende den Fehler, um die Gradienten in Bezug auf alle Parameter im Netzwerk zu berechnen â€“ rÃ¼ckwÃ¤rts von der Ausgabeschicht zur Eingabeschicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Back"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1085",
    "question": "Was ist VorwÃ¤rts?",
    "type": "single",
    "options": [
      "RÃ¼ckwÃ¤rts- Zyklus fÃ¼r die nÃ¤chsten Trainingsbeispiele â€“ bis das Modell konvergiert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "VorwÃ¤rts: RÃ¼ckwÃ¤rts- Zyklus fÃ¼r die nÃ¤chsten Trainingsbeispiele â€“ bis das Modell konvergiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "VorwÃ¤rts"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1086",
    "question": "Richtig oder Falsch: VorwÃ¤rts RÃ¼ckwÃ¤rts- Zyklus fÃ¼r die nÃ¤chsten Trainingsbeispiele â€“ bis das Modell konvergiert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. VorwÃ¤rts: RÃ¼ckwÃ¤rts- Zyklus fÃ¼r die nÃ¤chsten Trainingsbeispiele â€“ bis das Modell konvergiert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "VorwÃ¤rts"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1087",
    "question": "Was ist Epoche?",
    "type": "single",
    "options": [
      "Ein vollstÃ¤ndiger Durchlauf mit VorwÃ¤rts - und RÃ¼ckwÃ¤rtspropagation Ã¼ber alle Trainingsdaten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Epoche: Ein vollstÃ¤ndiger Durchlauf mit VorwÃ¤rts - und RÃ¼ckwÃ¤rtspropagation Ã¼ber alle Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Epoche"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1088",
    "question": "Richtig oder Falsch: Epoche Ein vollstÃ¤ndiger Durchlauf mit VorwÃ¤rts - und RÃ¼ckwÃ¤rtspropagation Ã¼ber alle Trainingsdaten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Epoche: Ein vollstÃ¤ndiger Durchlauf mit VorwÃ¤rts - und RÃ¼ckwÃ¤rtspropagation Ã¼ber alle Trainingsdaten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 105,
    "tags": [
      "Epoche"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1089",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1090",
    "question": "Richtig oder Falsch: Batch Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: Learning (Offline -Lernen) ï‚§Beim Batch -Learning (auch Offline Learning genannt) werden alle Trainingsdaten zu einem Batch zusammengefasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1091",
    "question": "Was ist Verfahren?",
    "type": "single",
    "options": [
      "mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verfahren: mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Verfahren"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1092",
    "question": "Richtig oder Falsch: Verfahren mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verfahren: mathematisch stabil und genau, erfordert aber hohe Rechenleistung und Speicher, da alle Daten gleichzeitig verarbeitet werden mÃ¼ssen.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 106,
    "tags": [
      "Verfahren"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1093",
    "question": "Was ist Mini?",
    "type": "single",
    "options": [
      "Batch Learning ï‚§Zwischenform zwischen Batch - und Online-Learning.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Mini: Batch Learning ï‚§Zwischenform zwischen Batch - und Online-Learning.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Mini"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1094",
    "question": "Richtig oder Falsch: Mini Batch Learning ï‚§Zwischenform zwischen Batch - und Online-Learning.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Mini: Batch Learning ï‚§Zwischenform zwischen Batch - und Online-Learning.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Mini"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1095",
    "question": "Was ist Batch?",
    "type": "single",
    "options": [
      "Learning mit der Schnelligkeit von Online-Learning.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Batch: Learning mit der Schnelligkeit von Online-Learning.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1096",
    "question": "Richtig oder Falsch: Batch Learning mit der Schnelligkeit von Online-Learning.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Batch: Learning mit der Schnelligkeit von Online-Learning.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 107,
    "tags": [
      "Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1097",
    "question": "Was ist Training Variants Merkmal Batch?",
    "type": "single",
    "options": [
      "Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Training Variants Merkmal Batch: Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Training Variants Merkmal Batch"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1098",
    "question": "Richtig oder Falsch: Training Variants Merkmal Batch Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Training Variants Merkmal Batch: Learning (Offline) Mini-Batch -LearningOnline -Learning (Inkrementell) DatenverarbeitungAlle Trainingsdaten werden gemeinsam verarbeitetTrainingsdaten werden in kleine Batches (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Training Variants Merkmal Batch"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1099",
    "question": "Was ist Gewichts?",
    "type": "single",
    "options": [
      "aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Gewichts: aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Gewichts"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1100",
    "question": "Richtig oder Falsch: Gewichts aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Gewichts: aktualisierungNach einer Epoche (einmal pro Gesamtdurchlauf)Nach jedem Mini -BatchNach jedem einzelnen Beispiel FehlerberechnungÃœber alle Trainingsdaten (globaler Fehler)Ãœber den jeweiligen Mini-BatchNur Ã¼ber das aktuelle Beispiel Rechenaufwand pro SchrittHoch Mittel Gering StabilitÃ¤tSehr stabil, da Mittelung Ã¼ber alle DatenKompromiss zwischen StabilitÃ¤t und GeschwindigkeitGeringere StabilitÃ¤t, da stark von einzelnen Beispielen abhÃ¤ngig Lernverhalten Langsam, aber prÃ¤ziseGuter Kompromiss aus Genauigkeit und EffizienzSehr schnell, aber potenziell schwankend EinsatzgebietBei kleinen bis mittleren DatensÃ¤tzen, wenn hohe Genauigkeit wichtig istStandardverfahren beim Training groÃŸer neuronaler NetzeBei kontinuierlich eintreffenden DatenstrÃ¶men (z.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 108,
    "tags": [
      "Gewichts"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1101",
    "question": "Was ist Ziel?",
    "type": "single",
    "options": [
      "es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ziel: es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Ziel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1102",
    "question": "Richtig oder Falsch: Ziel es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ziel: es, die Zielfunktion zu maximieren oder zu minimieren â€“ also eine LÃ¶sung zu finden, die den besten (hÃ¶chsten oder niedrigsten) Wert liefert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Ziel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1103",
    "question": "Was ist Netzen?",
    "type": "single",
    "options": [
      "das meist:Den Fehler minimieren.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Netzen: das meist:Den Fehler minimieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Netzen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1104",
    "question": "Richtig oder Falsch: Netzen das meist:Den Fehler minimieren.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Netzen: das meist:Den Fehler minimieren.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 109,
    "tags": [
      "Netzen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1105",
    "question": "Was ist Das Backpropagation?",
    "type": "single",
    "options": [
      "Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Das Backpropagation: Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Das Backpropagation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1106",
    "question": "Richtig oder Falsch: Das Backpropagation Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Das Backpropagation: Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Das Backpropagation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1107",
    "question": "Was ist Ziel?",
    "type": "single",
    "options": [
      "Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ziel: Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Ziel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1108",
    "question": "Richtig oder Falsch: Ziel Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ziel: Alle Gewichte so Ã¤ndern, dass der Fehler (Training â€“ Vorhersage) minimiert wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Ziel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1109",
    "question": "Was ist Lernverfahren?",
    "type": "single",
    "options": [
      "ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Lernverfahren: ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Lernverfahren"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1110",
    "question": "Richtig oder Falsch: Lernverfahren ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Lernverfahren: ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 110,
    "tags": [
      "Lernverfahren"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1111",
    "question": "Was ist Das Backpropagation?",
    "type": "single",
    "options": [
      "Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Das Backpropagation: Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Das Backpropagation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1112",
    "question": "Richtig oder Falsch: Das Backpropagation Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Das Backpropagation: Lernverfahren ist ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Das Backpropagation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1113",
    "question": "Was ist Grundidee?",
    "type": "single",
    "options": [
      "Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Grundidee: Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Grundidee"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1114",
    "question": "Richtig oder Falsch: Grundidee Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Grundidee: Alle Gewichte werden so angepasst, dass der Fehler â€“ basierend auf der Differenz zwischen Training (Sollwert) und Vorhersage (Istwert) â€“ minimiert wird.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Grundidee"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1115",
    "question": "Was ist Hinweis?",
    "type": "single",
    "options": [
      "In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Hinweis: In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Hinweis"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1116",
    "question": "Richtig oder Falsch: Hinweis In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Hinweis: In den folgenden Gleichungen wird der Eingabewert xáµ¢ als oáµ¢ bezeichnet, da er â€“ abhÃ¤ngig von der Schicht â€“ die Ausgabe der vorherigen Schicht darstellt, auÃŸer in der ersten Eingabeschicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Hinweis"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1117",
    "question": "Was ist Lernverfahren?",
    "type": "single",
    "options": [
      "ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Lernverfahren: ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Lernverfahren"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1118",
    "question": "Richtig oder Falsch: Lernverfahren ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Lernverfahren: ein Verfahren des Ã¼berwachten Lernens zum Anpassen der Verbindungsgewichte.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 111,
    "tags": [
      "Lernverfahren"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1119",
    "question": "Was ist Gewicht?",
    "type": "single",
    "options": [
      "net â±¼ = Î£(oáµ¢ Â· wáµ¢ â±¼) â‡’ âˆ‚netâ±¼/âˆ‚wâ‚áµ¢â±¼â‚ = oáµ¢ ï‚§2.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Gewicht: net â±¼ = Î£(oáµ¢ Â· wáµ¢ â±¼) â‡’ âˆ‚netâ±¼/âˆ‚wâ‚áµ¢â±¼â‚ = oáµ¢ ï‚§2.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 112,
    "tags": [
      "Gewicht"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1120",
    "question": "Richtig oder Falsch: Gewicht net â±¼ = Î£(oáµ¢ Â· wáµ¢ â±¼) â‡’ âˆ‚netâ±¼/âˆ‚wâ‚áµ¢â±¼â‚ = oáµ¢ ï‚§2.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Gewicht: net â±¼ = Î£(oáµ¢ Â· wáµ¢ â±¼) â‡’ âˆ‚netâ±¼/âˆ‚wâ‚áµ¢â±¼â‚ = oáµ¢ ï‚§2.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 112,
    "tags": [
      "Gewicht"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1121",
    "question": "Was ist Aktivierungsfunktionen?",
    "type": "single",
    "options": [
      "fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Aktivierungsfunktionen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1122",
    "question": "Richtig oder Falsch: Aktivierungsfunktionen fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Aktivierungsfunktionen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1123",
    "question": "Was ist Aktivierungsfunktion?",
    "type": "single",
    "options": [
      "eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Aktivierungsfunktion: eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Aktivierungsfunktion"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1124",
    "question": "Richtig oder Falsch: Aktivierungsfunktion eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Aktivierungsfunktion: eine der hÃ¤ufigsten Aktivierungsfunktionen: fâ‚—â‚’gâ‚â‚“â‚ = 1 / (1 + eâ»Ë£) ï‚§Ihre Ableitung lautet: fâ€™ â‚—â‚’gâ‚â‚“â‚ = fâ‚—â‚’gâ‚â‚“â‚ Â· (1 - fâ‚—â‚’gâ‚â‚“â‚) ï‚§Damit gilt: âˆ‚o â±¼/âˆ‚net â±¼ = oâ±¼ Â· (1 - oâ±¼) ï‚§Diese Eigenschaft ist rechnerisch effizient, da die Ableitung direkt aus der Ausgabe oâ±¼ berechnet werden kann â€“ ohne zusÃ¤tzliche Exponentialberechnung.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 114,
    "tags": [
      "Aktivierungsfunktion"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1125",
    "question": "Was ist Beispiel?",
    "type": "single",
    "options": [
      "Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Beispiel: Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 115,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1126",
    "question": "Richtig oder Falsch: Beispiel Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Beispiel: Logistische Aktivierungsfunktion factMachine Learning Beispiel: Logistische Aktivierungsfunktion LÃ¤mmel , Uwe; Cleve, JÃ¼rgen ( 2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 115,
    "tags": [
      "Beispiel"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1127",
    "question": "Was ist Soll?",
    "type": "single",
    "options": [
      "und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Soll: und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Soll"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1128",
    "question": "Richtig oder Falsch: Soll und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Soll: und Istwert ï‚§Die Ableitung des Fehlers nach der Ausgabe oâ±¼ ergibt: âˆ‚E/âˆ‚o â±¼ = -(tâ±¼ - oâ±¼) ï‚§Dieser Ausdruck beschreibt den Fehler des Ausgabeneurons â€“ also wie stark die berechnete Ausgabe vom Trainingsziel abweicht.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Soll"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1129",
    "question": "Was ist Backpropagation?",
    "type": "single",
    "options": [
      "Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Backpropagation: Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1130",
    "question": "Richtig oder Falsch: Backpropagation Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Backpropagation: Regel ergibt:Î”wâ‚áµ¢â±¼â‚ = -Î» (tâ±¼ - oâ±¼) fâ€™â‚â‚–â‚œ(netâ±¼) oáµ¢ ï‚§Jedes Gewicht wird proportional zum Fehler, zur Ableitung der Aktivierungsfunktion und zum Eingabewert angepasst.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 116,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1131",
    "question": "Was ist Ausgabe?",
    "type": "single",
    "options": [
      "Ableitung LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ausgabe: Ableitung LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 117,
    "tags": [
      "Ausgabe"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1132",
    "question": "Richtig oder Falsch: Ausgabe Ableitung LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ausgabe: Ableitung LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 117,
    "tags": [
      "Ausgabe"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1133",
    "question": "Was ist Training?",
    "type": "single",
    "options": [
      "Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Training: Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 117,
    "tags": [
      "Training"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1134",
    "question": "Richtig oder Falsch: Training Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Training: Ausgabe ğ‘–ğ‘–ğ‘“ğ‘“ğ‘—ğ‘—=ğ‘˜ğ‘˜ğœ•ğœ• ğœ•ğœ•ğ‘œğ‘œğ‘—ğ‘—â‰ 0Lies als: Der Ausgabefehler des Neurons j ist die Differenz zwischen dem Zielwert (Trainingswert) und dem vom neuronalen Netz berechneten Wert.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 117,
    "tags": [
      "Training"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1135",
    "question": "Was ist Ausgabeknoten?",
    "type": "single",
    "options": [
      "Fehlers (letzte Schicht)Machine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Ausgabeknoten: Fehlers (letzte Schicht)Machine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 118,
    "tags": [
      "Ausgabeknoten"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1136",
    "question": "Richtig oder Falsch: Ausgabeknoten Fehlers (letzte Schicht)Machine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Ausgabeknoten: Fehlers (letzte Schicht)Machine Learning Backpropagation LÃ¤mmel , Uwe; Cleve, JÃ¼rgen (2012): KÃ¼nstliche Intelligenz .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 118,
    "tags": [
      "Ausgabeknoten"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1137",
    "question": "Was ist Gesamtfehler?",
    "type": "single",
    "options": [
      "die Summe aller Fehler der Ausgabeneuronen .",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Gesamtfehler: die Summe aller Fehler der Ausgabeneuronen .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 118,
    "tags": [
      "Gesamtfehler"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1138",
    "question": "Richtig oder Falsch: Gesamtfehler die Summe aller Fehler der Ausgabeneuronen .",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Gesamtfehler: die Summe aller Fehler der Ausgabeneuronen .",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 118,
    "tags": [
      "Gesamtfehler"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1139",
    "question": "Was ist Backpropagation?",
    "type": "single",
    "options": [
      "Regel bleibt bestehen: Î”w â‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§FÃ¼r Neuronen der Hidden Layer gilt: sie haben keinen direkten Zielwert t â±¼.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Backpropagation: Regel bleibt bestehen: Î”w â‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§FÃ¼r Neuronen der Hidden Layer gilt: sie haben keinen direkten Zielwert t â±¼.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1140",
    "question": "Richtig oder Falsch: Backpropagation Regel bleibt bestehen: Î”w â‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§FÃ¼r Neuronen der Hidden Layer gilt: sie haben keinen direkten Zielwert t â±¼.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Backpropagation: Regel bleibt bestehen: Î”w â‚áµ¢â±¼â‚ = -Î» âˆ‚E/âˆ‚o â±¼ Â· âˆ‚oâ±¼/âˆ‚net â±¼ Â· âˆ‚net â±¼/âˆ‚wâ‚áµ¢â±¼â‚ ï‚§FÃ¼r Neuronen der Hidden Layer gilt: sie haben keinen direkten Zielwert t â±¼.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Backpropagation"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1141",
    "question": "Was ist Dabei?",
    "type": "single",
    "options": [
      "Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Dabei: Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Dabei"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1142",
    "question": "Richtig oder Falsch: Dabei Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Dabei: Î´ â‚– = -âˆ‚E/âˆ‚netâ‚– der Fehleranteil des nÃ¤chsten Layers.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 119,
    "tags": [
      "Dabei"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1143",
    "question": "Was ist Dabei?",
    "type": "single",
    "options": [
      "w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Dabei: w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 129,
    "tags": [
      "Dabei"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1144",
    "question": "Richtig oder Falsch: Dabei w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Dabei: w ij das Gewicht des Neurons j fÃ¼r den Eingang i, und ğ¸ğ¸ die Summe der Fehler.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 129,
    "tags": [
      "Dabei"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1145",
    "question": "Was ist Das Back?",
    "type": "single",
    "options": [
      "Percolation-Verfahren modifiziert den Algorithmus so, dass auch frÃ¼here (innere) Schichten stÃ¤rkere Gewichtsanpassungen erhalten.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Das Back: Percolation-Verfahren modifiziert den Algorithmus so, dass auch frÃ¼here (innere) Schichten stÃ¤rkere Gewichtsanpassungen erhalten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 130,
    "tags": [
      "Das Back"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1146",
    "question": "Richtig oder Falsch: Das Back Percolation-Verfahren modifiziert den Algorithmus so, dass auch frÃ¼here (innere) Schichten stÃ¤rkere Gewichtsanpassungen erhalten.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Das Back: Percolation-Verfahren modifiziert den Algorithmus so, dass auch frÃ¼here (innere) Schichten stÃ¤rkere Gewichtsanpassungen erhalten.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 130,
    "tags": [
      "Das Back"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1147",
    "question": "Was ist Verbesserungen?",
    "type": "single",
    "options": [
      "mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verbesserungen: mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Verbesserungen"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1148",
    "question": "Richtig oder Falsch: Verbesserungen mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verbesserungen: mÃ¶glich durch den Einsatz spezieller Optimierungsverfahren anstelle des standardmÃ¤ÃŸigen Gradienten-abstiegs.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Verbesserungen"
    ],
    "difficulty": 1
  },
  {
    "id": "q_1149",
    "question": "Was ist Verfahren?",
    "type": "single",
    "options": [
      "als â€Momentum -Termâ€œ bekannt.",
      "Eine andere Definition",
      "Keine der Antworten ist korrekt",
      "Nicht in den Quellen definiert"
    ],
    "correct_answer": 0,
    "explanation": "Verfahren: als â€Momentum -Termâ€œ bekannt.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Verfahren"
    ],
    "difficulty": 2
  },
  {
    "id": "q_1150",
    "question": "Richtig oder Falsch: Verfahren als â€Momentum -Termâ€œ bekannt.",
    "type": "tf",
    "options": [
      "Richtig",
      "Falsch"
    ],
    "correct_answer": 0,
    "explanation": "Richtig. Verfahren: als â€Momentum -Termâ€œ bekannt.",
    "source_file": "09-bigdata_data_science_NeuralNets_v7.pdf",
    "source_page": 131,
    "tags": [
      "Verfahren"
    ],
    "difficulty": 1
  }
]